[{"content":"","date":"2026年2月17日","externalUrl":null,"permalink":"/ja/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"2026年2月17日","externalUrl":null,"permalink":"/ja/categories/chama-optics/","section":"Categories","summary":"","title":"Chama Optics","type":"categories"},{"content":" Chama Optics # 🌐 한국어 릴리즈 노트 | English Release Note\nイベント会場で撮った写真を、その場で補正・フレーム・モザイクまで。\nChama Opticsは、写真好きで旅するVTuber 赤井はあとから着想を得て作った、ミラーレス・一眼レフカメラユーザー向けの写真加工アプリです。EXIFフレーム、顔自動モザイク、色調補正、チェキ風フレームなどの機能を備えています。\nイベント・旅行・ストリート撮影 —\n結婚式、VTuberオフイベント、街角や観光地など、他人の顔にモザイクをかける必要があるとき ファン写真ハッシュタグ参加者 —\n#推し活はあとん日記、#Towavel などのタグで写真を投稿するとき 一眼レフ/ミラーレスカメラユーザー・機材レビュアー —\n撮影情報（機種、レンズ、絞りなど）をフレームに入れて共有したいとき 技術的な開発過程については開発記をご覧ください。\n⬇ ダウンロードはこちら\n主な機能 # 撮影情報（EXIF）フレーム # iPhone iPad Film Date Strap Monitor Lightroom One Line Shot On Two Line Nikon PhotoStyle Lumix Photo Style + LUT EXIF情報を自動で読み取り、さまざまなテーマのフレームに配置します。（詳細を見る） カメラで撮影した写真には、カメラ機種、レンズ、シャッタースピード、絞り、ISOなどの撮影情報が含まれています。Chama Opticsはこの情報を自動で読み取り、さまざまなテーマのフレームに配置します。\nカメラメーカーのロゴ（Canon、Nikon、Sony、Lumixなど）も撮影情報から自動認識してフレームに配置します。Lumixの場合は適用されたPhoto Style名やLUTファイル名まで表示できます。\n顔自動認識 + モザイク/ステッカー # iPhone iPad 結果（結婚式） 結果（イベント） ‼️ 集合写真や20人以上が写っている場合は、「設定」→「顔検出」→「検出速度」→「Slowest」に設定してください。\n写真内の顔を自動検出し、モザイクやステッカーで隠します。（詳細を見る） イベント会場や観光地で他の人の顔が写り込んだとき、顔を自動検出してモザイクやステッカーで隠します。\nモザイク(Mosaic)、ストローク(Stroke)、ステッカー(Sticker)、モザイク+ストローク(Mosaic+Stroke)など多様な方式で隠せます 検出された顔を個別に選択して、効果を適用または解除できます 設定でカスタムステッカーを追加すると、チェキタブのサイコロにも自動的に含まれます 色調補正（LUT） # iPhone iPad 色調補正 UI (デスクトップ) 適用結果 (デスクトップ) 適用結果 (写真) .cube LUTファイルで映画のような色味を適用できます。（詳細を見る） 映画や写真で特定の色味を適用するために使われる**LUT（Look-Up Table）**ファイルを適用できます。.cubeファイルを読み込めば、写真に映画のような色味を加えることができます。\nチェキ風フレーム # 出力結果 チェキモード (iPhone) チェキモード (iPad) 結果（イベント） テキスト設定 (iPhone) テキスト設定 (iPad) 結果（日常） ポラロイド風チェキフレームを自動生成します。（詳細を見る） ポラロイド風チェキフレームを自動生成します。ランダムキャラクターステッカー配置、日付/署名テキスト、枠線設定などをカスタマイズできます。\nチェキ有効化でポラロイド風の下部余白が自動生成されます サイコロでランダムにキャラクターステッカーを画像に配置できます テキスト/署名、フォント、色、位置（TL/TC/TR/BL/BC/BR）を自由に設定できます iOS / Android / Desktop # iOS Android Desktop デスクトップと同じ機能をモバイルでも利用できます。（詳細を見る） App Storeで配布中です。デスクトップと同じ機能をiPhoneで利用できます。\nアーキテクチャの差別なくmacOS、Linux、Windows、FreeBSD、iOS、Android、Web (wasm32) をサポートしています。\nダウンロード # Desktop # macOS (Apple Silicon)\nLoading... Windows (x86_64)\nLoading... Linux\nDebian · Ubuntu · Fedora · Rocky · Arch\u0026#9654;curl -sSf https://raw.githubusercontent.com/pmnxis/chama-optics/master/quick-install-linux.sh | bashターミナルで実行詳細: README_LINUX.md💡 glibc \u0026lt; 2.38: ONNX Runtime 自動ダウングレード FreeBSD\nFreeBSD 13 · 14 · ⚠ 顔認識機能非対応\u0026#9654;fetch -o - https://raw.githubusercontent.com/pmnxis/chama-optics/master/quick-install-freebsd.sh | shターミナルで実行詳細: README_FREEBSD.md Web App (wasm32)\n⚠ 実験的サポート · 一部機能制限あり Mobile # iOS (iPhone / iPad)\nApp Storeで配布中 Android（クローズドテスト）\n2026年3月3日以降、オープンテストに移行予定 🤖 Androidクローズドテストのご案内\n現在Google Playクローズドテスト段階です。参加するにはこちらのフォームにPlay Storeのメールアドレスを登録してください。Google Playテストポリシー（12人以上14日間テスト）達成後、3月3日以降オープンテストに移行し、メール登録なしでどなたでもインストールできるようになります。\n🔒 プライバシーポリシー\n個人情報収集なし · 会員登録/ログインなし · 広告/トラッキングなし · すべての写真処理は端末内で実行 · 顔認識データのサーバー送信なし · オフライン動作\n🌐 アプリ内のインドネシア語（Bahasa Indonesia）翻訳は機械翻訳で提供されており、検収が行われていないため、誤訳が含まれている可能性があります。\n📜 ライセンス · クレジット\n赤井はあとは、COVER株式会社所属 hololive JP 1期生のVTuberです。\n二次創作ガイドライン: カバー二次創作ガイドライン\nChamaOptics（Desktop Core）: MIT / NON-AI-MIT デュアルライセンス · GitHub\nChamaOptics Mobile: クローズドソースライセンス\nアプリアイコン: NON-AI / CC-BY-NC · イラストレーター シエミカ（@shiemika324）によるファンアートであり、使用許可を得たオリジナル作品です。\n※ NON-AIライセンスは本ソフトウェアのソースコードの一部に適用されており、関連リソース（アイコン、イラスト、ドキュメントを含む）をAI（人工知能）による学習、データセット構築、検索、解析、派生生成に利用することを禁止します。\n","date":"2026年2月17日","externalUrl":null,"permalink":"/ja/posts/chama-optics-public-release/","section":"Posts","summary":"Chama Opticsをリリースします。写真好きで旅するVTuber 赤井はあとから着想を得て作った、ミラーレス・一眼レフカメラユーザー向けの写真加工アプリ","title":"Chama Optics リリース","type":"posts"},{"content":"","date":"2026年2月17日","externalUrl":null,"permalink":"/ja/tags/haachama/","section":"Tags","summary":"","title":"HAACHAMA","type":"tags"},{"content":"","date":"2026年2月17日","externalUrl":null,"permalink":"/ja/tags/hololive/","section":"Tags","summary":"","title":"Hololive","type":"tags"},{"content":" 電子技術の専門家である私の猫 Lambdaλ を紹介します。 このブログは主にLinux, Rust, Embedded, 電子回路を扱っており、韓国語と英語の記事が混在しています。時々私の猫 Lambdaλが頻繁に登場するので、気に入っていただけると嬉しいです。ニャー ","date":"2026年2月17日","externalUrl":null,"permalink":"/ja/","section":"Jinwoo Park Blog","summary":" 電子技術の専門家である私の猫 Lambdaλ を紹介します。 ","title":"Jinwoo Park Blog","type":"page"},{"content":"","date":"2026年2月17日","externalUrl":null,"permalink":"/ja/tags/photography/","section":"Tags","summary":"","title":"Photography","type":"tags"},{"content":"","date":"2026年2月17日","externalUrl":null,"permalink":"/ja/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"2026年2月17日","externalUrl":null,"permalink":"/ja/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"施行日: 2026年2月25日\n本ページはGitHub Pagesの自動デプロイにより管理されています。プライバシーポリシーの変更履歴は、GitHubリポジトリのコミット履歴から確認できます。\nChama Optics（以下「本アプリ」）は、Jinwoo Park（以下「開発者」）が開発・運営する写真後処理アプリケーションです。本プライバシーポリシーは、本アプリの使用時にユーザーの個人情報がどのように取り扱われるかについて説明します。\n1. 収集する個人情報 # Chama Opticsは、いかなる個人情報も収集、保存、送信しません。\n本アプリはアカウント作成、会員登録、ログインを必要としません。 氏名、メールアドレス、電話番号、位置情報など、個人を特定できる情報は収集しません。 アプリ使用分析（Analytics）、広告、トラッキングのための情報は収集しません。 デバイス識別子、IPアドレス、Cookieなどは収集しません。 2. アプリの権限およびアクセス目的 # Chama Opticsは、写真後処理機能を提供するために以下のデバイス権限を要求する場合があります。\n権限 目的 データ送信の有無 フォトライブラリへのアクセス ユーザーが選択した写真を読み込み、フレーム・モザイクなどの後処理を適用するため なし（端末内処理） ストレージへのアクセス 処理済みの写真を端末に保存するため なし（端末内保存） 要求される権限は、本アプリの主要機能（写真後処理）のためにのみ使用されます。 カメラ、マイク、連絡先、位置情報などの権限は要求しません。 3. 写真および画像データ # ユーザーが選択した写真は、端末内でのみ処理されます。 写真データは外部サーバーに送信されません。 EXIFデータ（カメラ機種、レンズ、撮影設定など）は撮影情報フレーム生成のために端末内でのみ読み取られ、外部に送信されることはありません。 処理済みの写真はユーザーの端末ストレージに保存され、ユーザーが直接管理（削除など）できます。 4. 顔検出処理 # Chama Opticsは、写真内の顔を自動的に検出し、モザイク（ピクセル化）・ステッカー・枠線などのプライバシー保護エフェクトを適用する機能を提供しています。\n4.1 収集する顔データ # 本アプリは顔バウンディングボックス座標（x位置、y位置、幅、高さ）のみを収集します — 画像内の顔の位置を示す矩形領域です。 顔のランドマーク（目、鼻、口の位置）は収集しません。 顔特徴埋め込みベクトルや生体認証情報は収集しません。 身元情報は収集しません — 本アプリは顔の検出（位置特定）のみを行い、顔の認識（個人の特定）は行いません。 4.2 顔データの使用目的 # 顔バウンディングボックス座標は、ユーザーが選択したプライバシー保護エフェクト（モザイク/ピクセル化、枠線、ステッカーオーバーレイ）を適用するためのみに使用されます。 この機能は、ユーザーがSNSに写真を共有する前に顔を隠すことを支援します。 顔検出結果は個人の特定、プロファイリング、追跡には一切使用されません。 4.3 顔データの保存場所 # すべての顔検出処理は端末内でのみ（オンデバイス）実行されます。 顔バウンディングボックス座標は、ユーザーが編集を再開できるよう、編集セッション状態の一部として端末内にローカル保存されます。 顔データは外部サーバー、クラウドサービス、または第三者に一切送信されません。 4.4 顔データの第三者提供 # 顔データはいかなる第三者にも共有されません。 本アプリには広告SDK、分析SDK、または顔データを送信し得るネットワークコードは含まれていません。 4.5 顔データの保持期間 # 顔バウンディングボックス座標は、該当する画像が本アプリのギャラリーに存在する間のみ端末内にローカル保持されます。 顔データは以下の場合に永久的に削除されます： ユーザーが本アプリのギャラリーから画像を削除した場合、または ユーザーが本アプリをアンインストールした場合。 いかなる時点においてもサーバーに顔データは保持されません。 4.6 プラットフォーム別使用技術 # iOS: Apple Vision Framework（VNDetectFaceRectanglesRequest）— 端末内処理 Android: Google ML Kit Face Detection — 端末内処理、Googleサーバーへのデータ送信なし デスクトップ（macOS/Windows/Linux）: ONNX Runtime + SCRFDモデル — 端末内処理 Androidユーザーへの注記: Google ML Kit Face Detectionは完全にオンデバイスで動作し、顔画像や認識結果がGoogleサーバーに送信されることはありません。詳細はGoogle ML Kit利用規約をご参照ください。\n5. データセキュリティ # 本アプリは個人情報を収集しないため、外部に送信されるユーザーデータはありません。 すべての写真処理はユーザーの端末内で実行され、外部サーバーとの通信は発生しません。 本アプリのコアライブラリはGitHubでオープンソースとして公開されており、透明性を確保しています。 6. データの保持および削除 # Chama Opticsはサーバーにいかなるユーザーデータも保存しません。 顔バウンディングボックス座標は編集セッションの一部としてローカル保存され、ユーザーがアプリから画像を削除するか、アプリをアンインストールすると削除されます（第4.5項参照）。 処理済みの結果画像はユーザーの端末ストレージに保存され、端末のファイル管理機能を通じてユーザーが直接削除できます。 アプリをアンインストールすると、保存された顔座標を含む、アプリに関連するすべてのローカルデータが削除されます。 7. ネットワーク使用 # Chama Opticsは写真処理にインターネット接続を必要としません。 本アプリは基本的にオフラインで動作します。 アプリのアップデート確認など、プラットフォーム（App Store、Google Play）が提供する機能によるネットワーク通信は、該当プラットフォームのポリシーに準じます。 8. 第三者への提供 # Chama Opticsはユーザーのデータを第三者に販売、提供、共有しません。 本アプリには広告SDK、分析SDK、ソーシャルログインSDKなどの第三者サービスは含まれていません。 Android版で使用されるGoogle ML Kitはオンデバイスでのみ動作し、ユーザーデータをGoogleに送信しません。 9. 児童のプライバシー保護 # Chama Opticsは13歳未満の児童を対象としていません。 本アプリはいかなるユーザーからも個人情報を収集しないため、児童に対する別途の収集手続きは存在しません。 10. プライバシーポリシーの変更 # 本ポリシーが変更される場合、変更内容はこのページに掲載され、施行日が更新されます。 重要な変更がある場合、アプリのアップデートまたはGitHubリポジトリを通じてお知らせします。 11. お問い合わせ # 本プライバシーポリシーに関するご質問やご要望がございましたら、以下までご連絡ください。\n開発者: Jinwoo Park GitHub: https://github.com/pmnxis/chama-optics メール: pmnxis@gmail.com ","date":"2026年2月16日","externalUrl":null,"permalink":"/ja/chama-optics-privacy/","section":"Jinwoo Park Blog","summary":"施行日: 2026年2月25日\n本ページはGitHub Pagesの自動デプロイにより管理されています。プライバシーポリシーの変更履歴は、GitHubリポジトリのコミット履歴から確認できます。\n","title":"Chama Optics プライバシーポリシー","type":"page"},{"content":"EXIF ベースの写真フレーム＋顔自動認識アプリ、Rust コアでデスクトップからモバイルまで\nこのブログにオタク全開の記事を堂々と書くのは、おそらく今回が初めてだと思います。 正直、この記事を書き始めてからかなり経つのですが、読者を開発者に向けるべきかVTuberオタクに向けるべきか掴めませんでした。 結局、意識の流れに任せて開発・貢献してきたことを並べていくことにしました。\nそこで、このブログでは主にRust Embeddedを扱っており、以前 billmock-app-rs というRust Embedded量産プロジェクトを手がけたことがあります。\nこの記事では Chama Optics の開発過程を紹介します。\n2026年2月最終週に 0.2.0 で iOS / Android / macOS / Linux / Windows の正式リリースを予定しており、App Store・Google Play 承認前の開発過程を記述しています。\n🌐 한국어 아티클 | English Article\nアプリ紹介およびリリースノートはこちらからご覧いただけます。\nプロジェクト紹介 # Chama Optics は、DSLR/ミラーレスカメラで撮影した写真のEXIFデータを解析し、さまざまなテーマフレームを適用して、ウォーターマーク・モザイク・ステッカーなどのエフェクトを追加できる写真加工プログラムです。「Chama」という名前は、旅系VTuber Akai Haato（赤井はあと）のニックネームに由来しています。\n数多くのモバイル端末を使ってきましたが、自分の関心はいつも電子機器を作る側にあり、スマホアプリ開発とは縁遠かったです。そんな自分がHololive JP 1期生の赤井はあと（HAACHAMA）のファンとしてオタク生活をする中で、組み込みではないソフトウェア開発領域で初めてのプロジェクトを始めることになりました。\nこのプログラムを最初に構想したのは2025年3月からです。 当時はWebアプリとして動作させたいと考えており、ライブラリのテスト、WASM環境のテスト、libheifのポーティングなどを進めていました。 2025年8月、東京での天音かなたソロライブ LOCK-ON と、米国ニューヨークでのAnimeNYC World Tour + EN Concert（All for one）に行った後、写真を素早く整理してWEBPに圧縮して投稿する必要性を痛感しました。 同時に赤井はあとも最近写真を撮ることが好きで、メンバーシップ限定投稿で自分のカメラを見せたり、推し活はあとん日記（#推し活はあとん日記）で写真投稿を促していたので、はあと（HAACHAMA）の名前でアプリを一つ開発してあげたかったです。\n最近の3D Live Akai Haato X(twitter) /／ 📢 本日２１：００から‼️\n\\＼\n赤井はあと生誕3D LIVE開催!!🎊\n🎁テーマはホラー⁉️\n🎁ゲスト多数\u0026amp;告知あり◎\n🎁演出はこだわり満天🥳\nダンスや歌も精一杯がんばったので\nみんな是非！見に来てねっ❕👀✨#赤井はあと爆誕祭2025\n【開催場所】https://t.co/3IUA2stYWi… pic.twitter.com/A1OqUBCbsM\n\u0026mdash; 赤井はあと❤️‍🔥旅するアイドル (@akaihaato) August 9, 2025 四万温泉ステキな場所でした。\nぐんまー帝国、ありがとん❤️‍🔥 pic.twitter.com/Ov0CwFRF7V\n\u0026mdash; 赤井はあと❤️‍🔥旅するアイドル (@akaihaato) April 26, 2025 プログラムを開発する際には、以下の鉄則に従いました。\nデスクトップ環境においていかなるアーキテクチャ差別があってはならない。 MSやAppleの開発エコシステムに最小限しか縛られないこと。 リソースを多く使ってはならず、高速でなければならない。 目標は大層なもののように見えますが、単に自分がRustマニアだからこうなっただけです。\n始まり：EXIFフレームをもっと手軽に # 最初から大掛かりなクロスプラットフォームアプリを計画していたわけではありませんでした。\nカメラ好きの間では、写真を投稿する際にEXIF情報をもとにカメラ機種名、レンズ、シャッタースピードなどをフレームに入れて共有する文化があります。自分もこの方法を愛用しており、既存の exif-frame というWeb上のツールを参考にしていました。しかしHEIFフォーマットに対応していない点や高解像度画像出力に制限がある点が惜しく、自分で作ろうという考えからChama Opticsが始まりました。\n最初はデスクトップだけを想定していました。モバイルへの漠然としたイメージはありましたが、旅先でもいつもMacBookを持ち歩いていたのでモバイルは全く念頭にありませんでした。カメラからSDカードを抜き、MacBookで写真を整理し、フレームをかぶせてアップロードする――そのワークフローが当たり前だったからです。\n方向転換：「会場でMacBookは開けないだろ」 # 方向が変わったのには二つのきっかけがありました。\nイベント文化の違い ―― AnimeNYCで感じたこと # 2025年8月、AnimeNYC と Hololive World Tour / EN Concert のために米国を訪れました。その時面白い違いに気づきました。米国ではイベント会場で撮った写真を投稿する際、他人の顔をモザイクしない傾向が強かったです。しかし韓国や日本のイベントでは、他人の顔を必ずモザイク処理するのがマナーであり暗黙のルールでした。\n「他人の顔のモザイク」は毎回手作業でやるにはあまりにも面倒な作業です。特に写真が数十枚、数百枚になればなおさらです。顔の自動認識＋モザイク/ステッカー機能が必要だという思いがこの時から強くなりました。\n間もなく開催のホロライブエキスポ # もう一つの動機は 2026年3月のホロライブエキスポ/フェスティバル でした。会場ですぐ写真を撮り、その場でフレームをかぶせ、モザイクまで処理してSNSに上げられたら？　でも会場でMacBookは開けません。スマートフォンですぐ処理できなければなりませんでした。\n周囲からのリクエスト # さらに周囲から iOS版開発へのリクエスト が加わりました。そこでiOS版を開発し始めたら、今度は Android版へのリクエスト も来ました。\nこうしてデスクトップ専用だったプログラムがiOS、さらにAndroidまでサポートする方向へ拡張されました。モバイルではミラーレスカメラユーザーよりも一般ユーザーの体験をより重視する設計方針としました。EXIFフレームという出発点はそのままですが、「イベント現場で素早く写真を処理して共有する」という新しいユースケースが加わったわけです。\nアーキテクチャ：デスクトップからモバイルへ # 最初はRust + eguiでデスクトップアプリだけを作るつもりでした。だからコアロジックをすべてRustで書いたことが、結果的に良い選択となりました。iOS/Androidへ拡張する際に、画像処理、EXIFパース、テーマレンダリング、エンコード/デコードといったコアコードをそのまま再利用できたからです。\nデスクトップではRustコアを直接リンクして使い、iOSでは C FFIを通じてSwiftから呼び出し、Androidでは JNA（Java Native Access）を通じてKotlinから呼び出す 構造です。Rustコアはgit submoduleで管理され、EXIF解析、画像オーバーレイ（テキスト、EXIF、余白、スケーリング、エンコード/デコード）といったコア機能をすべてのプラットフォームで共有します。\nただし、顔認識だけはプラットフォームごとに異なる戦略を使います。\nデスクトップ（macOS/Windows/Linux）: ONNX Runtime + InsightFace（SCRFD det_10g）モデル。Speed Modeに応じて640×640固定入力サイズのスライディングウィンドウを多段階（2560/1280/640）に適用して小さな顔まで検出し、NMSで重複を除去するパイプライン iOS: Apple Vision Frameworkをネイティブで使用。ONNXモデルなしでも高速・高精度で、プライバシー面でも有利 Android: Google ML Kit（com.google.mlkit:face-detection）を活用 ―― Googleが提供するオンデバイス顔認識ライブラリ、Rustコアのspeed_modeをFAST/ACCURATEパフォーマンスモードにマッピング Web版を断念した理由 # 自分はWeb Appやブラウザの動作の仕組みに詳しくありません。それでもChama Opticsは当初、Web（WASM）での動作を念頭に置いていました。 eguiがWASMをサポートしているから「デスクトップとWebが同時にいけるだろう」という漠然とした期待がありました。しかし次の二つの機能を実装しようとして断念しました。\nHEIFデコード egui WebでのDrag \u0026amp; Drop HEIF：WASMの上にWASM、その間にJS # libheifをブラウザで動かすのが難しいこと以前に、根本的な構造が腑に落ちませんでした。libheifはすでにWASMにコンパイルされた状態で、eguiアプリもWASMです。この二つの間の通信をJavaScriptを介したFFIで何度も経由しなければならないということが理解できませんでした。ほとんどの言語間FFIはCベースで行うのに対し、なぜJSエコシステムではこうしなければならないのか理解できませんでした。\nDrag \u0026amp; Drop：デスクトップ開発者の期待と現実 # Drag \u0026amp; Drop以外にも、WASMがブラウザからイベントを受け取る際にJSではなくDOMをバイナリ形態で受け取るとか、もっと従来のデスクトップ/組み込み開発で使われるような方法が提供されると思っていましたが、そうではありませんでした。\n正直、CとRustしか使えない # 自分はCとRustしか使えません。　つまり、Web開発そのものに対して非常に無知であるか、過去にやったとしても変な方法で開発していました。\n以前、大量のデータをWebに並べる必要があったとき、どうすればいいか分からず、データをCSVにして , と \\n を \u0026lt;div\u0026gt; などのHTMLタグに置き換えるのをhexエディタで一括置換してstatic webを作りデプロイしたことがあります。21世紀が25%も過ぎた現代のプログラム開発において、自分でも「これは何だ」と思いました。\nもちろんWASMはWebなので、Webエコシステムと開発者のやり方に従うのが一般的でしょう。しかし自分はWeb開発者ではないため理解できませんでした。自分はJS/Webエコシステムとはかけ離れた存在で、こうした開発環境自体の方向性の違いを克服するよりも、ネイティブモバイルアプリを作る方がよほど自然でした。v0.1.9-betaで正式にWASMサポートを削除し、そのエネルギーをiOS/Androidネイティブに注ぐことにしました。\nタイムラインで見る開発の旅 # v0.1.0~v0.1.1 (2025-10-19~21) ―― 初のプレリリース # macOS/Windowsバイナリ初配布。Filmテーマフレーム、日本語翻訳、一括保存、ファイル名プレフィックス/サフィックス設定。macOSコード署名DMG配布および日/英/韓インストールガイドWiki作成。\nv0.1.2~v0.1.6 (2025-10-27~11-24) ―― テーマ拡張とウォーターマーク # Film Date テーマ Strap テーマ Monitor テーマ Lightroom テーマ Film Date/Film Glow/Just Frame/Strap/Monitor/Lightroom テーマ追加。ウォーターマーク（9箇所の位置、透明度、ブレンドモード）、フォント選択（内蔵＋OSフォント）、内蔵カメラメーカーロゴ自動適用、HEIF方向修正、可変フォント初期サポート、Longsideスケールオプション。\nv0.1.7 (2025-11-26~12-19) ―― CJKレンダリング改善とオープンソース貢献 # One Line テーマ Shot On Two Line テーマ Nikon PhotoStyle Lumix Photo Style + LUT One Line/Two Line/Shot Onテーマ。CJKグリフレンダリングの大幅改善およびSourceHanSans fallback内蔵。Lumix LUT名・Nikon PhotoStyle名をEXIFから抽出するため exif-rs にPRを提出し先行反映。\nv0.1.8 (2025-12-25~27) ―― UIリニューアルとパフォーマンス改善 # 画像リストタブ テーマ設定タブ タブベースインターフェースへの切り替え（4タブ）、EXIF変数オートコンプリート、画像自動グループ化、2MP MPFプレビューベースのテーマプレビュー、Rayonマルチコア並列処理、システムフォント読み込みメモリ問題の修正。egui にもPRを提出。\nv0.1.9 (2026-01-18~02-04) ―― 顔認識、LUT、iOS初配布 # 顔認識（デスクトップ） モザイク適用 色調補正UI LUT適用結果 iOS ギャラリー iOS 編集 デスクトップ単独リリースの最終版であり、iOSアプリ初配布バージョンです。ONNX（InsightFace）顔検出＋モザイク/ストローク/ステッカーオーバーレイ。1D/3D LUT色調補正（wagahai-lut）。iOSはSwiftUI + Vision Frameworkネイティブ顔認識、Rust FFIブリッジ（ffi_ios.rs + RustBridge.swift）。インドネシア語翻訳追加。\n技術的チャレンジと解決策 # プロジェクト全般にわたって適用されたパフォーマンス戦略をまず整理すると以下の通りです。\nRayon並列処理 ―― 大量画像の一括エクスポート時にマルチコアを活用。ただし、色補正などピクセル単位の処理では10万ピクセル以上の場合のみ par_chunks_exact_mut() で並列化し、小さい画像はコンテキストスイッチのオーバーヘッドを避けるため逐次処理します。 fast_image_resize ベースのリサイズ ―― image クレートのデフォルトリサイズの代わりにSIMD最適化された fast_image_resize を使用し、サムネイル生成やプレビューリサイズの速度を大幅に改善 Lazyロードとキャッシュ ―― LUTファイルは lut_cache: HashMap\u0026lt;Uuid, CubeLut\u0026gt; に初回使用時にパースしてキャッシュし、EXIFサムネイルも thumbnail_cache に遅延ロードします。バックグラウンドスレッド用の複製（clone_for_thread()）時にはキャッシュを除外し、不要なメモリ複製を防止します。 パーセプチュアルハッシュベースの画像グループ化 ―― 画像ロード時に8×8グレースケール平均ハッシュ（64-bit）を事前計算し、その後の類似画像グループ化をハミング距離O(1)比較で実行。元画像を再ロードせずメタデータだけでグループ化します。 ビルドプロファイル最適化 ―― Releaseビルドで opt-level = 3、lto = \u0026quot;fat\u0026quot;、codegen-units = 1 を適用し、Devビルドでも fast_image_resize、mozjpeg、ab_glyph などパフォーマンスに敏感な依存関係は opt-level = 3 で個別設定して、デバッグ中でも画像処理パフォーマンスを維持します。 1. クロスプラットフォームFFIの複雑さ # Rustコアを3つのプラットフォーム（デスクトップ/iOS/Android）で使うために、それぞれ異なるFFI戦略を採用しました。\nプラットフォーム FFI方式 特徴 デスクトップ (egui) 直接リンク Rust → Rust、FFI不要 iOS (SwiftUI) C FFI (@_silgen_name) SwiftからC関数を直接呼び出し Android (Compose) JNA (Java Native Access) KotlinからJNA経由で.soを呼び出し このブリッジレイヤーをメンテナンスしつつも安定したメモリ管理（文字列の割り当て/解放、不透明ポインタハンドルパターン）を保証することが主な課題でした。\n2. EXIFパースの尽きない変数 # カメラごとにEXIFの記録方式が異なります。\nシャッタースピード/F値の浮動小数点問題 ―― 1/125秒が 0.008000000 のような汚い値で記録される場合の自動補正 HEIF/HEIC方向情報の誤り ―― 一部の画像で方向がずれる問題 レンズ情報のないカメラ ―― Nikon Coolpixのようなコンパクトカメラへの対応 MakerNoteに隠された情報 ―― Lumix LUT名、Nikon PhotoStyle、Sony Creative Lookなどメーカー別非公開EXIFフィールドのパース これらのために exif-rs ライブラリに直接PRを送り、必要な機能を追加しました。\n3. MakerNoteパース：メーカー別撮影設定の抽出 # 最近のミラーレスカメラは独自の色味を合わせる機能が非常に優れています。LumixのPhoto Style、NikonのPicture Control、SonyのCreative Lookなどがそれです。写真家の間では「どの色味設定で撮ったか」がカメラ機種やレンズと同じくらい重要な情報であり、この情報をフレームに一緒に入れられたらいいなと思いました。\nEXIF標準の MakerNote（Tag 0x927C）は、カメラメーカーが自由に使える非標準領域です。フォーマットはメーカーごとに、さらには同じメーカーのモデルごとに異なり、ドキュメントも乏しいです。しかしここには**「どの色味設定で撮ったか」**のような、写真家にとって重要な情報が隠れています。\nChama Opticsでは exif.maker_note_vendor() でメーカーを先に識別し、各メーカー専用パーサーに分岐します。\nNikon ―― PictureControlData / PictureControlData2 タグからPicture Control名を抽出します。\u0026quot;VitalityFilm_Pmango\u0026quot; のようなユーザー定義プロファイル名や、\u0026quot;Flat\u0026quot;、\u0026quot;Vivid\u0026quot; のようなプリセット名がここに格納されています。\nPanasonic (Lumix) ―― 最も豊富なデータを提供します。PhotoStyleName から基本のPhoto Style名（\u0026quot;NostalgicKintex\u0026quot;）を、LutPrimaryFile/LutSecondaryFile から適用されたLUTファイル名（\u0026quot;KintexYellow33.CUBE\u0026quot;）とGain値まで抽出します。この情報はChama OpticsのLUT色調補正機能と直接連携します。\nSony ―― Sony_0x9416 タグからCreative Style/Creative Look情報（\u0026quot;Vivid\u0026quot;、\u0026quot;Standard\u0026quot;、\u0026quot;Portrait\u0026quot; など）を抽出します。\nこのMakerNoteパース機能は既存のexif-rsになかったため、直接実装して PR #57 として提出しました。\nEXIF IFDエントリ構造とMakerNoteのoffset問題 # MakerNoteをパースするには、まずEXIFのIFD（Image File Directory）構造を理解する必要があります。EXIFデータはTIFFフォーマットを基盤としており、各IFDエントリはちょうど 12バイト で構成されます。\nTag（2バイト） ―― フィールド識別子（例：0x927C = MakerNote） Type（2バイト） ―― データ型 Count（4バイト） ―― 値の個数 Value/Offset（4バイト） ―― データが4バイト以下なら値そのもの、超過ならデータ位置を指すoffset 標準EXIFではこのoffsetは TIFFヘッダー開始点からの距離 です。シンプルで明快です。ところがMakerNote内部のIFDではこのルールが崩れます。\n問題はこれです：MakerNote内部にもIFDと同一構造のエントリが存在しますが、ここでのoffsetが「どこを基準にした距離か」がメーカーごとに異なります。\nTIFF-Relative方式（Panasonic、Canon、Sony、Leica、Sigma） ―― MakerNote内のoffsetが元のTIFFヘッダー開始点基準。MakerNote自体にTIFFヘッダーがなく、offsetから tiff_offset（TIFFスタートからMakerNoteまでの距離）を引くことで実際のデータ位置を見つけられます。 MakerNote-Relative方式（Nikon、Olympus、Fujifilm、Samsung、Apple、Pentax） ―― MakerNote内のoffsetがMakerNote開始点基準。自己完結型の構造（self-contained）であり、Nikonの場合はMakerNote内に独自のTIFFヘッダーまで持っています。 さらにバイトオーダー（エンディアン）もメーカーごとに異なります。Nikonは独自TIFFヘッダーから、Olympus/Appleはプロプライエタリヘッダー内の \u0026quot;II\u0026quot;/\u0026quot;MM\u0026quot; バイトから、SamsungはIFDタグ番号のパターンで自動判別します。\n結局、10メーカー（Panasonic、Nikon、Sony、Canon、Olympus、Fujifilm、Samsung、Apple、Sigma、Pentax）それぞれのヘッダーフォーマット、offset補正式、バイトオーダー判別ロジックを実装し、合計23ファイル約5,900行のPRとなりました。\n4. カメラメーカーロゴシステム：CSV → build.rs → バイナリ埋め込み # Strapテーマ、Filmテーマなどで写真フレームにカメラメーカーのロゴを自動挿入するには、二つのことが必要です。(1) EXIFからメーカーを認識すること、(2) 該当メーカーのSVGロゴをレンダリングすること。\nコンパイルタイム：CSVからSVGダウンロード＆埋め込み # 以前のRust Embedded量産プロジェクトで const fn/const impl でコンパイルタイムに最大限任せるアプローチ と build.rs を活用したビルドスクリプト手法 を扱ったことがあります。Chama Opticsのロゴシステムはこの経験の延長線上で build.rs + include_bytes!() を積極活用しています。\nassets/logo_mnf.csv に35メーカーのロゴ情報が定義されています。cargo build が実行されると build.rs がこのCSVを読み取り、以下を実行します。\nSVGダウンロード ―― 各行の url カラムからSVGを取得します。Wikimedia Commons URLならHTTPでダウンロードし、ローカルパス（assets/logo_mnf/contax.svg）なら直接読み込みます。ネットワーク失敗時は最大3回、5秒間隔でリトライします。 MD5ハッシュ検証 ―― ダウンロードしたファイルのMD5ハッシュをCSVの expected_md5 値と比較します。ファイルがすでに存在しハッシュが一致すれば再ダウンロードをスキップします。 ハッシュが不一致なら panic! でビルドを中断します ―― Wikimedia側でSVGが変更された場合は意図的に確認する必要があるためです。 Rustコード生成 ―― assets/auto_generated/logo_assets.rs を生成し、各SVGを include_bytes!() でバイナリに埋め込みます。ランタイムでのファイルロードは不要です。 // 自動生成されるコード例 pub const LOGO_ASSETS: \u0026amp;[ArtAsset] = \u0026amp;[ ArtAsset { key: \u0026#34;canon.svg\u0026#34;, data: include_bytes!(\u0026#34;.../assets/download/canon.svg\u0026#34;), color_type: ColorType::Color, mnf: \u0026#34;canon\u0026#34;, model: \u0026#34;\u0026#34;, mnf_model_rel: MnfRelation::Any, }, // ... 35メーカー ]; ランタイム：EXIF → ロゴマッチング → SVGラスタライズ # 写真がロードされるとEXIFの Tag::Make（メーカー）と Tag::Model（モデル名）を抽出し、LOGO_ASSETS 配列を巡回してマッチングします。\nマッチングルールは二つです。\nMnfRelation::Any ―― メーカー名またはモデル名のどちらか一方が一致すればよい（ほとんどの場合） MnfRelation::Both ―― メーカー名かつモデル名の両方が一致しなければならない（特殊なケース） Both が必要な実例：Sigma は2025年にロゴを変更しました。新ロゴを使うカメラは SIGMA BF モデルのみなので、CSVに mnf=\u0026quot;sigma\u0026quot;, model=\u0026quot;sigma bf\u0026quot;, mnf_model_rel=Both で sigma2025.svg（新ロゴ）を登録し、残りのSigmaカメラは mnf=\u0026quot;sigma\u0026quot;, mnf_model_rel=Any で sigma.svg（旧ロゴ）を使うように分離しました。\nマッチングされたSVGは usvg でパース後 resvg+tiny-skia でラスタライズし、フレーム内の適切な位置とサイズで合成されます。color_type（Black/Color）と fill_ops（Default/Monochrome）に応じてレンダリング方式が変わり、背景色に合ったロゴ表現が可能です。\n5. CJKフォントレンダリングと可変フォント（Variable Font）最適化 # 日本語・韓国語・中国語テキストを画像にレンダリングする際、多くの問題が発生しました。\n一部のCJK漢字（ideograph）がレンダリングされない問題 可変フォントでグリフ幅が合わない問題 解決策として SourceHanSansをビルトインfallbackフォント として内蔵し、選択したフォントでサポートされないグリフを自動で代替レンダリングするようにしました。具体的にはテキストを文字単位で巡回し、主フォントで GlyphId(0)（グリフなし）が返された場合、SourceHanSans fallbackフォントに切り替えてレンダリングします。\n可変フォント weight リマッピング # Chama Opticsで使用する主フォント BarlowGX.ttf は可変フォント（Variable Font）ですが、内部のweight軸値が 22~188 という非標準範囲を使用していました。CSS標準やFreeTypeなどで使われる 100~900 の範囲と合わないため、ab_glyph で set_variation(b\u0026quot;wght\u0026quot;, 400.0) でRegular weightを指定しても意図した結果になりませんでした。さらにデフォルトのwidthがwdth=300（Condensed）に設定されておりグリフ幅も合いませんでした。\n単に fvar（Font Variationsメタデータ）だけ修正すればいいと思いましたが、実際のグリフ幅を保持する hmtx テーブルは依然としてCondensed基準でした。メタデータだけ変えてもレンダリング結果は変わりません。 結局BarlowGX.ttfから9つのweightインスタンスをwdth=500（Regular width）で抽出し、これをマスターソースとして fontTools.varLib.build() で可変フォントを丸ごとリビルドして解決しました。成果物が Barlow-Variable-Remapped.ttf と Barlow-Variable-Remapped-Narrow.ttf です。\n複数のフォントファイルを一つに統合 ―― ファイルサイズの絶対的な削減 # 可変フォントのもう一つの利点は、複数のweightファイルを一つにまとめられることです。従来Barlow-Thin.ttf、Barlow-Light.ttf、Barlow-Regular.ttf、Barlow-Bold.ttf、Barlow-Black.ttfなど9つ以上の静的フォントファイルが必要だったものを、可変フォント一つで置き換えられます。\nCJKフォントも同様です。SourceHanSans（日中韓文字に最適な選択）は元々weight別に別ファイルが提供されますが、可変フォント版（SourceHanSansVF）を使えば一つのファイルで200~800範囲のweightをすべてカバーします。ただしこのフォントもBarlowGXと同じ問題があり、weight軸を標準範囲にリマッピングして SourceHanSansVF-remapped.otf を生成しました。\nさらに fontTools を活用して、異なる文字集合を持つフォントを一つに統合する作業も行いました。ラテン文字フォント＋日本語フォント＋韓国語フォントを合わせて一つのファイルにでき、WOFF2解凍、TTC（Font Collection）処理、特定weightのインスタンス抽出、UTF-8ベースの文字サブセッティングなどを組み合わせて最終ファイルサイズを最小化しました。\n最終的にChama Opticsに内蔵されるフォントファイルは：\nフォント 静的フォント時の容量 可変フォント容量 削減 Barlow-Variable-Remapped.ttf (100~900) ~1.35 MB (9 weight) 385 KB ~3.5x Barlow-Variable-Remapped-Narrow.ttf (100~900) ~1.45 MB (9 weight) 207 KB ~7x SourceHanSansVF-remapped.otf (200~800) ~105 MB (7 weight) 30 MB ~3.5x DejaVuSansMono.ttf (静的) — 327 KB — digital-7.ttf (静的) — 34 KB — 合計 ~108 MB ~31 MB ~3.5x Barlowの場合が特に劇的です。元のBarlowプロジェクトには 9 weight × 3 width × 2 (upright+italic) = 54個の静的TTFファイルがあり合計 8.5 MB ですが、Chama Opticsで必要な normal + narrow の2つの可変フォントは合わせて 592 KB に過ぎません。モバイルアプリのバンドルサイズに敏感な環境ではこの差は決定的です。\neguiでの可変フォント weightセレクティブロード # デスクトップ版（egui）では可変フォントのweightをユーザーが自由に調整できます。核心は ab_glyph クレートの set_variation APIです。\npub struct VariableFontPack { pub label: \u0026amp;\u0026#39;static str, pub font: ab_glyph::FontRef\u0026lt;\u0026#39;static\u0026gt;, pub default: u16, // デフォルトweight（例：300） pub start: u16, // 最小weight（例：100） pub end_include: u16, // 最大weight（例：900） } impl VariableFontPack { pub fn get_font_by_weight(\u0026amp;self, weight: u16) -\u0026gt; ab_glyph::FontArc { let clamped = weight.clamp(self.start, self.end_include); let mut font = self.font.clone(); font.set_variation(b\u0026#34;wght\u0026#34;, clamped as f32); font.into() } } ユーザーがテーマ設定でweightスライダーを調整すると、そのweight値で set_variation(b\u0026quot;wght\u0026quot;, weight) を呼び出してランタイムでフォントの太さが変更されます。100（Thin）から900（Black）まで連続的な値を指定でき、350や450のような中間値も補間（interpolation）されてスムーズなweight遷移が可能です。\nこのロジックはデスクトップだけでなくiOS/Androidでも同様に動作します。iOSでは FontSelectionView で可変フォントの場合のみweightスライダーを表示し、選択されたweight値をFFI経由でRustコアに渡します。AndroidでもKotlinから fontWeight パラメータでRust FFIに渡す同一の構造です。\nCJK fallbackもweightを反映します。主フォントがBarlow weight 700（Bold）でCJK文字が出現した場合、SourceHanSansも700に近いweightでレンダリングし、ラテン文字とCJK文字の太さが一貫して見えるようにしました。\nビルトインフォントとシステムフォント # Chama Opticsで使用するフォントは二種類に分かれます。ビルトイン（builtin）フォントとシステム（OS）フォントです。\nビルトインフォントはアプリにデフォルト内蔵されるフォントで、Barlow（ラテン）、SourceHanSans（CJK fallback）、D2Coding（モノスペース）、Digital-7（セグメントディスプレイスタイル）などがあります。システムフォントはユーザーのOSにインストールされたフォントを取得してテーマに適用できるようにする機能です。EXIFフレームに表示されるテキストのフォントをユーザーが自由に選択できる必要があるため、ビルトインフォントだけでは不十分です。\nデスクトップでは include_bytes! でフォントをバイナリに内蔵します。\npub(crate) const FONT_BARLOW: BuiltInFonts = BuiltInFonts { name: \u0026#34;Barlow\u0026#34;, data: include_bytes!(\u0026#34;../../assets/fonts/Barlow-Variable-Remapped.ttf\u0026#34;), }; デスクトップは実行ファイル一つで配布するのが便利なため、フォントファイルをコンパイル時にバイナリに含めます。別途のフォントディレクトリなしに実行ファイルだけですぐ動作します。\n一方、iOS/Androidではフォントをファイルパスで動的ロードします。モバイルアプリはバイナリサイズに敏感で、アプリバンドル内にリソースファイルとして分離するのがプラットフォームの慣例でもあります。Swift/KotlinからFFI経由でフォントディレクトリパスをRustコアに渡すと、Rust側で std::fs::read() で必要なタイミングにファイルを読み込んでロードします。\nシステムフォントはデスクトップでのみサポートします。font-kit クレートの SystemSource を使用してOSにインストールされたフォント一覧を列挙し、ユーザーが選択したフォントをロードします。この処理はUIをブロックしないようバックグラウンドスレッドで実行し、Arc\u0026lt;RwLock\u0026lt;Vec\u0026lt;SystemFont\u0026gt;\u0026gt;\u0026gt; でスレッドセーフに共有します。\nfont-kit macOS メモリ暴走のデバッグ # システムフォント列挙を実装した後、macOSで深刻な問題が発生しました。アプリ起動直後にメモリ使用量が1.0GB、ピーク1.5GBまで跳ね上がる現象でした。（#5）\nMallocStackLogging と malloc_history で追跡した結果、原因は font-kit のmacOSバックエンド（core_text）にありました。font_kit::SystemSource::all_fonts() がシステムフォント一覧を列挙する際、各フォントのファイルデータ全体をメモリに読み込んでいました：\n435 calls for 2045941700 bytes: ← 約2GB font_kit::sources::core_text::create_handles_from_core_text_collection font_kit::utils::slurp_file ← フォントファイル全体をメモリに読み込み alloc::raw_vec::RawVecInner::try_allocate_in macOSには数百のシステムフォントがインストールされており、CJKフォント（例：Apple SD Gothic Neo、Hiraginoなど）は個別ファイルが数十MBに達します。slurp_file がこれらのファイルをすべてメモリに載せ、435フォントに対して約2GBを割り当てたのです。（Windowsでは同じコードで約90MB程度でした。）\n解決方法は font-kit をフォークして all_fonts() 呼び出し時にフォントデータを読まずメタデータ（名前、パス）のみ収集するよう修正することでした。修正後、メモリ使用量は 144.9MB（ピーク389.4MB）に大幅削減されました。\n6. LUT色調補正：wagahai-lutの最適化哲学 # ライブラリ名の由来は wagahaida_L（ラプラス・ダークネス） のツイートから取りました。\nLaplusDarknesss wagahaida_L pic.twitter.com/dKCBGYJobj\n\u0026mdash; ラプラス・ダークネス🛸💜 (@LaplusDarknesss) July 1, 2025 https://t.co/WjplefTDWX pic.twitter.com/8L19fSqYBg\n\u0026mdash; ラプ様 (@wagahaida_L) November 24, 2025 余談ですが、v0.2.0で準備中のチェキ風（ポラロイド）画像自動生成機能もラプラス・ダークネスからアイデアを得ました。妖しく頭がいいと思います。\nv0.1.9で追加されたLUT色調補正機能は、自作の wagahai-lut（crates.io）ライブラリを使用します。\nCUBE LUTとは？ # CUBE LUT（Look-Up Table）は Adobeが定義した .cube ファイルフォーマット で、色変換情報を格納しています。1D LUTと3D LUTの2種類があります。\n1D LUT はR、G、B各チャンネルを独立して変換します。入力値をテーブルから探して出力値に置き換える単純な構造です。明るさ/コントラスト調整に適していますが、チャンネル間の相互作用（例：赤を青に変えること）は不可能です。テーブルサイズは通常1,024（10-bit）から65,536（16-bit）エントリで、隣接する2エントリ間の値は線形補間（linear interpolation）で計算します。\n3D LUT はRGB 3次元色空間全体をマッピングします。入力 (R, G, B) がまったく異なる (R\u0026rsquo;, G\u0026rsquo;, B\u0026rsquo;) に変換されうるため、映画/写真のクリエイティブな色味補正（film look、color grading）に使われます。キューブ内部の格子点（lattice point）が既知のマッピングを定義し、格子点間の値は周囲8つの頂点から三線形補間（trilinear interpolation）で計算します。一般的なサイズは17³（4,913点）、33³（35,937点）、65³（274,625点）です。\nwagahai-lutの最適化戦略 # 既存のRust LUTライブラリは汎用性に重点を置いていました。wagahai-lutは「24MP写真数十枚を一括処理しても速くなければならない」というChama Opticsの要件に合わせ、メモリレイアウトからSIMDレベルまで最適化しました。ただしx86_64とARM64の両方をサポートする必要があるため、直接アセンブリを書く代わりに wide クレートを使用して、アーキテクチャに依存しない汎用的なベクトル最適化を選択しました。\n1) Structure of Arrays (SoA) メモリレイアウト\n一般的な3D LUT実装は [Rgb, Rgb, Rgb, ...] 形式のAoS（Array of Structures）レイアウトを使用します。しかし三線形補間は一度に1チャンネルずつ8頂点の値を読む必要があるため、AoSではキャッシュラインに不要なチャンネルデータが一緒にロードされます。\nwagahai-lutは3D LUTを r: Vec\u0026lt;f32\u0026gt;、g: Vec\u0026lt;f32\u0026gt;、b: Vec\u0026lt;f32\u0026gt; の3つの分離された配列で格納します。このSoAレイアウトのおかげで、1チャンネルの補間に必要な8つの値がメモリ上で近くに位置し、CPUキャッシュヒット率が向上します。\n2) SIMD並列処理 (wide::f32x4)\n1D LUT処理では wide クレートの f32x4 SIMDベクトルを使用し、R、G、B 3チャンネルの線形補間を単一ベクトル演算で実行します。4レーンのうち3つをR、G、Bに割り当て、乗算・加算が1命令で処理されます。\n3) 固定サイズ特殊化（Fixed-Size Specialization）\n1D LUTは Bit10(1024)、Bit12(4096)、Bit14(16384)、Bit16(65536) などの一般的なサイズに対して Box\u0026lt;[Rgb; SIZE]\u0026gt; 固定サイズ配列を使用します。コンパイルタイムにサイズが確定するため、境界チェック（bounds checking）をスキップして get_unchecked() で直接アクセスが可能です。3D LUTも17³、33³、65³のような一般的なサイズを別タイプで提供します。\n4) In-Place処理とループ最適化\napply_rgb_mut() / apply_rgba_mut() 関数は画像バッファをその場で（in-place）修正し、追加メモリ割り当てが一切ありません。ホットループではドメイン範囲の逆数（inv_domain_range）をループ外で事前計算し、生ポインタ（raw pointer）演算で get_pixel()/put_pixel() 呼び出しのオーバーヘッドを除去し、バイトスライスを線形に巡回してCPUキャッシュプリフェッチを最大化します。\nベンチマーク結果 # M4 Max（Stable Rust）基準の処理時間（JPEGデコード/エンコード時間含む）：\n解像度 1D LUT 3D LUT 1920×1080 (FHD) 14.39 ms 19.40 ms 6000×4000 (24MP) 159.91 ms 223.15 ms 8144×5424 (44MP) 294.34 ms 417.09 ms 24MP写真基準で3D LUT適用が約0.22秒であり、Chama Opticsで数十枚の写真を一括処理する際にRayon並列化と組み合わせれば実用的な速度を達成できます。\n7. デスクトップ顔認識：Speed Modeとスライディングウィンドウアルゴリズム # デスクトップではONNX Runtime + InsightFace（det_10g）モデルを使用します。このモデルの入力サイズは固定640×640ピクセルです。しかし実際の写真は24MP（6000×4000）以上であることがほとんどで、640×640に画像全体を縮小すると、人物が小さく写った集合写真では顔を見逃してしまいます。\nこの問題を解決するため、Speed Modeに応じた多段階スライディングウィンドウアルゴリズムを実装しました。\nモード max_depth Depth Loopウィンドウサイズ 全体動作 Fastest 0 (なし) 画像全体 → 640×640リサイズ → 単一推論 Fast 1 (なし、depth loop未実行) + 短辺（min(W,H)）サイズのスライディングウィンドウ Normal 1 640×640 + 640×640精密ウィンドウ Slow 2 1280×1280 → 640×640 + 1280→640多段階ウィンドウ Slowest 3 2560×2560 → 1280×1280 → 640×640 + 2560→1280→640全多段階ウィンドウ Depth Loopウィンドウサイズの公式: window = 640 × 2^(max_depth - depth - 1)\n例：Slowest(max_depth=3) → depth 0: 2560, depth 1: 1280, depth 2: 640\nアルゴリズムの流れは以下の通りです。\n第1段階（共通）: 画像全体を640×640にリサイズして単一推論。大きな顔はこの段階で捕捉されます。 第2段階（Fast以上）: 画像の短辺（min(width, height)）サイズのスライディングウィンドウを10%オーバーラップで移動させ、各ウィンドウを640×640に縮小して推論。異常なアスペクト比（パノラマなど）での漏れを防止します。 第3段階（Normal以上）: 640 × 2^(max_depth - depth - 1) サイズのウィンドウをdepthごとに巡回。Slowestは2560→1280→640、Slowは1280→640、Normalは640単一depth。 最終: NMS（Non-Maximum Suppression、IoU閾値0.4）で重複検出を除去します。 各Speed Modeの動作を視覚化したダイアグラム（6000×4000元画像基準）：\nFastest # Fast # Normal # Slow # Slowest # 以下はSlowestモードで処理した実際のイベント写真の例です。大規模な集合写真で後列の隅にいる小さな顔まで漏れなく検出してモザイク処理した結果です。\n2025年AGF 天音かなた ファン集合写真会\n各モードの使用シナリオ：\nモード 平均所要時間 適した状況 Fastest ~0.5秒 1~2人のポートレート Fast ~0.6秒 パノラマなど異常アスペクト比の1~2人写真 Normal ~7秒 約10人程度の集合写真 Slow ~13秒 40~50人規模の集合写真 Slowest ~28秒 50人以上の大規模集合写真 Fastestが画像全体を640×640一つに縮小して0.5秒で終わるのに対し、Slowestは2560/1280/640の3段階のウィンドウをオーバーラップさせて探索するため28秒かかります。しかしイベント会場の集合写真で後列の隅の小さな顔まで捕捉するにはこの程度の探索が必要です。\n実行環境（Execution Provider）もプラットフォームごとに最適化されています。\nmacOS: CoreML Execution Provider自動選択 ―― AppleのNeural Engine/GPUアクセラレーション活用 Windows/Linux: CPUまたはOnnxAuto（自動検出） macOSではユーザーがCPUを選択しても内部的にCorMLに自動切り替えされ、Apple SiliconのNeural Engineを活用します。これはCPU比で数倍のパフォーマンス向上をもたらします。\niOSでは、スライディングウィンドウアルゴリズムの構造（Fastest/Fast/ピラミッド深度）はデスクトップと同一ですが、推論エンジンとしてInsightFace ONNXの代わりに**Apple Vision Framework（VNDetectFaceRectanglesRequest）**を使用します。Visionが内部的にスケーリングを処理するため640×640リサイズ手順が不要で、ONNXモデルなしでも正確な顔認識が可能です。\nAndroidでは、Google ML Kit（com.google.mlkit:face-detection）を多段階累積構造で使用します。\nPass 1（全速度）: 全体イメージを最大1024pxでデコード、PERFORMANCE_MODE_FAST、minFaceSize=0.2 Pass 2（Fast以上）: 1024pxビットマップ上でmin(w,h)サイズの正方ウィンドウを10%オーバーラップでスライディング Pass 3+（Normal以上）: ピラミッドマルチレベルデコード ―― base = floor(min(minSide/2, maxSide/3) × 1.1)を基準に、NormalはL0、SlowはL0–L1、SlowestはL0–L2までPERFORMANCE_MODE_ACCURATE、minFaceSize=0.1で探索 全Passの結果をNMS（IoU 0.4）でマージして重複除去 8. iOSネイティブ統合 # iOSアプリは単にRustコアをラップするだけでなく、プラットフォームの利点を最大限に活用しました。\nVision Framework ―― 顔認識をiOSネイティブで処理し、ONNXモデルなしでも高速・高精度な認識 PhotosUI ―― iOS写真ライブラリから直接画像を選択 Metalレンダリング ―― GPUアクセラレーション画像処理 iPadサポート ―― 広い画面に最適化されたレイアウト 9. MPFおよび内蔵プレビュー画像の抽出 # JPEGファイル内に隠されたサブ画像を抽出する機能は、Chama Opticsのパフォーマンスに決定的な役割を果たします。この機能は exif-rs PR #58（+1,364行、PR #57ベース）で実装しました。\nJPEGの中に隠された画像たち # 1つのJPEGファイルの中には実際に複数の画像が入っている可能性があります。\nJPEG内に内蔵された画像は大きく3つのソースから抽出できます。\nEXIF IFD(1) サムネイル ―― 標準EXIFサムネイル（通常160×120） APP2セグメント（MPF） ―― CIPA DC-007 標準で定義されたMulti-Picture Format。メインEOI以降に別の完全なJPEGストリームとして格納される。 MakerNote内部プレビュー ―― メーカー別非標準プレビュー画像 なぜMPFプレビューが重要なのか：メモリとパフォーマンス # 写真一覧でサムネイルを表示する際、最も単純な方法は元画像をロードしてリサイズすることです。しかしこれはひどく非効率的です。\n方式 メモリ使用量 処理時間 元画像(24MP)ロード → リサイズ ~72MB (24M × 3bytes) 遅い IFD(1)サムネイル使用 ~76KB (160×120) 速いが、小さすぎてぼやける MPFプレビュー(~2MP)使用 ~8MB 速く、視覚的に十分 IFD(1)のサムネイルは小さすぎて一覧用には問題ありませんがプレビュー用にはぼやけます。元画像をロードすると24MP画像がメモリに72MBを占有しデコード時間も長いです。**MPFに含まれる12MPプレビュー画像**はこの両者の間のスイートスポットです ―― 視覚的に十分鮮明でありながら、メモリとCPUオーバーヘッドが元画像の1/10以下です。\n特にChama Opticsのように数十枚の写真を同時にリスト表示し、テーマプレビューまで提供するプログラムではこの差が決定的です。50枚の24MP写真を元画像でロードすると3.6GB、MPFプレビューでロードすると400MB ―― 約9倍の差です。\n既存のexif-rsユーザーに影響を与えないよう mpf feature flagで提供するようにしました。\n10. HEIF/HEICデコーダ：プラットフォーム別戦略 # 最近JPEG以外にHEIF（High Efficiency Image Format）で写真を保存するデバイスが増えています。特にiOSは撮影時にHEIFをデフォルトで使用し、写真を外部に転送する際にJPEGに変換するかHEIFのまま渡すかをOSが自律的に判断します ―― アプリからこれを制御するのは容易ではありません。一部のミラーレスカメラ（Sony、Canonなど）もHEIF撮影をサポートし始めました。互換性のためにJPEGだけを使うユーザーもいますが、HEIFで入ってくるファイルを処理できなければ写真アプリとして致命的です。問題はHEIFデコードのサポートがプラットフォームごとに大きく異なることです。\nChama Opticsは可能な限りOSネイティブデコーダを使い、ネイティブサポートのないプラットフォームでのみlibheifを使う戦略を取りました。\niOS/macOS ―― AppleのImageIO フレームワークがHEIFをネイティブサポートします。外部ライブラリなしにOS APIだけでデコードが可能です。iOSではSwiftアプリレイヤーでデコードしたピクセルバッファをC FFIでRustに渡し、macOSではRustが直接macOS APIバインディング経由で呼び出します。\nAndroid ―― API 26（Android 8.0）以上でBitmapFactoryとMediaCodecがHEIFをネイティブサポートします。Kotlinアプリでデコードした後JNA経由でRustに渡します。\nWindows/Linux ―― ネイティブHEIFデコーダがないか制限的です。この場合 libheif_rs（libheifのRustバインディング）を使用します。C FFIはlibheif_rsが内部的に処理するため、Rustコードからは安全なAPIのみ呼び出せばよいです。libheifは内部的にlibde265（HEVCデコーダ）とlibaom（AV1/AVIF）を使用します。\nこの戦略の核心は #[cfg(target_os)] 条件付きコンパイルです。ネイティブデコーダがあるプラットフォームでは外部依存なしに最適なパフォーマンスを得て、libheif_rsが必要なプラットフォームでのみリンクします。結果的にmacOSビルドではlibheif関連コードはそもそもコンパイルされません。\n11. テーマパラメータシステム：Rust → JSON → プラットフォーム別UI # Chama Opticsのテーマには40以上の設定パラメータがあります ―― フォントweight、ウォーターマークの位置・透明度、フレームスタイル、ロゴ表示有無、色、余白など。これらのパラメータがデスクトップとモバイルで同一の結果を保証しなければならないことが核心的な要件でした。\nデスクトップ（egui）ではRust構造体を直接参照してUIウィジェットを描画します。Slider::new(\u0026amp;mut config.font_weight, 100..=900) のようなコードで構造体フィールドがそのままUI状態になります ―― JSONシリアライゼーションも中間変換もありません。\n問題はモバイルです。iOS（SwiftUI）とAndroid（Jetpack Compose）はRust構造体に直接アクセスできません。40以上のパラメータそれぞれについてSwift/Kotlin側で手動でUIを作り、FFIで値をやり取りするコードを一つ一つ書くとしたら？　パラメータが一つ追加されるたびにRust、Swift、Kotlinの三箇所を同時に修正しなければなりません。\nこの問題を proc_macro で解決しました。Rust構造体の定義に #[derive(ThemeParam)] を付けると、コンパイルタイムに以下が自動生成されます。\nJSONスキーマ: 各フィールドのUI型（スライダー、トグル、enum選択、カラーピッカーなど）、範囲、デフォルト値を含むJSON FFI関数: get_param_json()、set_param() などモバイルから呼び出せるC ABI関数 デシリアライゼーションロジック: JSONで受け取った値をRust構造体に反映するコード モバイルアプリはこのJSONをパースしてネイティブUI要素を動的に生成します。\u0026quot;type\u0026quot;: \u0026quot;slider\u0026quot; → SwiftUIの Slider、Jetpack Composeの Slider()。\u0026quot;type\u0026quot;: \u0026quot;toggle\u0026quot; → Toggle / Switch。ユーザーが値を変更するとFFI経由でRustコアに渡され、Rustコアは同一のレンダリングパイプラインで結果を返します。\n結果的にRust構造体一つがUI仕様でありデータモデルでありシリアライゼーションフォーマットの役割を同時に果たします。新しいパラメータを追加する際はRustにフィールド一つを追加してアトリビュートでUIヒントを付ければ、proc_macroがJSONスキーマを更新し、モバイルアプリは次回ビルドで自動的にそのUIを表示します。Swift/Kotlinコードを修正する必要がありません。\n組み込みでの build.rs 乱用と const fn 執着がこのような形で応用されました。正直proc_macroでやるのがスマートかどうかは分かりません ―― 本人も「異様だ」と思っている部分です。しかし40以上のパラメータを3つのプラットフォームで手動同期するよりは確実にマシです。 Rustの手続き型マクロ（procedural macro）についてもっと知りたければ この記事 が良い参考になります。\n12. 多言語翻訳システム：YAML一つで3プラットフォームの翻訳を自動生成 # 4つの言語（英語、韓国語、日本語、インドネシア語）をサポートしながら翻訳文字列が3つのプラットフォームで同期されなければなりません。 翻訳キーを一つ追加したり文言を修正するたびにiOSの .strings、Androidの strings.xml、デスクトップのRustコードをそれぞれ手で直さなければならないとしたら？　結局漏れたりずれたりします。\n解決方法はシンプルです。rust-coreのYAMLファイルを唯一の原本とし、ビルド時に各プラットフォームのフォーマットに自動変換することです。\nYAML：翻訳の原本 # rust-core/locales/ ディレクトリに23個のYAMLファイルがあります。common.yml、gallery.yml、theme.yml、face_detection.yml など機能単位で分割されており、合計約3,900行です。\n# rust-core/locales/gallery.yml gallery: empty_state_title: en: \u0026#34;No Images Yet\u0026#34; ko: \u0026#34;이미지 없음\u0026#34; ja: \u0026#34;画像がありません\u0026#34; id: \u0026#34;Belum Ada Gambar\u0026#34; この構造は rust_i18n クレートが要求するフォーマットそのままです。デスクトップでは rust_i18n::i18n!(\u0026quot;locales\u0026quot;) でコンパイルタイムにYAMLを埋め込み、t!(\u0026quot;gallery.empty_state_title\u0026quot;) で呼び出します。別途の変換は不要です。build.rsで cargo:rerun-if-changed=locales を宣言してあるため、YAMLが修正されると自動的に再コンパイルされます。\n問題はiOSとAndroidです。\niOS: generate_ios_strings.sh # iOSは NSLocalizedString と .strings ファイルを使用します。generate_ios_strings.sh はPython3 + PyYAMLでYAMLをパースし、各ロケール別の Localizable.strings を生成します。\n# build_ios.sh から自動呼び出し ./generate_ios_strings.sh YAMLの階層構造をドット（.）表記法で平坦化して .strings フォーマットに変換します。\n/* Auto-generated from rust-core/locales - DO NOT EDIT */ \u0026#34;gallery.empty_state_title\u0026#34; = \u0026#34;이미지 없음\u0026#34;; \u0026#34;common.actions.save\u0026#34; = \u0026#34;저장\u0026#34;; iOS固有の要件もありました。同じキーでもiOSでは異なる文言を使うべき場合があります ―― 例えばデスクトップで「ファイル読み込み」と書く箇所をiOSでは「写真を選択」と書く方が自然です。これに対応するため _ios サフィックスオーバーライドを実装しました。YAMLで import.label_ios が定義されていればiOSビルドでは import.label の代わりにその値を使用します。デスクトップとAndroidには影響しません。\nこのスクリプトは build_ios.sh でRustクロスコンパイル前に自動的に呼び出されるため、YAMLを修正してXcodeビルドを実行すれば翻訳が自動反映されます。\nAndroid: generate_android_strings.sh # Androidは strings.xml と R.string.* リソースシステムを使用します。核心的な違いが2つあります。\n第一に、キーフォーマットが異なります。 Androidリソース名にはドット（.）を使用できません。YAMLの gallery.empty_state_title をAndroidでは gallery_empty_state_title に変換する必要があります。\ndef yml_key_to_android_key(yml_key): return yml_key.replace(\u0026#39;.\u0026#39;, \u0026#39;_\u0026#39;) 第二に、ロケールディレクトリ規則が異なります。 Androidはインドネシア語を id ではなく in で表記します ―― values-in/strings.xml。このマッピングをスクリプトで処理します。\nANDROID_LOCALE_MAP[\u0026#34;en\u0026#34;]=\u0026#34;values\u0026#34; ANDROID_LOCALE_MAP[\u0026#34;ko\u0026#34;]=\u0026#34;values-ko\u0026#34; ANDROID_LOCALE_MAP[\u0026#34;ja\u0026#34;]=\u0026#34;values-ja\u0026#34; ANDROID_LOCALE_MAP[\u0026#34;id\u0026#34;]=\u0026#34;values-in\u0026#34; # Android uses \u0026#34;in\u0026#34; for Indonesian iOSスクリプトとのもう一つの違いはdiff基盤同期だということです。iOSは毎回ファイルを丸ごと上書きしますが、Androidスクリプトは既存の strings.xml に既にあるキーには触れず不足しているキーのみ追加します。Android側で手動管理しているエントリ（アプリ名など）を保持するためです。--check モードで実行するとファイルを修正せず不足している翻訳のみ報告します。\nAndroidでこれらのキーを実際に使用する際は ThemeI18n.kt でYAMLドット表記法キーを R.string.* リソースIDにマッピングします。\nobject ThemeI18n { fun translate(context: Context, key: String): String { val resourceId = keyToResourceId(key) return if (resourceId != 0) context.getString(resourceId) else key } } 3プラットフォームのキー変換比較 # 要素Desktop (Rust)iOS (Swift)Android (Kotlin) 原本t!(\"gallery.empty_state_title\")NSLocalizedString(\"gallery.empty_state_title\")R.string.gallery_empty_state_title キー区切り.（ドット）.（ドット）_（アンダースコア） 生成方式コンパイルタイム埋め込みビルドスクリプト自動生成ビルドスクリプトdiff同期 プラットフォームオーバーライド—_ios サフィックス— インドネシア語コードididin この構造のおかげで翻訳を追加または修正する際にYAMLファイル一つを直すだけで 3つのプラットフォーム全てに反映されます。23個のYAMLファイル、4つの言語、3つのプラットフォームを手動で同期するのは現実的に不可能です ―― 自分が考えた方法は自動化だけでした。\nオープンソース貢献活動 # Chama Opticsの開発過程で依存するオープンソースプロジェクトにも積極的に貢献しました。\nプロジェクト 貢献内容 exif-rs MakerNoteパース ―― 10メーカーサポート (PR #57, +5,946 lines) exif-rs MPFおよび内蔵プレビュー画像抽出 (PR #58, +1,364 lines) exif-rs TIFFフィールドアクセス改善 (PR #51, approved) font-kit macOSシステムフォント列挙時のメモリ暴走修正 (PR #271) egui variable fontロード時のmain weight設定機能改善 (PR #7790, approved) wagahai-lut 1D/3D LUT色調補正ライブラリ (crates.io) リリースまとめ # バージョン 日付 主な変更点 v0.1.0 2025-10-19 初プレリリース、macOS/Windows、Filmテーマ v0.1.1 2025-10-19 日本語翻訳、一括保存、プレフィックス/サフィックス v0.1.2 2025-10-27 Glowエフェクト、Film Date/Glowテーマ v0.1.3 2025-11-03 ウォーターマーク（9箇所）、フォント選択 v0.1.4~5 2025-11-05~12 Just Frame、Strapテーマ、カメラロゴ v0.1.6 2025-11-24 Monitor、Lightroomテーマ、Longsideスケール v0.1.7 2025-12-19 One/Two Line、Shot Onテーマ、CJK修正、PhotoStyle v0.1.8 2025-12-27 タブUI、グループ化、テーマプレビュー、マルチコア v0.1.9 2026-02-04 顔認識、LUT色調補正、iOS TestFlight初配布 AIと共にプログラミング（バイブコーディング？） # 最初はAIコーディングに対して懐疑的でした。\nそのためデスクトップ版の大半は今でも自分の手書きコード + cargo fmt/clippy/check に依存しています。Rust Embeddedでの習慣である const の乱用をデスクトップでも適用しようとする自分の意図を、AI（Claude）はまだ正しく把握できていません。\nしかしモバイル版を開発しながら、一人でこれを全部やるのは正気の沙汰じゃないと思いました。既存のデスクトップ版と同一の結果をモバイルで提供することが最優先であり、ネイティブAPIとRust FFIを直接呼び出す形が多くなると予想されました。\nそんな折、友人の結婚式の招待状の集まりに行く際、一緒に車に乗っていた友人が「FlutterでiOS 26のLiquid UIが今まともに動かない」と言いました。開発するとしてもネイティブでのみ開発すべきだという考えが固まり、同時にAIにモバイル用のコードを任せることに決めました。\n結果として Rustコアは自分が直接、モバイルUI（SwiftUI/Jetpack Compose）とFFIブリッジはAIと共に 書くという分業体制が生まれました。Rust側は自分の意図したパターンとスタイルがあるのでAIがうまく合わせられませんが、Swift/Kotlinのように自分がよく知らない言語でプラットフォームネイティブコードを書くにはAIが大いに助けになりました。\nこの経験をした後、Flutterのようなクロスプラットフォームフレームワークの立ち位置について考えるようになりました。もちろんFlutterやReact Nativeが解決する問題 ―― 一つのコードベースで複数プラットフォームをカバーすること ―― は依然として有効です。しかしAIが各プラットフォームのネイティブコードを十分にうまく書ける時代になれば、「ネイティブを知らないからクロスプラットフォームを選ぶ」という動機は徐々に弱まっていくかもしれません。モバイル開発をまったく知らなかった自分がAIの助けだけでSwiftUIとJetpack Composeをそれぞれネイティブで書けたという事実が、その可能性を示す一つの事例ではないかと思います。\n今後の計画 # v0.1.9を起点にデスクトップ単独リリースは終了し、v0.2.0からはiOS、Androidモバイルアプリと一緒にリリースする予定です。追加機能よりは随時安定化とテーマ追加に集中するつもりです。\n当面の目標は 2026年3月のホロライブエキスポ/フェスティバル で実戦投入することです。会場でミラーレスで写真を撮り、iPhoneですぐフレームをかぶせ、顔を自動でモザイク処理してSNSに上げる ―― カメラユーザーでも一般のスマホユーザーでも、それぞれの環境で快適に使えるワークフローを提供するのが方向性です。\nサイドプロジェクトとしてChama Opticsは「写真を撮る人が写真をより良く見せられるようサポートするツール」を目標に、もっと快適なワークフローを提供していきます。そして今回の開発で蓄積した手続き型マクロと最適化の経験をもとに、再びRust Embedded方面にももう少し力を入れていく予定です。\n参考文献および引用 # 標準文書 # CIPA DC-008 — Exchangeable image file format (Exif) Version 3.0 CIPA DC-007 — Multi-Picture Format (MPF) Adobe — Adobe Cube LUT Spec 1.0 ライブラリおよびフレームワーク # exif-rs — Rust EXIFパースライブラリ egui — Rust即時モードGUIフレームワーク font-kit — クロスプラットフォームフォントロードライブラリ wagahai-lut (crates.io) — 1D/3D LUT色調補正ライブラリ libheif-rs — libheif Rustバインディング wide — クロスプラットフォームSIMDベクトルクレート ONNX Runtime — クロスプラットフォームML推論エンジン InsightFace SCRFD — 顔検出モデル (det_10g) exif-frame — EXIFフレームWebツール（Chama Opticsの初期参考） 参考資料 # Rust Procedural Macros — 手続き型マクロ参考 ExifTool TagNames — メーカー別MakerNoteタグ参考 Exiv2 MakerNote Documentation — MakerNote構造およびメーカー別フォーマット参考 Special Thanks # SkuldNorniern — デバッグおよび顔認識関連の支援 miniex — フォントシステムのデバッグおよび顔認識関連の支援 jcm7612 — デバッグおよびフィードバック shiemika324 — イラストおよびアイコンイラスト提供 ","date":"2026年2月14日","externalUrl":null,"permalink":"/ja/posts/chama-optics-dev-story/","section":"Posts","summary":"EXIF ベースの写真フレーム＋顔自動認識アプリ、Rust コアでデスクトップからモバイルまで\n","title":"Chama Optics 開発記","type":"posts"},{"content":"","date":"2026年2月14日","externalUrl":null,"permalink":"/ja/tags/cross-platform/","section":"Tags","summary":"","title":"Cross-Platform","type":"tags"},{"content":"","date":"2026年2月14日","externalUrl":null,"permalink":"/ja/tags/exif/","section":"Tags","summary":"","title":"EXIF","type":"tags"},{"content":"","date":"2026年2月14日","externalUrl":null,"permalink":"/ja/tags/ios/","section":"Tags","summary":"","title":"IOS","type":"tags"},{"content":"","date":"2026年2月14日","externalUrl":null,"permalink":"/ja/tags/rust/","section":"Tags","summary":"","title":"Rust","type":"tags"},{"content":" WARN! This article is still a work in progress. Content may change at any time. Before Reading # This post is a continuation of the previous post Part 3: Leave It to Compile Time, but focuses on build.rs rather than const fn/trait/impl.\nIf you are not familiar enough with Rust syntax, I recommend reading the #Studying-Rust section in the previous post Part 2: Study Methods and Key Characteristics. I also recommend the excellent article by Ki-O Kim, A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust.\nBuild Scripts (build.rs) # Just as C and C++ have Makefiles, Rust has Cargo. Cargo provides build.rs, which allows you to easily write scripts that run before compilation begins.\nFor detailed documentation on build.rs, see: The Cargo Book - Build Scripts\nbuild.rs runs before compiling the source code in the src directory or external libraries. Importantly, even if you are developing code for no_std, build.rs can use libraries available on the host OS, including no_std and the alloc crate.\nA separate program in main.rs must create const data at compile time, but there are cases where the functions and methods you need are not available in const form.\nFetching Strings with build.rs and env!() # Let us practice fetching a string (\u0026amp;str) at compile time using build.rs and the env!() macro.\nThe project structure looks like this. build.rs is not in the src directory; it goes in the root directory of the project.\nCargo.toml Example # # End of Cargo.toml [build-dependencies] chrono = \u0026#34;0.4.31\u0026#34; As mentioned above, build.rs can use libraries available for OS targets. If there is a crate you want to use, add it under build-dependencies below dependencies. Here we have added the chrono crate for our example.\nbuild.rs Example # // build.rs fn main() { let now = chrono::Utc::now().to_rfc3339(); println!(\u0026#34;cargo:rustc-env=GIVEN_BUILD_TIME={}\u0026#34;, now); } When Cargo compiles and runs build.rs, it uses the chrono library to get the current time in UTC and converts it to a String.\nThen it passes it to rustc (the compiler) as the \u0026ldquo;GIVEN_BUILD_TIME\u0026rdquo; environment variable via println!.\nsrc/main.rs Example # // src/main.rs const BUILD_TIME: \u0026amp;str = env!(\u0026#34;GIVEN_BUILD_TIME\u0026#34;); fn main() { // if you working with firmware environment, // use defmt::info!(..) instead of println!(..) println!(\u0026#34;passed build time is {}\u0026#34;, BUILD_TIME); // \u0026#34;passed build time is 2023-11-14T06:14:02.366899222+00:00\u0026#34; } In src/main.rs, the \u0026ldquo;GIVEN_BUILD_TIME\u0026rdquo; environment variable is retrieved as a const \u0026amp;str using the built-in env!(..) macro.\nThe exact module path of env!(..) is core::env!(..), and core::env!(..) fetches environment variables at compile time. If you are developing for an OS target and want to get runtime environment variables or execution arguments rather than compile-time ones, you should use the items in the std::env module. Since you may end up using both when working with build.rs, be careful not to confuse them.\nFor detailed documentation on the env!() macro, see: https://doc.rust-lang.org/core/macro.env.html\nCreating Fixed-Length Binary Data # Fetching with include_bytes # core::include_bytes can load a file from the project directory as binary data at compile time. https://doc.rust-lang.org/core/macro.include_bytes.html\nCreating a Dummy Binary # echo -n \u0026#34;\\x00\\x01\\x02\\x03\u0026#34; \u0026gt;\u0026gt; ./src/stuff0123.bin Create a dummy binary for our exercise. It is [0x00, 0x01, 0x02, 0x03], totaling 4 bytes, and is placed in the same location as main.rs.\nIn this post we create the dummy binary from the terminal, but it can also be done from build.rs.\nsrc/main.rs Example # const DATA0123: \u0026amp;[u8; 4] = include_bytes!(\u0026#34;stuff0123.bin\u0026#34;); fn main() { println!(\u0026#34;binary data is {:?}\u0026#34;, DATA0123); } In src/main.rs, the binary created earlier is fetched at compile time as const \u0026amp;[u8; 4]. Note that unlike fetching a \u0026amp;str above, you must specify the number of elements like [u8; N].\nTo fetch data without worrying about the number of elements, you need to use macros. This is covered later in this post.\nFetching Variable-Length Binary Data # build.rs src/**.rs String const \u0026amp;str Vec\u0026lt;u8\u0026gt; const [u8; N] In build.rs, data has variable-length characteristics, but when compiling for the target inside src/**.rs, you need the help of proc_macro. However, if the data size changes variably with each compilation and is not strictly controlled, it can be dangerous, so keep this in mind when using it.\nFetching Variable-Length Binary Data with proc-macro # There is also an approach of saving data to a tmp file and using include_bytes! with proc_macro, but the method introduced here uses env! together with proc_macro.\nTo explain proc_macro: in the past with C, you would use ## to concatenate tokens to generate code, or use compiler-specific features for black magic. Proc_macro brings in the concepts of tokens and parsers to enable reasonably stable metaprogramming through a macro system.\nIn Korean it is called procedural macros (jeolchahyeong maekeullo). If you master proc_macro and procedural macros, you can achieve excellent metaprogramming. I will write about this in more detail in a future post.\nFor the official detailed explanation of proc_macro, see: Procedural Macros\nOverall Flow # stateDiagram-v2 state \"Total flow\" as total_flow state \"data prepare\" as data_prepare state \"hex::encode(..)\" as hex_encode state \"hex encoded\" as hex_encoded state \"passing to env\" as passing_to state \"passing from env\" as passing_from state \"proc_macro\" as proc_macro state \"decoding at build time\" as decoding state \"decoded data\" as decoded_data state \"code generation\" as code_generation state \"src/**.rs\" as src_rs state \"const NAME: [u8; N] = [...]\" as const_u8_n state total_flow { [*] --\u003e build.rs state build.rs { [*] --\u003e data_prepare data_prepare --\u003e hex_encode hex_encode --\u003e hex_encoded hex_encoded --\u003e passing_to } -- state src_rs { passing_from --\u003e proc_macro state proc_macro { [*] --\u003e decoding decoding --\u003e decoded_data decoded_data --\u003e code_generation } proc_macro --\u003e const_u8_n } } The overall flow is as follows:\nPrepare the data to inject in build.rs. Encode it as hex and pass it as an environment variable to rustc. In src/**.rs, receive the environment variable and pass it to a function created with proc_macro. The macro function decodes the data at compile time and turns it into an array of the original data. Generate const data as a code declaration with the specified name and the array length. proc_macro Code for Decoding at Compile Time # To perform steps 4 and 5 described above, the following code is needed:\nfn slice_to_auto_sized ( arr_name: String, input: \u0026amp;[u8], ) -\u0026gt; TokenStream { format!( \u0026#34;const {}: [u8; {}] = [{}];\u0026#34;, arr_name, input.len(), input.iter().join(\u0026#34;, \u0026#34;) ) .parse::\u0026lt;proc_macro2::TokenStream\u0026gt;() .expect(\u0026#34;Failed to parse array\u0026#34;) .into() } struct NameAndEnvInput { arr_name: syn::LitStr, _comma0: Token![,], env_var: syn::LitStr, } impl Parse for NameAndEnvInput { fn parse(input: syn::parse::ParseStream) -\u0026gt; syn::Result\u0026lt;Self\u0026gt; { Ok(Self { arr_name: input.parse()?, _comma0: input.parse()?, env_var: input.parse()?, }) } } #[proc_macro] pub fn c(inputs: TokenStream) -\u0026gt; TokenStream { let inputs = parse_macro_input!(inputs as NameAndEnvInput); slice_to_auto_sized( inputs.link_section_name.value(), inputs.arr_name.value(), hex::decode(std::env::var(inputs.env_var.value()).expect(\u0026#34;This env not found\u0026#34;)) .expect(\u0026#34;Can\u0026#39;t decode hex\u0026#34;) .as_slice(), ) } As an example, assume that slice_to_auto_sized!(SOME_DATA, GIVEN_ENV); is declared in main.rs.\nIn const_from_hex_env, it takes three tokens matching the structure of the NameAndEnvInput struct: \u0026ldquo;SOME_DATA\u0026rdquo;, a comma (,), and \u0026ldquo;GIVEN_ENV\u0026rdquo;. These tokens are passed to slice_to_auto_sized at the top, which generates the code to be produced.\nThe above code can be found in the forked env-to-array commit. The code there has been modified to create dummy sections for the linker, so it is slightly different. This code is a slightly modified fork of the env-to-array crate. Data Generation Example for Hex Encoding # fn main { // https://github.com/pmnxis/billmock-mptool/blob/master/otp-proof-of-concept/build.rs // (abbreviated) let fingerprint = MpFingerprint { firmware_fingerprint: FirmwareFingerprint { model_name: main_package.name.clone(), // reference package name temporary model_ver: feature_based_model_ver, firmware_ver: main_package.version.to_string(), firmware_git_hash: format!(\u0026#34;{}\u0026#34;, commit_hash), }, }; // cargo objdump --release -- -s --section .mp_fingerprint println!( \u0026#34;cargo:rustc-env=MP_FINGERPRINT_TOML_HEX={}\u0026#34;, fingerprint.to_hex_string(), ); } When encoding in hex style, you can use hex and encode with hex::encode().\nThe code above creates package information and a git hash in TOML format, then hex-encodes it.\nPractical Applications # Application - Fetching EUC-KR Strings at Compile Time # use encoding_rs::EUC_KR; fn main() { // encoding_rs::Encoding::encode(..) is not const fn let ret: \u0026amp;[u8] = EUC_KR.encode(\u0026#34;안녕하세요\u0026#34;).0.to_vec().as_slice(); } While developing billmock-app-rs, I encountered several problems when creating an NDA financial institution protocol communication library. I needed to hold EUC-KR strings as const. However, the EUC-KR string encoding library encoding-rs does not provide const functions.\nSince EUC-KR is ultimately a character encoding, under the assumption that the strings are predetermined, it is binary data that can be generated at compile time.\nBy combining the techniques introduced above, I wrote code in the financial institution protocol communication library that converts EUC-KR strings to const [u8; N] at compile time.\nApplication - Dummy ELF Header # During firmware development, when creating an MP Tool (Mass Production Tool) for flashing firmware in bulk, I inserted a dummy header into the ELF to prevent mistakes and record hardware version information. Since this dummy ELF header is data that is not actually loaded into flash, using variable-length data was no problem at all.\nThe overall structure is similar to what was described above in \u0026ldquo;Fetching Variable-Length Binary Data with proc-macro\u0026rdquo;.\nRelated commits are as follows:\nhttps://github.com/pmnxis/billmock-app-rs/pull/42/files https://github.com/pmnxis/env-to-array/commit/782c2b265d8a23653321d163ac5cea96c04bc85d Wrapping Up # This post is a continuation of the previous post Part 3: Leave It to Compile Time, but focused on build.rs rather than const fn/trait/impl. I covered how to handle fixed-length and variable-length data through build.rs and listed practical usage examples.\nThe topic of proc_macro (procedural macros) was too lengthy to explain in the middle of this post, so I plan to cover it in a future article.\n","date":"2023年11月13日","externalUrl":null,"permalink":"/ja/posts/my_first_commerical_rust_embedded_product_4/","section":"Posts","summary":" WARN! This article is still a work in progress. Content may change at any time. ","title":"Developing a Mass-Produced Rust Embedded Product - 4 Leveraging Build Scripts","type":"posts"},{"content":"","date":"2023年11月13日","externalUrl":null,"permalink":"/ja/tags/embedded/","section":"Tags","summary":"","title":"Embedded","type":"tags"},{"content":"","date":"2023年11月13日","externalUrl":null,"permalink":"/ja/tags/korean_article/","section":"Tags","summary":"","title":"Korean_Article","type":"tags"},{"content":"","date":"2023年11月13日","externalUrl":null,"permalink":"/ja/categories/my-frist-mass-production-with-rust-embedded/","section":"Categories","summary":"","title":"My Frist Mass Production With Rust Embedded","type":"categories"},{"content":"","date":"2023年11月13日","externalUrl":null,"permalink":"/ja/tags/%ED%9A%8C%EA%B3%A0%EB%A1%9D/","section":"Tags","summary":"","title":"회고록","type":"tags"},{"content":" WARN! This article is still a work in progress. Content may change at any time. Introduction # Before reading this post, if you are not familiar enough with Rust syntax, I recommend reading the #Studying-Rust section in the previous post Part 2: Study Methods and Key Characteristics. I also recommend the excellent article by Ki-O Kim, A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust.\nLeave It to Compile Time # A typical function will use a constant (immutable value) directly if the result can be predicted at compile time.\nHowever, if storing the value as a constant is deemed inefficient, it remains as a function in the instruction stream.\nIn embedded systems, especially firmware running on low-cost MCUs, RAM is very limited. (The MCU I used, STM32G030C8, has only 8KiB.)\nTo leave complex computations as constant-like data at compile time and load them into the Flash region (.text or .rodata), I occasionally departed from typical Rust programming practices and wrote code with this in mind.\nconst fn # Unlike a regular fn, a const fn guarantees that constant-like data is obtained at compile time.\nconst fn const_add(a: i32, b: i32) -\u0026gt; i32 { a + b } const fn const_add_round_up(a: i32, b: i32) -\u0026gt; i32 { let added = const_add(a, b); // Functions inside must also be const (added / 10) * 10 } However, there are many constraints. Functions within a const fn scope must also be const fn, and other operations must also be computable at compile time.\nConversely, a const fn can be used inside a regular fn or async fn scope.\nconst impl # Making a regular function const is straightforward, but the moment you turn it into a method for a struct, you run into difficult problems. This topic will be covered in the const trait section below.\nFor now, let us look at the simplest case: defining a default for a specific struct.\npub enum Player { Undefined = 0, Player1 = 1, Player2 = 2, } impl Player { pub const fn default() -\u0026gt; Self { Self::Undefined } } The code ends up being very simple, but by doing this, the caller of default() can obtain a constant at compile time. For more complex cases, you can supply more complex values. As mentioned above, as long as the arguments are not dynamic, the function will not remain in function form, so you are guaranteed to skip branching, stack back-and-forth, and the process of backing up and restoring registers.\nconst trait # Now we arrive at the much-anticipated const trait, which at the time of writing (November 2023) is a nightly feature. From here, I will also describe why const fn / impl / trait is still an RFC under discussion in Rust.\nConflicts with Existing Traits # Did you notice anything odd about the pub const fn default() mentioned above?\nThe issue is that a Default trait already exists separately.\nHowever, the definition of the Default trait is not in const form.\nIt is obvious that the core::default::Default trait impl for many structs is trivially simple. But no matter how simple it looks by eye, in this case it cannot be used inside a const fn.\nThe Case of Into/From # So far there has been little need to abstract through the Default trait using const, but surprisingly, Into/From turned out to be the real problem.\nFor now, by modifying the trait definition of core::default::From into ConstInto and ConstFrom compatible with const traits, you can use them as follows:\nConstConvert definition used in the product Example of using const-style Into/From\npub struct UnpackedQuad4Bits { pub b0: u8, pub b1: u8, pub b2: u8, pub b3: u8, } #[derive(PartialEq)] pub struct PackedQuad4Bits { inner: u16, } impl const ConstFrom\u0026lt;UnpackedQuad4Bits\u0026gt; for PackedQuad4Bits { fn const_from(value: UnpackedQuad4Bits) -\u0026gt; Self { PackedQuad4Bits { inner: ((value.b0 as u16 \u0026amp; 0xF) \u0026lt;\u0026lt; 12) | ((value.b1 as u16 \u0026amp; 0xF) \u0026lt;\u0026lt; 8) | ((value.b2 as u16 \u0026amp; 0xF) \u0026lt;\u0026lt; 4) | (value.b3 as u16 \u0026amp; 0xF), } } } #[test] fn test() { assert_eq!( PackedQuad4Bits::const_from(UnpackedQuad4Bits { b0: 0x0, b1: 0x1, b2: 0x2, b3: 0x3 }), PackedQuad4Bits { inner: 0x0123 } ); } When you create ConstInto / ConstFrom in const form, you cannot use them directly via .into() as with regular Into/From. You need to call the preceding const method again from the Into/From trait definition, but you can define the into conversion at compile time.\nconst trait as a Nightly Feature # const trait is still a nightly feature. In my personal experience, I had to change feature flags every time I slightly updated the nightly compiler version. Nevertheless, it is a very necessary feature in certain cases. (Of course, you can get by using only const fn without it.)\nWhen defining a const trait, you need to add #[const_trait] before the trait definition and declare #![feature(const_trait_impl)] in lib.rs or main.rs.\ntodo! Write about the history of discussions around const trait Tracking issue for RFC 2632, impl const Trait for Ty and ~const (tilde const) syntax Check out other posts in this series: Developing a Mass-Produced Rust Embedded Product ","date":"2023年11月12日","externalUrl":null,"permalink":"/ja/posts/my_first_commerical_rust_embedded_product_3/","section":"Posts","summary":" WARN! This article is still a work in progress. Content may change at any time. ","title":"Developing a Mass-Produced Rust Embedded Product - 3 Leave It to Compile Time","type":"posts"},{"content":" WARN! This article is still a work in progress. Content may change at any time. RIIR BEAM\nIntroduction # Continuing from the previous post, I want to briefly cover the pros and cons of applying Rust to embedded development, as well as how to study Rust for embedded.\nWhat I Felt After Using Rust for Embedded # There is a 38-Year Gap Between C and Rust # Image source: History Of Programming Languages\nC was released in 1972, and Rust was released in 2010. There is at least a 38-year gap between them, during which many languages, concepts, and changes emerged.\nC has structs, but it is fundamentally a procedural and strongly-typed language. Rust is a strongly-typed language with object-oriented capabilities (without inheritance, unlike C++), and like C and C++, it is designed with systems programming in mind.\nIn my personal interpretation, while C is strongly typed, it is a language tightly bound to CPU registers. In comparison, Rust is less dependent on CPU registers than C, but you can still be register-aware when programming in certain situations. I believe Rust has its strong typing characteristics rooted in the concept of \u0026ldquo;objects.\u0026rdquo;\nC has been maintained for a long time, and if you only work on embedded, you can be very fluent in C. However, there can be many challenges when adapting to a modern language like Rust. The biggest challenge is probably designing \u0026ldquo;objects\u0026rdquo; and \u0026ldquo;methods.\u0026rdquo; If you have only done procedural programming, you may struggle with this for at least several months.\nBeyond this, there are many things you need to break out of your existing mental framework \u0026ndash; the philosophy of explicitly distinguishing nullable values, ownership, and more. Understanding these concepts, and occasionally breaking them in low-level control (unsafe), or tuning for program size, is a process where you can gain a lot of CS knowledge and philosophical insight. I believe this is the most valuable part.\nAdvantages of Applying Rust to Embedded (Firmware) Projects # Thanks to built-in test support in the language spec, writing partial unit tests is straightforward. If the logic itself is sound and unit tests back it up, integration testing can be kept to a minimum while still catching bugs. Code written for firmware could be reused to a certain extent on backend servers. clippy and the formatter are built-in, making it easy to eliminate unnecessary code and unify code conventions. Object-oriented design (without inheritance) makes code reuse practical. The Cargo ecosystem makes adding libraries really convenient. Toolchain setup is also very simple. You can use async / await in firmware instead of epoll. Procedural macros are available. It is safer than writing in C, and you can significantly reduce mistakes during the development process. Disadvantages of Applying Rust to Embedded (Firmware) Projects # There are still not many reference projects to look at. It is practically difficult to apply to 8-bit processors. When putting data into queues or arrays, you tend to define separate, smaller types for enums, options, and structs to minimize size. Implementing Into/From for these is a bit tedious. You need to consider nightly features to some extent. When viewing compiled binaries with Ghidra/objdump, the output differs quite a bit from conventional C code. (Static analysis at the assembly level is still difficult. This is more of a characteristic than a disadvantage.) If you lack experience with object-oriented programming, you may end up writing procedural-style Rust code. With All These Disadvantages, Should You Still Use It? # Ultimately, it comes down to individual or organizational choice, but I personally think you should.\nThe reason is that I believe you cannot keep insisting on C forever. No matter how unique manufacturing and low-level domains may be, being an embedded developer does not mean you are outside the category of software developers. The languages developers use across the broader industry have evolved significantly and continue to change. The manufacturing and low-level sectors cannot escape this modern trend, and if they keep avoiding it, I believe the talent pipeline will eventually dry up.\nOf course, you cannot completely abandon C. But not every C developer can write code as rock-solid and performant as the Linux kernel core.\nStudying Rust # Recommended Reading # Ideally, I would like to introduce Rust syntax that would be useful for people new to Rust, from a C developer\u0026rsquo;s perspective. However, Ki-O Kim has already left an excellent article, A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust, so I will simply reference it here.\nThe resources below also do a great job of explaining Rust syntax:\nThe Rust Programming Language Korean Translation Comprehensive Rust Korean A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust Study Approach # If your goal is to study Rust for embedded, jumping straight into MCU or Linux driver development is not a great choice. When we talk about embedded, there are roughly three directions:\n\u0026ldquo;Firmware development running on MCUs\u0026rdquo; \u0026ldquo;Kernel development or kernel driver development\u0026rdquo; \u0026ldquo;FPGA development\u0026rdquo; What I cover here is direction 1, \u0026ldquo;Firmware development running on MCUs.\u0026rdquo; I plan to write about direction 2 separately after gaining more personal study and hands-on experience. Strictly speaking, while the domains share knowledge that is mutually helpful, they are entirely different domains. Direction 3 is even more distinct.\n(There are cases of applying Rust to FPGA, which is why I included it, but since I am not familiar with HDL-type languages, I will not mention it further.)\nIf you set your goals around directions 1 and 2, when it comes to studying just the Rust language itself outside of the domain, you need to study the language first.\nI recommend starting by reviewing the good resources mentioned above and trying out a toy project that runs on top of an OS.\nA language is just a tool, so there may be a temptation to immediately apply it to a domain you already know. However, in the long run, I do not think that is a great choice. I will discuss the reasons for this in another section.\nBe Mindful of no_std # To give a rough analogy for hardware engineers, no_std is like non-eabi. In other words, it refers to an environment that runs without standard APIs provided by an OS. In this case, there are significant constraints around heap or dynamic allocation, and since there is no standard I/O, you have no choice but to develop with hardware considerations in mind, unlike when developing on top of an OS.\nno_std is a reserved keyword for rustc (the compiler) and an implicit reserved keyword for cargo (the package manager). If #![no_std] is annotated at the beginning of a library\u0026rsquo;s lib.rs, it means the library can be used in a no_std environment.\nAdditionally, some crates mark no_std in their Cargo.toml to advertise no_std support on crates.io.\nA no_std Rust Environment Going forward, if you develop on Rust embedded, in both directions 1 and 2, you will frequently write or use no_std libraries. This is because the targets we aim for have very limited operating system support.\nUse core Instead of std for Core Library Imports # use core::borrow::BorrowMut; use core::cell::UnsafeCell; use core::marker::PhantomData; One thing you can immediately keep in mind is to import from core instead of std whenever possible. std re-exports everything from core, so using core imports directly is perfectly fine.\nhttps://doc.rust-lang.org/src/std/lib.rs.html#431-459 Avoid unsafe as Much as Possible at First # While I eventually used unsafe for optimization when writing embedded Rust, unsafe is difficult to use and requires a process of re-understanding your programming model and computer architecture knowledge through the lens of Rust\u0026rsquo;s philosophy. And the biggest problem is that fewer people can help you with it.\nI recommend getting comfortable with the Rust language first before diving into unsafe.\nIf you do need to use it, the following document provides very detailed coverage:\nThe Rustonomicon Check out other posts in this series: Developing a Mass-Produced Rust Embedded Product ","date":"2023年11月4日","externalUrl":null,"permalink":"/ja/posts/my_first_commerical_rust_embedded_product_2/","section":"Posts","summary":" WARN! This article is still a work in progress. Content may change at any time. RIIR BEAM\n","title":"Developing a Mass-Produced Rust Embedded Product - 2 Study Methods and Key Characteristics","type":"posts"},{"content":"This article is still being written. Content may change along the way.\nA test unit recently sent out to the field\nIntroduction # As a language to replace C, Rust is a language that has been receiving a lot of attention. While I am currently doing backend development, from the perspective of someone who used to live and breathe firmware, I have always held the belief \u0026ndash; past and present \u0026ndash; that if a programming language is not an HDL language, \u0026ldquo;it must be able to run on a 500-won MCU.\u0026rdquo;\nFrom this perspective, aside from zig which is currently gaining traction, I believe Rust is the only language that can replace C. However, this claim had the flaw that \u0026ldquo;I had never developed firmware at a production level with Rust.\u0026rdquo; Being aware of this shortcoming, after several attempts over 2-3 years, a commercial Rust embedded project that I finally started in July 2023 has reached the initial mass production phase.\nI intend to cover my experience with Rust embedded, its advantages, and various techniques across multiple articles. In this article, I would like to introduce the development framework used, what was developed for the project, and briefly share my impressions.\nAs a personal ambition, I would like to write a book about Rust embedded based on this experience, but I have not been able to decide on the target audience from among three categories. Until I settle on a target audience in my mind, I expect to organize things in a free-form manner as they come to me.\n\u0026ldquo;Developers who already have experience with Rust\u0026rdquo; \u0026ldquo;Developers whose primary job is not embedded but who do Arduino as a hobby\u0026rdquo; \u0026ldquo;Existing embedded developers\u0026rdquo; The reason I bother to explain this is that there are so few embedded developers using Rust. Most readers will likely fall into the category of developers interested in Rust, and trying to explain both the unfamiliar Rust and embedded simultaneously would be far too unkind. So even if the writing progresses slowly, I intend to go through the process of providing some perspective on the development process of embedded.\nProduct Planning # To the question of why card payment terminals are only being installed in arcades now in 2023, you need to look at the history of the arcade industry itself. Due to the \u0026ldquo;Sea Story\u0026rdquo; gambling scandal around 2007, it was not possible to install card terminals until 2020. From 2020 onward it became possible, but in that case, the game itself had to go through the approval process again. However, related regulations have recently been relaxed, and a request came in for me to develop a module that enables card terminal installation.\nGame Rating and Administration Committee decides to diversify arcade game payment methods starting next month - 2019-06-28 Regarding changes to payment methods for all-ages arcade games - 2022-03-21 Example of a bill acceptor\nCard terminals use RS232 serial communication, and existing arcade machines use a Molex 2.00mm pitch 10-pin connector for the bill acceptor, or 2-4 pin connectors for the coin acceptor. Unless special features are used, the signal systems of the 10-pin bill acceptor and coin acceptor are compatible. Given that prices have risen significantly compared to the past, 1000-won bills are used much more frequently than 500-won or 100-won coins as a payment method, so I decided to prioritize the bill acceptor wiring.\nTo add a card terminal to an existing arcade machine, the only option is to share the existing currency payment signal lines and generate signals in place of the bill acceptor (or coin acceptor). However, if you simply inject signals onto the existing wiring, the signals from the bill acceptor and the card terminal would overlap. Therefore, a FIFO Queue was applied to each signal output so that bill acceptor and card terminal inputs can be processed sequentially even if they overlap, and the hardware was designed accordingly.\nHardware Development # STM32G030C8Tx Chip Selection # STM32G030C8Tx is a Cortex-M0 (ARM Cortex-Mv6) MCU from ST. An MCU is a device that contains a 32-bit CPU along with peripherals for embedded use. This product has 64 KBytes of Flash for storing programs and 8KB of SRAM (similar to a computer\u0026rsquo;s RAM), and operates at 16 MHz. There is also a variant with half the capacity at 32 KBytes, but based on the experience at my company that 32 KBytes was not enough for a Rust debug build for even simple products, and the expectation that the features and business logic would likely grow, I chose 64 KBytes without going much higher. Additionally, this was based on the belief that being able to create a Rust embedded product on an inexpensive MCU with minimal computing resources would prove that Rust can be used for production and professional embedded development. (I have heard that you can write embedded code in Go, Python, and JavaScript too, but I think it is very difficult to use them in production environments where the cost must be very low, and it is meaningless if it only runs on expensive chips.)\nPCB (Circuit) Development # The Gerber data on the left is not publicly released, but the schematic (circuit diagram) is. BillMock-HW-RELEASE\nKiCad was used for circuit development. KiCad is an open-source EDA CAD program released by CERN. It supports all commonly used operating systems \u0026ndash; Linux, macOS, and Windows. I have been using it since version 5.x, and after going through 6.x, it became quite usable at 7.x, so I applied it to this project as well.\nPCB (circuit) development roughly divides into schematic development and Gerber artwork. A schematic is a diagram that represents how the circuit is to be configured, as shown in the right image. Gerber artwork, as shown in the left image, represents how the copper traces and components will actually be printed/mounted. Depending on the required connector positions in the circuit, the speed of communication on the traces, the magnitude of electrical signals, and power requirements, components are placed closer or farther apart, and traces are routed thicker or relatively thinner.\nJust as programs need optimization, circuits also need optimization. It is important to reduce the number and variety of components, use reasonably priced parts, reduce overall size or lower specifications to cut costs, while maintaining the hardware\u0026rsquo;s functionality and stability as planned.\nPrototype Production # JLCPCB was used for prototyping. For a company project, the orthodox choice would be to use a domestic turnkey manufacturer. However, having already used JLCPCB\u0026rsquo;s SMT (assembly) service several times, I did not need any additional adaptation, and I had confidence that if JLCPCB could produce good results at very low cost for small quantities, it would work fine at another manufacturer for mass production later. (JLCPCB is exceptionally inexpensive for small sample runs.)\nTo draw an analogy for backend server developers, I think it is similar to the thought: \u0026ldquo;If it runs on a 10-year-old school club server, it will probably run fine in the IDC for the final release.\u0026rdquo;\nFinal Mass Production # BOM Organization and Parts Procurement # Unlike software, as you get closer to hardware, you frequently hear the term BOM. Bill of Materials is literally a parts list and inevitably includes pricing and various other information. If the price is too high, you go back to the design stage and either make major design changes or, if there are components that can be replaced without design changes, substitute them with alternatives. During this process, I determined that costs were too high, reduced the number of connectors, and based on some demand forecasting, decided to purchase components in advance in \u0026ldquo;Reel\u0026rdquo; units.\nComponents sent to the assembly factory for mass production. A Reel refers to a cylindrical spool where components are wound up like film tape.\nBOM organization and optimization are very important, but since it is a topic that generally does not excite typical software developers, I think watching YouTuber Seungwoo Daddy\u0026rsquo;s restaurant BOM video can make it interesting. While it is about BOM (ingredient) management in restaurant operations rather than electronics, I think it is very informative.\nLet me tell you why this happens. - Seungwoo Daddy Daily Channel\nProduction Outsourcing / Assembly Outsourcing # Manufacturing a PCB and soldering components onto it (assembly, PCB Assembly) are separate tasks. There are cases where a turnkey company handles parts procurement as well, but in my case, I proceeded with company-supplied materials (purchasing and providing the parts ourselves).\nI used a turnkey company recommended by a senior colleague at the company who had previous mass production experience. (Trust-based, saving the time of searching around.)\nReasons for Domestic Mass Production (Why Not JLCPCB or Other Chinese Manufacturers) # Before present-day China emerged, Korea was capable of quickly handling everything from PCB manufacturing and assembly (+development) to product case injection molding and sheet metal fabrication for the entire world, and that supply chain still remains. Korea is still a country that can handle most processes of electronic product manufacturing and production. However, due to low prices and marketing, the practice of outsourcing sampling and small-scale production to Chinese companies has spread widely through YouTube and online communities. In Korea, if you can find the routes (manufacturers) known only to practitioners, and if those manufacturers accept the work, it is advantageous to conduct mass production domestically up to a certain quantity. If you are producing hundreds of thousands of units per month, it may be more cost-effective to outsource to overseas manufacturers, but for small quantities of several thousand or tens of thousands, you lack the ability and personnel to inspect whether the overseas factory performs well each time, and there is no way to hold them accountable if something goes wrong.\nBased on the PCB I made, assuming a production run of 1,000 units, JLCPCB is overwhelmingly cheaper, but there exists a point where the difference is only about 20-30%. When you factor in shipping costs, customs duties, and other administrative expenses, JLCPCB did not really provide much of an advantage. More importantly, the issue is that they do not properly take responsibility when problems occur. Besides JLCPCB, other overseas manufacturers may offer good quality, but the problem of not being able to visit in person to discuss issues when they arise still remains.\nIn the early days, I ordered 10 PCBs and 5 were defective, but I had to file the claim first.\nProgram Download # MP Tool\nEven after the PCB is manufactured, it does not just work \u0026ndash; you need to load the program onto it. There are cases where the assembly contractor can load the program binary upon request, but this time a custom program was needed, so I decided to handle the flashing directly.\nCovering why that process was necessary and how it was developed would make this too long, so I will address it in a separate article.\nThe rough process is as follows:\ngraph LR; A[Power Up] --\u003e|Flash \\nLock Check| B(Unlock Flash\\nTemporary) B --\u003e C[Program\\nDownload] C --\u003e |OTP section\\n check|D{S/N Exist?} D --\u003e|Yes| E[Update to DB] D --\u003e|No| F[Write New OTP\\n\u0026 Insert to DB] Here, an additional step is included to check the serial number in the OTP section and either add or update the information accordingly. If there is no serial number in the OTP, a serial number is written to the OTP section.\nClosing Remarks # The final mass-produced board\nNext time, I plan to cover the firmware software development side of things developed in Rust, and after that, I expect to cover the Rust embedded ecosystem and techniques I have picked up.\nI am very happy that my first personal mass production experience was built on firmware developed in Rust and that it was completed successfully.\nIf asked to do personal mass production again, I do not think I could. I will treasure it as a valuable experience that helps with development, but handling everything alone as a primary job is too much. Still, I recommend trying it at least once if you get the opportunity to do a production run on your own.\nCheck out other articles in this series: Rust Embedded Mass Production Development Story ","date":"2023年11月2日","externalUrl":null,"permalink":"/ja/posts/my_first_commerical_rust_embedded_product_1/","section":"Posts","summary":"This article is still being written. Content may change along the way.\nA test unit recently sent out to the field\n","title":"Rust Embedded Mass Production Development Story - 1: From Development to Production","type":"posts"},{"content":"","date":"2023年4月8日","externalUrl":null,"permalink":"/ja/tags/amd/","section":"Tags","summary":"","title":"AMD","type":"tags"},{"content":"","date":"2023年4月8日","externalUrl":null,"permalink":"/ja/tags/cache/","section":"Tags","summary":"","title":"Cache","type":"tags"},{"content":"","date":"2023年4月8日","externalUrl":null,"permalink":"/ja/categories/cpu/","section":"Categories","summary":"","title":"CPU","type":"categories"},{"content":"It has been quite a while since ZEN4 started selling, and ZEN3 has also gone through several internal stepping/revision changes that seem to have improved things, so I feel this is an appropriate time to write this article. I originally posted this on other communities as well, and while it may seem tangential to development, it deals with CPU internals, so I am reposting it on my dev blog.\nInstruction L1/L2 Cache Failures Occur When Power Consumption Changes Drastically # Just searching for \u0026ldquo;WHEA\u0026rdquo; on Quasarzone yields countless posts.\nIn the past, numerous people reported these issues while using AMD Zen2/Zen3:\nWHEA 18 errors suddenly appear in the Windows Event Logger. The system suddenly shuts down. [Halt] (no logs found) The system suddenly resets. [Reset] (no logs found) These symptoms occur even when the system is idle. Disabling C-State reduces the frequency of these issues. \u0026ldquo;Just disable C-State.\u0026rdquo; I also experienced these issues when I was using a 3950X, and it cost me an enormous amount of time. Eventually, I went from the 3950X to a 5950X (a recent stepping revision), and in between, I temporarily used a 5900X that I purchased separately.\nThis led to a situation where my computers self-replicated and I ended up with two systems. I also purchased three motherboards during this process.\nIf you have read this far, you will have noticed a few key terms:\nKeyword 1 Keyword 2 Keyword 3 Instruction L1, L2 cache C-State Reset/Halt What is C-State? # Let me explain C-State first. Source: https://www.dell.com/support/kbdoc/ko-kr/000060621/c-state%EB%8A%94-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80\nC-State is a feature that reduces CPU power consumption, minimizing it as much as possible when the CPU is underutilized.\nIn practice, whether on AMD or Intel, the power consumption difference between C-State enabled and disabled during PC idle is quite significant when measured with a UPS \u0026ndash; around 10W to 20W. That difference alone is enough power to run one of the new Intel Alderlake N100 Mini PCs. Furthermore, this feature has been around since the 1990s, so it is essentially a well-established feature that should just work reliably.\nWhat is Instruction L1/L2 Cache? # Let me start with the memory model taught in undergraduate \u0026ldquo;Computer Architecture\u0026rdquo; courses in Computer Science departments.\n[Source: https://diveintosystems.org/book/C11-MemHierarchy/mem_hierarchy.html ]\nThe modern memory system is structured in this pyramid-like hierarchy.\nFrom registers at the very top, through cache, down to Flash Disk and beyond, access time and capacity scale proportionally as you go down.\nFrom the CPU\u0026rsquo;s perspective, accessing a register takes the shortest time, but the cost per area for registers is extremely high.\nThe further down you go, the more time it takes, but the cheaper it becomes.\nAlthough this diagram does not show the exact capacity differences between registers/cache/Main Memory, the allocation of capacity depending on the system and its purpose is very important. The key is in \u0026ldquo;how you divide it.\u0026rdquo; One thing the user can control is to just pack in as much DRAM as possible.\nSo what exactly is the Instruction L1/L2 cache?\nThe CPU needs cache not only for fast data access/reads,\nbut also for fast instruction execution.\nIf the data needed for reading or the instructions being processed are not in the cache, the CPU effectively stalls while fetching from DRAM (main memory). (We will not consider the pipelining concept here.)\nThe L1/L2 designation refers to levels: L1 is the space closest and fastest for each CPU core to access, while L2 is a slightly more distant level (though still much closer than DRAM).\nComing back to Zen2/3, the CPUs from the Zen2/3 generation with 16 cores have the highest core count. They adopted a multi-die structure, packaging two groups of 8 cores together.\nSo in reality, the memory model does not form a single pyramid shape as shown above. Instead, there are two pyramids on top of one pyramid, and on top of those two pyramids, there are 8 additional pyramids each.\nDetailed Report on the Symptoms Mentioned Above # The majority of users who build their own PCs use Windows. If you experienced the issues mentioned in this article,\nyou would have seen a WHEA18 error in the Windows Event Logger, or the system would have shut down (reset) or frozen (halt) without any error logged at all. Whether it is a reset or halt likely depends on the motherboard. I confirmed this by using Asrock/Gigabyte/Asus boards with B550/X570 chipsets, all three of which exhibited errors in different ways.\nTo analyze this problem accurately, we should not be looking at Windows but rather finding answers in the Linux community.\n[Correctable MCE errors logged for CPU0/CPU12 L1 instruction cache with AMD Ryzen 9 3900X 12-Core Processor] https://bugzilla.redhat.com/show_bug.cgi?id=1830404 [Random freezes and reboots AMD Ryzen] https://bugzilla.kernel.org/show_bug.cgi?id=210261 (There are many more reports beyond these two links, but I will only post these two for now.)\nThe threads themselves are very long, so here is a summary:\nAt random times, the errors below appear and the system freezes. And replacing the CPU just fixes it.\nEnabling C-State prevents or reduces the occurrence of the issue.\nMay 01 15:06:59 kernel: mce: [Hardware Error]: Machine check events logged May 01 15:06:59 kernel: [Hardware Error]: Corrected error, no action required. May 01 15:06:59 kernel: [Hardware Error]: CPU:12 (17:71:0) MC1_STATUS[Over|CE|MiscV|AddrV|-|-|SyndV|-|-|-]: 0xdc20000000030151 May 01 15:06:59 kernel: [Hardware Error]: Error Addr: 0x000000076da32ae0 May 01 15:06:59 kernel: [Hardware Error]: IPID: 0x000100b000000000, Syndrome: 0x000000001a030507 May 01 15:06:59 kernel: [Hardware Error]: Instruction Fetch Unit Ext. Error Code: 3, IC Data Array Parity Error. May 01 15:06:59 kernel: [Hardware Error]: cache level: L1, tx: INSN, mem-tx: IRD May 01 15:06:59 kernel: mce: [Hardware Error]: Machine check events logged May 01 15:06:59 kernel: [Hardware Error]: Corrected error, no action required. May 01 15:06:59 kernel: [Hardware Error]: CPU:0 (17:71:0) MC1_STATUS[Over|CE|MiscV|AddrV|-|-|SyndV|-|-|-]: 0xdc20000000030151 May 01 15:06:59 kernel: [Hardware Error]: Error Addr: 0x0000000fbedc2ae0 May 01 15:06:59 kernel: [Hardware Error]: IPID: 0x000100b000000000, Syndrome: 0x000000001a030507 May 01 15:06:59 kernel: [Hardware Error]: Instruction Fetch Unit Ext. Error Code: 3, IC Data Array Parity Error. May 01 15:06:59 kernel: [Hardware Error]: cache level: L1, tx: INSN, mem-tx: IRD Speculative Analysis of the Error Cause # This particular condition occurs extremely rarely (a CPU running at 3GHz or above executes 3,000,000,000 cycles per second, so from a cycle perspective, occurring once every 30 minutes to 24 hours is extremely rare \u0026ndash; but this is not saying it is rare from a user\u0026rsquo;s perspective).\nThe clue was found in the C-State feature mentioned above:\nIf C-State is enabled, the power delivered to the CPU core goes from very low to very high in a very short time. If C-State is disabled, the power delivered to the CPU core goes from slightly low to very high in a very short time. So the cause relates to the rapid change in power delivered to the CPU core affecting the CPU Instruction L1/L2 cache.\nWhile executing instructions, if the instructions themselves that the CPU fetches from the cache are corrupted, the CPU cannot execute them. It cannot proceed further, and in fact, even producing a core dump (memory dump) in this case would be a miracle. [Broadly speaking, there are two approaches to memory debugging: one is to back up the entire memory via software, and the other is to dump memory using hardware equipment that costs more than a luxury car. In this case, only the latter can provide a proper analysis.]\nWhile the contents of L1/L2 cache are said to be a mirror of DRAM (Main Memory), kept for faster access,\nin actual operating system and program design, variables like Linux\u0026rsquo;s per-cpu variables are typically sized to match or be smaller than each architecture\u0026rsquo;s L1 cache size as a block unit. In SMP (multi-core) systems, there are values where the address and memory information are stored in DRAM, but the accurate information is presumed to reside in the cache rather than DRAM, for faster read/write without going to DRAM. If L1/L2 becomes unreliable, variables with per-cpu-like characteristics (values used by computer programs) would become unusable, and this can similarly affect instructions.\nWhether the root cause is truly the rapid fluctuation in power delivered to the CPU is ultimately speculation,\nbut the fact that so many people are reporting L1/L2 cache problems is, in my personal opinion, recall-worthy.\nThe per-cpu details I mentioned later are not taught at the undergraduate level, but CPU L1/L2 cache is undergraduate-level knowledge, and there appears to be a fundamental design miss.\nDetailed link about per-cpu: http://jake.dothome.co.kr/per-cpu/\nHow Are AMD and Distributors Responding? # So how are AMD and distributors responding? Looking at how distributors check for defects: they boot the system and run a benchmark program. That is it. In reality, finding such problems is very difficult unless you use professional equipment like Trace32.\n[Source: https://www2.lauterbach.com/pdf/general_ref_c.pdf page 172]\nWith Trace32, you can observe all CPU values in real time. The most an average person or even most developers can do is access memory addresses, but there is no way to tell whether the value comes from DRAM or cache. While such advanced development tools are needed, it is practically impossible for distributors to perform after-sales service using these tools. Therefore, the service staff must also find themselves in a very difficult position regarding this issue.\nFrom the consumer\u0026rsquo;s perspective, proving this defect and getting an exchange is extremely difficult.\nIn my opinion, the fault lies with AMD.\nI believe the problem is that there were either QC failures initially, or that AMD failed to properly verify and fix these issues during silicon design before selling the product.\nSo does AMD publicly disclose or share information about defects in their CPUs?\nNo, they hide far more than Intel does.\nFor reference, Intel shared an Errata Sheet (a paper documenting design flaws and issues) for their recently released 13th generation:\n[ Intel Raptor Lake S - Errata Details ] https://edc.intel.com/content/www/us/en/design/products/platforms/details/raptor-lake-s/13th-generation-core-processor-specification-update/errata-details/\nHowever, AMD has not published Errata Sheets for the consumer Zen2: Family 17h Model 71h or Zen3: Family 19h Model 21h.\nThose who purchase chips to design their own PCB circuits or write Linux kernel drivers may have heard of Errata Sheets and have occasionally found problems there, leading them to re-select components or work around silicon bugs in software.\nIt is deeply disappointing that AMD has not issued any notice about such a serious problem and has instead relied on internet posts telling people to disable C-State while hiding these issues.\nI hope that AMD will change its ways and properly disclose defects in products that have serious issues with the memory hierarchy. I will close this article with a photo of a cat that loves memory. ","date":"2023年4月8日","externalUrl":null,"permalink":"/ja/posts/casts_double_amd_desktop_zen_2_and_3_halt_randomly_kr/","section":"Posts","summary":"It has been quite a while since ZEN4 started selling, and ZEN3 has also gone through several internal stepping/revision changes that seem to have improved things, so I feel this is an appropriate time to write this article. I originally posted this on other communities as well, and while it may seem tangential to development, it deals with CPU internals, so I am reposting it on my dev blog.\n","title":"Raising Suspicions of QC/Design Flaws Causing Intermittent Resets/Freezes in ZEN 2/3","type":"posts"},{"content":"","date":"2023年4月8日","externalUrl":null,"permalink":"/ja/tags/ryzen/","section":"Tags","summary":"","title":"Ryzen","type":"tags"},{"content":"","date":"2023年4月8日","externalUrl":null,"permalink":"/ja/tags/silicon-bug/","section":"Tags","summary":"","title":"Silicon Bug","type":"tags"},{"content":" 1. Fourier series coefficients for Continuous signal # Asking deriving coefficients comes with periodic signal.: \\(x(t) \\rightarrow a_k\\)\n1.1 (CT FS) Basic concept of continuous Fourier coefficients # $$ \\begin{gathered} x(t): \\text { Periodic signal } \\ T: \\text { Fundamental Period } \\ \\end{gathered} $$\n$$ \\begin{gathered} \\omega_0=\\frac{2 \\pi}{T} \\quad \u0026amp; \\quad f_0=\\frac{1}{T}(\\text { freq }) \\ \\end{gathered} $$\n$$ \\begin{gathered} \\quad x(t)=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k \\omega_0 t}=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k(2 \\pi / T) t} \\end{gathered} $$\n1.2 (CT FS) Continuous-Time, Fourier Series # Convert periodic signal to fourier coefficients : \\(x(t) \\stackrel{F S}{\\rightarrow} a_k\\)\n$$ \\begin{gathered} a_k=\\frac{1}{T} \\int _T x(t) e^{-j k \\omega_0 t} d t \\ \\end{gathered} $$ $$ or $$\n$$ \\begin{gathered} a_k=\\frac{1}{T} \\int_T x(t) e^{-j k(2 \\pi / T) t} d t \\end{gathered} $$\n1.3 (CT IFS) Continuous-Time, Inverse Fourier Series # Fourier coefficients to peridoic signal : \\(a_k \\stackrel{I F S}{\\longrightarrow} x(t)\\)\n$$ x(t)=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k \\omega_0 t}=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k(2 \\pi / T) t} $$\n1.4 Properties of Continuous-Time Fourier Series # Fourier transform for Continuous-time signal \\(x(t)\\) Most of case, aperiodic signals comes...\n2. Fourier coefficients for Discrete signal # $$ \\begin{gathered} x[n] \\rightarrow \\boldsymbol{a}_{\\boldsymbol{k}} \\end{gathered} $$ Asking deriving coefficients comes with periodic signal.\n2.1 (DT FS) Basic concept of discrete Fourier coefficients \\(x[n]: Periodic\\) # $$ \\begin{gathered} x[n]: \\text { Periodic signal } \\end{gathered} $$\n$$ N \\text { : Fundamental Period (LCM of } 2 \\pi \\text { ) } $$\n$$ \\begin{gathered} \\omega_0=\\frac{2 \\pi}{N} \\quad \u0026amp; \\quad f_0=\\frac{1}{T}(\\text { freq }) \\end{gathered} $$\n$$ x[n]=\\sum_{k=\\langle N\\rangle} a_k e^{j k \\omega_0 n}=\\sum_{k=\\langle N\\rangle} a_k e^{j k(2 \\pi / N) n} $$\n2.3 (DT FS) Discrete-Time, Fourier Series # $$\\begin{gathered} a_{k}=\\frac{1}{N} \\sum_{n=\\langle N\\rangle} x[n] e^{-j k \\omega_{0} n} \\ a_{k}=\\frac{1}{N} \\sum_{n=\\langle N\\rangle} x[n] e^{-j k(2 \\pi / N) n} \\end{gathered}$$\n$$\\begin{aligned} \u0026amp; x[n] \\stackrel{F S}{\\rightarrow} a_{k} \\end{aligned}$$\n2.4 (DT IFS) Discrete-Time, Inverse Fourier Series # $$a_{k} \\stackrel{I F S}{\\rightarrow} x[n] \\quad x[n]=\\sum_{k=\\langle N\\rangle} a_{k} e^{j k \\omega_{0} n}=\\sum_{k=\\langle N\\rangle} a_{k} e^{j k(2 \\pi / N) n}$$\n2.5 Properties of Continuous-Time Fourier Series # 3 Fourier transform for Continuous-time signal \\(x(t)\\) : # 3.1 (CT FT) Continuous-Time, Fourier Transform ( periodic) # $$ x(t) \\stackrel{F T}{\\longrightarrow} X(j \\omega) $$\n$$ \\tilde{x}(t): \\text { single sliced periodic sig } \\ $$\n$$ a_k=\\frac{1}{T} \\int_{-\\frac{T}{2}}^{\\frac{T}{2}} \\tilde{x}(t) e^{-j k \\omega_0 t} d t $$ $$ X(j \\omega)=T a_k $$\n3.2 (CT FT) Continuous-Time, Fourier Transform (aperiodic) # $$x(t) \\stackrel{F T}{\\rightarrow} X(j \\omega) \\quad X(j \\omega)=\\int_{-\\infty}^{+\\infty} x(t) e^{-j \\omega t} d t$$\n3.3 (CT IFT) Continuous-Time, Inverse Fourier Transform # $$X(j w) \\stackrel{I F T}{\\rightarrow} x(t) \\quad x(t)=\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} X(j \\omega) e^{j \\omega t} d \\omega$$\n3.4 Properties of Continuous Fourier Transform # 3.5 Basic Continuous Fourier Transform Pairs # 4 Fourier transform for Discrete-time signal \\(x[n]\\) # Most of case, aperiodic signals comes…\n4.1 (DT FT) Discrete-Time, Fourier Transform # $$x[n] \\stackrel{F T}{\\rightarrow} X\\left(e^{j \\omega}\\right) \\quad X\\left(e^{j \\omega}\\right)=\\sum_{n=-\\infty}^{+\\infty} x[n] e^{-j \\omega n}$$\n4.2 (DT IFT) Discrete-Time, Inverse Fourier Transform # $$X\\left(e^{j \\omega}\\right) \\stackrel{I F T}{\\rightarrow} x[n] \\quad x[n]=\\frac{1}{2 \\pi} \\int_{2 \\pi} X\\left(e^{j \\omega}\\right) e^{j \\omega n} d \\omega$$\n4.3 Properties of Discrete Fourier Transform # 4.4 Basic Discrete Fourier Transform Pairs # PDF version # Related files DSP_Fourier_CheatNote.pdf (275 KBytes) ","date":"2022年12月20日","externalUrl":null,"permalink":"/ja/posts/discrete_signal_processing_cheat_note/","section":"Posts","summary":"1. Fourier series coefficients for Continuous signal # Asking deriving coefficients comes with periodic signal.: \\(x(t) \\rightarrow a_k\\)\n","title":"Discrete Signal Processing Fourier Transform Cheat Note","type":"posts"},{"content":"","date":"2022年12月20日","externalUrl":null,"permalink":"/ja/tags/dsp/","section":"Tags","summary":"","title":"DSP","type":"tags"},{"content":"","date":"2022年12月20日","externalUrl":null,"permalink":"/ja/tags/english_article/","section":"Tags","summary":"","title":"English_Article","type":"tags"},{"content":"","date":"2022年12月20日","externalUrl":null,"permalink":"/ja/categories/math/","section":"Categories","summary":"","title":"Math","type":"categories"},{"content":"","date":"2022年12月20日","externalUrl":null,"permalink":"/ja/tags/mathmatics/","section":"Tags","summary":"","title":"Mathmatics","type":"tags"},{"content":"","date":"2022年12月20日","externalUrl":null,"permalink":"/ja/tags/signal-processing/","section":"Tags","summary":"","title":"Signal Processing","type":"tags"},{"content":"I have been using Rust at the company I recently joined. Five months have passed since I switched jobs, and I would like to describe what I have felt so far. Setting aside the detailed syntactic advantages, I will simply describe my general impressions.\nPros # If there is a developer who knows the domain well and at least two people conduct thorough code reviews for each other, you can code safely. Compared to C, there are many conveniences. As someone who only worked with C and firmware, Rust feels more familiar compared to other modern languages, and most behaviors/designs feel reasonable. In my personal opinion, Rust can be applied to many areas except frontend. [Firmware, OS-dependent utilities, backend] You continuously encounter study/challenge opportunities related to pure CS, rather than just business logic. Regardless of what target architecture (CPU, Operating System) comes along, it is very convenient to adapt. Cons # Can we go beyond FullStack and become EntireStack developers?\nEach difficulty point fundamentally requires a large base of knowledge. Occasionally, the study/challenge demands spill over into personal time. [This is not a con for me, but I think some people may feel it is.] There are significant limitations when hiring. When asked \u0026ldquo;What are the advantages of this language?\u0026rdquo;, the scope of required knowledge inevitably becomes very broad. And that scope of knowledge may lie far beyond most people\u0026rsquo;s areas of interest. If you use it in embedded and look at the domestic developer pool, it is difficult to find embedded developers who will use Rust together, and the range of additional skills required of embedded developers grows almost exponentially. Even without considering Rust, the pool of embedded developers is simply too small, although embedded development is not my primary work. The chip I want to use always has ambiguous Rust embedded support. (The answer to this is for me to contribute myself.) The community is still more focused on chips suitable for toy projects rather than chips that are practical in terms of cost/lead time during the chip shortage situation. Miscellaneous # I was very strict about code reviews at my previous company and was worried about how things would be at my current company. My initial impression was that since Rust\u0026rsquo;s syntax is more sophisticated than C, individual coding styles varied too much, and I thought this would be a bottleneck during reviews. However, clippy handles a lot of that, and as long as there is typo checking and a reasonable level of agreed-upon tests, reviews are not a problem. We can naturally have healthy discussions about CS topics with each other. Proper Support for Multiple Architectures # In theory and concept, pure interpreted languages are advantageous for multi-platform support. However, my actual experience with Rust has led me to feel differently. No matter how theoretically advantageous interpreted languages are supposed to be, for truly and properly supporting all architectures (various CPU architectures and multiple OSes), Rust was extremely convenient.\nFirst of all, properly supporting all architectures is one of the key values of systems programming or firmware programming. So what languages were traditionally used for this kind of programming? That would be C and C++. However, to quickly get started (Getting Start) with these languages, you first had to set up Makefile or CMake configurations, and every time a new architecture was added, you had to accommodate it. On top of that, setting up the compiler, development environment, and libraries for each architecture was a separate task entirely.\nLet me compare with another language. Currently, almost nobody compares Go-Lang and Rust, but five years ago, many people did. When comparing the systems programming domain only on top of an OS, both are excellent languages. What I am about to say is quite a stretch, but in Rust\u0026rsquo;s conceptual no-std scenario \u0026ndash; where there is no OS or the OS is very different from a typical one \u0026ndash; it is difficult to adapt. [The author previously worked in firmware development and is also evaluating whether production-grade firmware development is feasible.]\nRust Is Difficult for Quick Prototyping Right Away # In the previous sections, I praised Rust\u0026rsquo;s advantages, but in this section, I will describe some slightly disappointing aspects. Rust is a difficult language to write. More precisely, it is very difficult to develop in a Rust-like way that maximizes Rust\u0026rsquo;s strengths. Realistically, it would be very difficult with any language to fully leverage its strengths during development. However, if Rust is chosen for commercial purposes (as a language/framework for a company/development team), personal preferences should be set aside in favor of the company\u0026rsquo;s perspective.\nIs it a medium that can realize what we want to develop? Can we adequately recruit developers? How much development time does it require? Does it run fast and correctly? Do the team members want to use it? (In other words, preference.) Rust is likely to score low on items (2) and (3), and I believe this is absolutely the case for (2) in particular.\nIf Rust must be chosen despite these drawbacks, it would largely be due to (4) and (5). In that case, the development team and developers would need tangible events or results that highlight Rust\u0026rsquo;s advantages in order to sustain its use, whether voluntarily or otherwise.\nEven though you can just use whatever language the company assigns, if you have a choice and want to keep using Rust, you would want to highlight its merits. (This is a somewhat difficult topic to articulate, as it overlaps with emotional territory.)\nThen, to develop in a way that maximizes Rust\u0026rsquo;s strengths, a great deal of knowledge is required. In other words, the learning curve becomes steep. Depending on how you look at it, this can be either digging your own grave or creating an opportunity.\nBut an Opportunity to Gain Tremendous Intellectual Value # When C was first created, concepts like multi-processing/processors (SMP), caching, and GPGPU did not exist, and in many details, it was an era with a different memory model from today\u0026rsquo;s. And to this day, C is used to handle these aspects. When you find yourself in a situation where you must develop with these concepts in mind, there are many difficulties.\nHowever, Rust has infrastructure in place to overcome these challenges to some degree, with room for more to come. And while this is an ambiguous statement, through Rust, it feels like opportunities are created to more closely examine the difficult architectural designs of computers and operating systems, albeit indirectly. This can be gained through Rust compiler\u0026rsquo;s safety constraints and warnings, and I believe it is also driven by the influence of a community populated by many expert-level systems programmers. Speaking a bit more about multi-platform support, I also believe that the strength of the community is why multi-platform support is handled so well.\nWhen Can We Say We Have Become Proficient Rust Developers? # People occasionally say things like \u0026ldquo;I am a ____ developer.\u0026rdquo; So when can we say that we have become proficient Rust developers?\nThere is no definitive answer.\nHowever, in my personal opinion, if you can explain the advantages that a given framework or language provides in a way that others can understand, then perhaps you can call yourself a ____ developer.\nBut unfortunately, with Rust, this is very difficult to articulate. You have to start by explaining ownership. And to do that, you first need to understand the stack and heap of a running process.\nReference: 4.1 What is Ownership - The Rust Programming Language Korean Translation\nBecause of this, you either need the ability to explain a great deal to the person you are trying to convince, or the listener must be at a high level, requiring precise and very deep explanations.\nIt is unfortunate that the difficulty level of explanation starts at HARD MODE from the get-go, but we do not develop alone. If we truly want to submit a Pull Request, I think it is necessary to explain well to the reviewer, or to write code in a way that makes explanations easier.\nThrough that process, you can build the knowledge base and communication skills needed to explain things, and going further, I think you can develop the ability to explain any given technology as described above.\nThe next time (or the time after) I write a retrospective, I plan to cover the actual gains and losses from using Rust at work.\n","date":"2022年11月27日","externalUrl":null,"permalink":"/ja/posts/five_mothes_ago_from_using_rust_as_work_kr/","section":"Posts","summary":"I have been using Rust at the company I recently joined. Five months have passed since I switched jobs, and I would like to describe what I have felt so far. Setting aside the detailed syntactic advantages, I will simply describe my general impressions.\n","title":"About Five Months After Using Rust at Work","type":"posts"},{"content":"","date":"2022年11月27日","externalUrl":null,"permalink":"/ja/categories/etc/","section":"Categories","summary":"","title":"Etc","type":"categories"},{"content":"","date":"2022年10月4日","externalUrl":null,"permalink":"/ja/tags/armv8a/","section":"Tags","summary":"","title":"ARMv8A","type":"tags"},{"content":"","date":"2022年10月4日","externalUrl":null,"permalink":"/ja/tags/cross-compile/","section":"Tags","summary":"","title":"Cross Compile","type":"tags"},{"content":"In October 6, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nCurrent linux 6.1 rc1 doesn\u0026rsquo;t contain rust for linux with ARM64. Thus this article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\nIntroduction # This article describes cross-compiling rust for linux on x86_64 debian. There is still not enough computing power to build arm64 native kernel except for Apple Silicon.\nBtw, this article is in reference to these links\nhttps://github.com/Rust-for-Linux/linux/blob/rust/Documentation/rust/quick-start.rst https://docs.kernel.org/kbuild/llvm.html#cross-compiling Debian / Ubuntu Package Requirements # # Install build-requirements for kernel compile with LLVM. # Biggest difference to native build is # crossbuild-essential-arm64 needed to build` for arm64 apt install clang git llvm-dev libclang-dev build-essential \\ bc kmod cpio flex libncurses5-dev libelf-dev libssl-dev \\ dwarves bison lld curl crossbuild-essential-arm64 Before build kernel, we need to install some packages.\ncurl --proto \u0026#39;=https\u0026#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh rustup default 1.62 rustup component add rust-src # rustfmt and clippy is need for later developing and debugging. rustup component add rustfmt rustup component add clippy Install rust with curl. You can select just default options. Also current rust for linux working with 1.62. Some native compile is working well with recent version (1.64 tested, but cross compile not working).\nArch Package Requirements # TBD Clone linux from Rust-For-Linux # State of current rust-for-linux, they are under 6.0 RC\n# In my case use `Develop` as worksapce, you can replace this word. mkdir -p ~/Develop cd ~/Develop git clone https://github.com/Rust-for-Linux/linux.git -b rust clone like this.\nNecessary some rust scripts in Rust-For-Linux # In cloned linux directory.\ngit clone --recurse-submodules \\ --branch $(scripts/min-tool-version.sh rustc) \\ https://github.com/rust-lang/rust \\ $(rustc --print sysroot)/lib/rustlib/src/rust This work clone rustlib repository in your rust toolchain directory.\ncargo install --locked --version $(scripts/min-tool-version.sh bindgen) bindgen This work need to bind existing c code to rust code. s\nCheck RUST_AVAILABLE # cd ~/Develop/linux make LLVM=1 rustavailable $ make LLVM=1 rustavailable *** *** Rust compiler \u0026#39;rustc\u0026#39; is too new. This may or may not work. *** Your version: 1.62.1 *** Expected version: 1.62.0 *** Rust is available! Than if you get result like this it\u0026rsquo;s good to go (1.62.1 was fine to cross compile, but if you consider best fit, run rustup default 1.62.0.)\nConfigure linux source code with menuconfig # make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- defconfig make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- menuconfig General setup -\u0026gt; Rust support # In General setup -\u0026gt; Rust support , Enable this If you don\u0026rsquo;t see the flag, double-check that the make LLVM=1 rustavailable process was successful. For a detailed mailing thread on CONFIG_RUST see here. See details \u0026rharu; Kernel hacking -\u0026gt; Sample kernel code # For easy to develop rust kernel code we need some examples. You can get them with following menus.\nIn Kernel hacking -\u0026gt; Sample kernel code , enable it (not all of them..) when you interest. I don\u0026rsquo;t recommend you enable them when you write own driver. Because there\u0026rsquo;s some possibility make system slow or make unwanted log in dmesg. In particular, the netflitter example outputs too many dmesg, so it is recommended that you disable it unless you are studying the netfilter example. Kernel hacking -\u0026gt; Rust hacking # For debug rust kernel code or driver, need to enable some debug options.\nIn Kernel hacking -\u0026gt; Rust hacking , enables it and inside menus.\nCross compile # # -j4 for 4 core virtual machine, -j2 for 2 core, -j1 for single core. make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- LLVM=1 -j32 Build with following command. You need to set number of job considering assigned number of cores for virtual machine. (-j#)\nAlso while you build it, it will ask some flag. I just select default in my case.\nSimple compile speed comparation. # Machine / Environment Compile time M1 Max Virtual Machine (4 core 8GB RAM with aarch64 debian11) 16 minutes M1 Asahi Linux (4P+4E core 16GB RAM MacMini with 6.1.0-rc6-asahi) 11 minutes AMD Ryzen 5950x Native (16 core 32 thread, 64GB with x86_64) 3 minutes AMD Threadripper Pro 5975wx Native (32 core 64 thread, 256GB with x86_64) 2 minutes Install cross compiled kernel to arm64 virtual machine # TBD, will update asap. Install cross compiled kernel to raspberry pi # TBD, will update asap. ","date":"2022年10月4日","externalUrl":null,"permalink":"/ja/posts/cross_compiling_aarch64_rust_for_linux_from_x86_64_linux/","section":"Posts","summary":"In October 6, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nCurrent linux 6.1 rc1 doesn’t contain rust for linux with ARM64. Thus this article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\n","title":"Cross compiling aarch64(arm64) rust for linux from x86_64 machine","type":"posts"},{"content":"","date":"2022年10月4日","externalUrl":null,"permalink":"/ja/categories/linux/","section":"Categories","summary":"","title":"Linux","type":"categories"},{"content":"","date":"2022年10月4日","externalUrl":null,"permalink":"/ja/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"In October, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nmodules, out-of-tree # There are two main ways to develop kernel modules. In-Of-Tree and Out-Of-Tree. In this article, we\u0026rsquo;re going to make the Out-Of-Tree method a Rust kernel module.\nBefore we start # Check your kernel has been compiled with CONFIG_RUST=y. # Check with following command.\nzcat /proc/config.gz | grep -i CONFIG_RUST=y The result comes with CONFIG_RUST=y.\nBut you may not check from /proc/config.gz when using distibution kernel image that downloaded or pre-installed.\nNeed some build \u0026 install rust support kernel see here. See details \u0026rharu; Prepare $KDIR # $KDIR is path of kernel source.\nIn this article path of kernel source that system used for boot with CONFIG_RUST.\nKDIR and other kernel module descriptions See details \u0026rharu; In my case it\u0026rsquo;s ~/Develop/linux\n# /home/pmnxis/Develop/linux export KDIR=$HOME/Develop/linux Looking in to code # Let\u0026rsquo;s preview the code rust_out_of_tree.rs \u0026hellip;\nLicense and imports # 1 2 3 4 5 6 7 8 9 10 11 12 13 // SPDX-License-Identifier: GPL-2.0 //! Rust out-of-tree sample use kernel::prelude::*; module! { type: RustOutOfTree, name: \u0026#34;rust_out_of_tree\u0026#34;, author: \u0026#34;Rust for Linux Contributors\u0026#34;, description: \u0026#34;Rust out-of-tree sample\u0026#34;, license: \u0026#34;GPL\u0026#34;, } Lines 1~3, show file\u0026rsquo;s license information. If you are write the code in company, SomeCompanyName instead GPL-2.0 or just keep GPL-2.0. 1 2 3 4 5 6 7 8 9 10 11 12 13 // SPDX-License-Identifier: GPL-2.0 //! Rust out-of-tree sample use kernel::prelude::*; module! { type: RustOutOfTree, name: \u0026#34;rust_out_of_tree\u0026#34;, author: \u0026#34;Rust for Linux Contributors\u0026#34;, description: \u0026#34;Rust out-of-tree sample\u0026#34;, license: \u0026#34;GPL\u0026#34;, } Line 5 means, bring rust for linux library for this code.\nIn following example module written in C were include like this.\n2 3 4 #include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kthread.h\u0026gt; #include \u0026lt;linux/irq_work.h\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 // SPDX-License-Identifier: GPL-2.0 //! Rust out-of-tree sample use kernel::prelude::*; module! { type: RustOutOfTree, name: \u0026#34;rust_out_of_tree\u0026#34;, author: \u0026#34;Rust for Linux Contributors\u0026#34;, description: \u0026#34;Rust out-of-tree sample\u0026#34;, license: \u0026#34;GPL\u0026#34;, } Line 8, implement of the module trait. Line 9, name of the module, if we written c, it\u0026rsquo;s the name of *.ko name field. Line 10~12, those fields are simillar with below the example written in c. Those fields are same purpose.\n56 57 58 MODULE_AUTHOR(\u0026#34;Steven Rostedt\u0026#34;); MODULE_DESCRIPTION(\u0026#34;trace-printk\u0026#34;); MODULE_LICENSE(\u0026#34;GPL\u0026#34;); We preview macro_rule! module shortly. You can see detail here.\nDetails for module! See details \u0026rharu; Actual implements # 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 struct RustOutOfTree { numbers: Vec\u0026lt;i32\u0026gt;, } impl kernel::Module for RustOutOfTree { fn init(_name: \u0026amp;\u0026#39;static CStr, _module: \u0026amp;\u0026#39;static ThisModule) -\u0026gt; Result\u0026lt;Self\u0026gt; { pr_info!(\u0026#34;Rust out-of-tree sample (init)\\n\u0026#34;); let mut numbers = Vec::new(); numbers.try_push(72)?; numbers.try_push(108)?; numbers.try_push(200)?; Ok(RustOutOfTree { numbers }) } } impl Drop for RustOutOfTree { fn drop(\u0026amp;mut self) { pr_info!(\u0026#34;My numbers are {:?}\\n\u0026#34;, self.numbers); pr_info!(\u0026#34;Rust out-of-tree sample (exit)\\n\u0026#34;); } } I just guess working as \u0026hellip;\nOn init (insmod?), print out somewhere with text Rust out-of-tree sample (init) vec\u0026lt;i32\u0026gt;[72, 108, 200] is stored some kernel memory space with struct RustOutOfTree. When drop the module (rmmod?), will print out with text [72, 108, 200]. By the way, we need to keep on eyes here.\n23 24 let mut numbers = Vec::new(); numbers.try_push(72)?; In line 24, try_push is not exsting in std::Vec. In rust kernel programming, need to use try_push instead std::Vec::push.\nDetails for alloc::vec::Vec See details \u0026rharu; Also there's some `init` and `drop` functions in line 20 and 33. The code covers those function with `impl for` pattern. Details for Implementation in rust See details \u0026rharu; I will explain about implementation and it\u0026rsquo;s philosophy later article.\nRun code # Build it # make LLVM=1 My rust acceptable kernel build were buiten with LLVM.\nSo I compile the kernel module with LLVM.\nInstall module # sudo insmod ./rust_out_of_tree.ko After compile, we can there\u0026rsquo;s rust_out_of_tree.ko inside of project directory.\nWe can install module with insmod that normally used before.\nInspect result # # do `sudo rmmod rust_out_of_tree` if you already install the module` # clear all of dmesg log sudo dmesg -C # install the module sudo insmod ./rust_out_of_tree.ko # see log dmesg # uninstall the module sudo rmmod rust_out_of_tree # check log again. dmesg We can check the inspect actual result with above commands.\nAs we guess it prints with [72, 108, 200].\nConclusion # We can summary from this simple kernel module.\nSummary # Need to use use kernel::prelude::*; on top of code. module! macro to define some description and board my own struct to the kernel module. kernel::Module templete functions \u0026hellip;. -WIP- In kernel programming, use alloc::vec::Vec instead std::Vec. pr_info is just same as way to write with C. Reference # https://github.com/Rust-for-Linux/rust-out-of-tree-module https://www.kernel.org/doc/html/latest/kbuild/modules.html https://github.com/Rust-for-Linux/linux https://rust-for-linux.github.io/docs/kernel/prelude/index.html https://rust-for-linux.github.io/docs/kernel/prelude/macro.module.html https://rust-for-linux.github.io/docs/kernel/prelude/struct.Vec.html ","date":"2022年10月2日","externalUrl":null,"permalink":"/ja/posts/look_into_simple_rust_out_of_tree/","section":"Posts","summary":"In October, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nmodules, out-of-tree # There are two main ways to develop kernel modules. In-Of-Tree and Out-Of-Tree. In this article, we’re going to make the Out-Of-Tree method a Rust kernel module.\n","title":"[Rust Driver] Let's try build example rust linux driver.","type":"posts"},{"content":"","date":"2022年10月2日","externalUrl":null,"permalink":"/ja/tags/rust-driver/","section":"Tags","summary":"","title":"Rust Driver","type":"tags"},{"content":"In October 1, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nThis article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\nIntroduction # Currently Apple Silicon mac series is only one ARM workstation that have powerful performance as normal desktop class workstation and can purchase anywhere. Of course if you have 32GB or bigger memory and least 8 big cores of apple silicon.\nBtw, this article is in reference to https://github.com/Rust-for-Linux/linux/blob/rust/Documentation/rust/quick-start.rst .\nVM hypervisor software selection. # UTM : Free / OpenSource, QEMU based Sometimes tricky. VM Fusion Tech Preview : Free for now / ClosedSource, Moderate Parallels : Non-Free / ClosedSource, not my taste (sorry). There\u0026rsquo;s some option working with Asahi Linux. But in this article is not consider native asahi linux environment.\nIn my case, I was chosen VM Fusion.\nVirtual Machine Configuration # Debian 11 : https://cdimage.debian.org/debian-cd/current/arm64/iso-dvd/ !! Checked working well.\nUbuntu : There were some issue clang and other gcc build tools version mismatch than broken apt things in aarch64 ubuntu apt repo. But you can try with ubuntu.\nArch Linux : https://gitlab.archlinux.org/tpowa/archboot/-/wikis/Archboot-Homepage#aarch64-architecture I didn\u0026rsquo;t tested yet. But tested with Asahi linux with M1 Mac Mini\nDebian / Ubuntu Package Requirements # # Install build-requirements for kernel compile with LLVM. apt install clang git llvm-dev libclang-dev build-essential \\ bc kmod cpio flex libncurses5-dev libelf-dev libssl-dev \\ dwarves bison lld curl Asahi Linux Package Requirements # pacman -S base-devel cpio lld llvm llvm-libs bc libdwarf Ready for rust # Before build kernel, we need to install some packages.\ncurl --proto \u0026#39;=https\u0026#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh rustup default 1.62 rustup component add rust-src # rustfmt and clippy is need for later developing and debugging. rustup component add rustfmt rustup component add clippy Install rust with curl. You can select just default options. Also current rust for linux working with 1.62. Some native compile is working well with recent version (1.64 tested, but cross compile not working).\nClone linux from Rust-For-Linux # State of current rust-for-linux, they are under 6.0 RC\n# In my case use `Develop` as worksapce, you can replace this word. mkdir -p ~/Develop cd ~/Develop git clone https://github.com/Rust-for-Linux/linux.git -b rust clone like this.\nNecessary some rust scripts in Rust-For-Linux # In cloned linux directory.\ngit clone --recurse-submodules \\ --branch $(scripts/min-tool-version.sh rustc) \\ https://github.com/rust-lang/rust \\ $(rustc --print sysroot)/lib/rustlib/src/rust This work clone rustlib repository in your rust toolchain directory.\ncargo install --locked --version $(scripts/min-tool-version.sh bindgen) bindgen This work need to bind existing c code to rust code. s\nCheck RUST_AVAILABLE # cd ~/Develop/linux make LLVM=1 rustavailable $ make LLVM=1 rustavailable *** *** Rust compiler \u0026#39;rustc\u0026#39; is too new. This may or may not work. *** Your version: 1.64.0 *** Expected version: 1.62.0 *** Rust is available! Than if you get result like this it\u0026rsquo;s good to go\nConfigure linux source code with menuconfig # make ARCH=arm64 defconfig make menuconfig Disable GCC plugins # General architecture-dependent options -\u0026gt; GCC plugins For now (6.1 rc*), GCC_PLUGINS config should be disabled for RUST_CONFIG config. Be sure disable it.\nGeneral setup -\u0026gt; Rust support # In General setup -\u0026gt; Rust support , Enable this If you don\u0026rsquo;t see the flag, double-check that the make LLVM=1 rustavailable process was successful. For a detailed mailing thread on CONFIG_RUST see here. See details \u0026rharu; Kernel hacking -\u0026gt; Sample kernel code # For easy to develop rust kernel code we need some examples. You can get them with following menus.\nIn Kernel hacking -\u0026gt; Sample kernel code , enable it (not all of them..) when you interest. I don\u0026rsquo;t recommend you enable them when you write own driver. Because there\u0026rsquo;s some possibility make system slow or make unwanted log in dmesg. In particular, the netflitter example outputs too many dmesg, so it is recommended that you disable it unless you are studying the netfilter example. Kernel hacking -\u0026gt; Rust hacking # For debug rust kernel code or driver, need to enable some debug options.\nIn Kernel hacking -\u0026gt; Rust hacking , enables it and inside menus.\nCompile and install it in virtual machine. # # -j4 for 4 core virtual machine, -j2 for 2 core, -j1 for single core. make LLVM=1 -j4 Build with following command. You need to set number of job considering assigned number of cores for virtual machine. (-j#)\nAlso while you build it, it will ask some flag. I just select default in my case.\nIt takes lot of time (don\u0026rsquo;t worry much better than raspberry pi 4), 13~14 minuites takes in my environment (VM 4core, 8GB)\nAfter than, install via following command\n# should be under the root permision. make modules_install make install update-grub It\u0026rsquo;s done!. Reboot program and then check the kernel working well.\nLinux lambda-next 6.0.0-rc7-175589-g542379556669 #2 SMP PREEMPT Sun Oct 2 19:02:32 KST 2022 aarch64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Sun Oct 2 18:20:21 2022 from 192.168.99.1 pmnxis@lambda-next:~$ uname -r 6.0.0-rc7-175589-g542379556669 Simple compile speed comparation. # Machine / Environment Compile time M1 Max Virtual Machine (4 core 8GB RAM with aarch64 debian11) 16 minutes M1 Asahi Linux (4P+4E core 16GB RAM MacMini with 6.1.0-rc6-asahi) 11 minutes AMD Ryzen 5950x Native (16 core 32 thread, 64GB with x86_64) 3 minutes AMD Threadripper Pro 5975wx Native (32 core 64 thread, 256GB with x86_64) 2 minutes ","date":"2022年10月1日","externalUrl":null,"permalink":"/ja/posts/rust_for_linux_with_m1/","section":"Posts","summary":"In October 1, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nThis article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\n","title":"Rust For Linux Development Environment with AppleSilicon MacOS","type":"posts"},{"content":" Introduction # ARMv8A, also commonly known as aarch64, is one of the widely used architectures that has largely succeeded ARMv7A. In this article, we will examine the ARMv8A memory system at the IP (Intellectual Property) block level.\nWhile there are slight differences depending on the memory type used (DDR4, LPDDR4, DDR3, LPDDR3, DDR2) and the architecture version (ARM v8.1 or 8.2), the overall structure generally follows the form shown in the diagram above.\nComponents # CPU # Processes instructions.\nGIC # Generic Interrupt Controller; The GIC manages various nested interrupts. When an interrupt occurs, it backs up the PC/registers that were active on the CPU and directs execution to the corresponding interrupt vector.\nCCI / CCN # Cache Coherent Interconnect / Network\nDMC # Manages DRAM. DRAM is volatile memory that requires operations beyond simple Read/Write, such as Refresh and Calibration. Additionally, it handles ECC and RAS management. In the Linux driver codebase, you can find the ECC and RAS management driver code under the edac directory.\nNIC # Used to connect various peripherals.\nMMU # PA/VA (Physical/Virtual Address) translation DMA control Reference # CCI-400 ; https://developer.arm.com/Processors/CoreLink%20CCI-400 CCI-500 ; https://developer.arm.com/Processors/CoreLink%20CCI-500 DMC-400 ; DDR3/DDR2 DMC ; https://developer.arm.com/documentation/ddi0466/f/introduction/about-the-dmc-400 DMC-500 ; LPDDR4/LPDDR3 DMC ; https://developer.arm.com/documentation/100131/0000 ","date":"2021年12月14日","externalUrl":null,"permalink":"/ja/posts/arm_v8a_memory_ip_review/","section":"Posts","summary":"Introduction # ARMv8A, also commonly known as aarch64, is one of the widely used architectures that has largely succeeded ARMv7A. In this article, we will examine the ARMv8A memory system at the IP (Intellectual Property) block level.\n","title":"ARMv8A Memory IP Review","type":"posts"},{"content":"","date":"2021年12月14日","externalUrl":null,"permalink":"/ja/tags/electronics/","section":"Tags","summary":"","title":"Electronics","type":"tags"},{"content":"","externalUrl":null,"permalink":"/ja/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/ja/series/","section":"Series","summary":"","title":"Series","type":"series"}]