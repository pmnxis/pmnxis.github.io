[{"content":"","date":"13 November 2023","externalUrl":null,"permalink":"/en/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":" WARN! This article is still a work in progress. Content may change at any time. Before Reading # This post is a continuation of the previous post Part 3: Leave It to Compile Time, but focuses on build.rs rather than const fn/trait/impl.\nIf you are not familiar enough with Rust syntax, I recommend reading the #Studying-Rust section in the previous post Part 2: Study Methods and Key Characteristics. I also recommend the excellent article by Ki-O Kim, A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust.\nBuild Scripts (build.rs) # Just as C and C++ have Makefiles, Rust has Cargo. Cargo provides build.rs, which allows you to easily write scripts that run before compilation begins.\nFor detailed documentation on build.rs, see: The Cargo Book - Build Scripts\nbuild.rs runs before compiling the source code in the src directory or external libraries. Importantly, even if you are developing code for no_std, build.rs can use libraries available on the host OS, including no_std and the alloc crate.\nA separate program in main.rs must create const data at compile time, but there are cases where the functions and methods you need are not available in const form.\nFetching Strings with build.rs and env!() # Let us practice fetching a string (\u0026amp;str) at compile time using build.rs and the env!() macro.\nThe project structure looks like this. build.rs is not in the src directory; it goes in the root directory of the project.\nCargo.toml Example # # End of Cargo.toml [build-dependencies] chrono = \u0026#34;0.4.31\u0026#34; As mentioned above, build.rs can use libraries available for OS targets. If there is a crate you want to use, add it under build-dependencies below dependencies. Here we have added the chrono crate for our example.\nbuild.rs Example # // build.rs fn main() { let now = chrono::Utc::now().to_rfc3339(); println!(\u0026#34;cargo:rustc-env=GIVEN_BUILD_TIME={}\u0026#34;, now); } When Cargo compiles and runs build.rs, it uses the chrono library to get the current time in UTC and converts it to a String.\nThen it passes it to rustc (the compiler) as the \u0026ldquo;GIVEN_BUILD_TIME\u0026rdquo; environment variable via println!.\nsrc/main.rs Example # // src/main.rs const BUILD_TIME: \u0026amp;str = env!(\u0026#34;GIVEN_BUILD_TIME\u0026#34;); fn main() { // if you working with firmware environment, // use defmt::info!(..) instead of println!(..) println!(\u0026#34;passed build time is {}\u0026#34;, BUILD_TIME); // \u0026#34;passed build time is 2023-11-14T06:14:02.366899222+00:00\u0026#34; } In src/main.rs, the \u0026ldquo;GIVEN_BUILD_TIME\u0026rdquo; environment variable is retrieved as a const \u0026amp;str using the built-in env!(..) macro.\nThe exact module path of env!(..) is core::env!(..), and core::env!(..) fetches environment variables at compile time. If you are developing for an OS target and want to get runtime environment variables or execution arguments rather than compile-time ones, you should use the items in the std::env module. Since you may end up using both when working with build.rs, be careful not to confuse them.\nFor detailed documentation on the env!() macro, see: https://doc.rust-lang.org/core/macro.env.html\nCreating Fixed-Length Binary Data # Fetching with include_bytes # core::include_bytes can load a file from the project directory as binary data at compile time. https://doc.rust-lang.org/core/macro.include_bytes.html\nCreating a Dummy Binary # echo -n \u0026#34;\\x00\\x01\\x02\\x03\u0026#34; \u0026gt;\u0026gt; ./src/stuff0123.bin Create a dummy binary for our exercise. It is [0x00, 0x01, 0x02, 0x03], totaling 4 bytes, and is placed in the same location as main.rs.\nIn this post we create the dummy binary from the terminal, but it can also be done from build.rs.\nsrc/main.rs Example # const DATA0123: \u0026amp;[u8; 4] = include_bytes!(\u0026#34;stuff0123.bin\u0026#34;); fn main() { println!(\u0026#34;binary data is {:?}\u0026#34;, DATA0123); } In src/main.rs, the binary created earlier is fetched at compile time as const \u0026amp;[u8; 4]. Note that unlike fetching a \u0026amp;str above, you must specify the number of elements like [u8; N].\nTo fetch data without worrying about the number of elements, you need to use macros. This is covered later in this post.\nFetching Variable-Length Binary Data # build.rs src/**.rs String const \u0026amp;str Vec\u0026lt;u8\u0026gt; const [u8; N] In build.rs, data has variable-length characteristics, but when compiling for the target inside src/**.rs, you need the help of proc_macro. However, if the data size changes variably with each compilation and is not strictly controlled, it can be dangerous, so keep this in mind when using it.\nFetching Variable-Length Binary Data with proc-macro # There is also an approach of saving data to a tmp file and using include_bytes! with proc_macro, but the method introduced here uses env! together with proc_macro.\nTo explain proc_macro: in the past with C, you would use ## to concatenate tokens to generate code, or use compiler-specific features for black magic. Proc_macro brings in the concepts of tokens and parsers to enable reasonably stable metaprogramming through a macro system.\nIn Korean it is called procedural macros (jeolchahyeong maekeullo). If you master proc_macro and procedural macros, you can achieve excellent metaprogramming. I will write about this in more detail in a future post.\nFor the official detailed explanation of proc_macro, see: Procedural Macros\nOverall Flow # stateDiagram-v2 state \"Total flow\" as total_flow state \"data prepare\" as data_prepare state \"hex::encode(..)\" as hex_encode state \"hex encoded\" as hex_encoded state \"passing to env\" as passing_to state \"passing from env\" as passing_from state \"proc_macro\" as proc_macro state \"decoding at build time\" as decoding state \"decoded data\" as decoded_data state \"code generation\" as code_generation state \"src/**.rs\" as src_rs state \"const NAME: [u8; N] = [...]\" as const_u8_n state total_flow { [*] --\u003e build.rs state build.rs { [*] --\u003e data_prepare data_prepare --\u003e hex_encode hex_encode --\u003e hex_encoded hex_encoded --\u003e passing_to } -- state src_rs { passing_from --\u003e proc_macro state proc_macro { [*] --\u003e decoding decoding --\u003e decoded_data decoded_data --\u003e code_generation } proc_macro --\u003e const_u8_n } } The overall flow is as follows:\nPrepare the data to inject in build.rs. Encode it as hex and pass it as an environment variable to rustc. In src/**.rs, receive the environment variable and pass it to a function created with proc_macro. The macro function decodes the data at compile time and turns it into an array of the original data. Generate const data as a code declaration with the specified name and the array length. proc_macro Code for Decoding at Compile Time # To perform steps 4 and 5 described above, the following code is needed:\nfn slice_to_auto_sized ( arr_name: String, input: \u0026amp;[u8], ) -\u0026gt; TokenStream { format!( \u0026#34;const {}: [u8; {}] = [{}];\u0026#34;, arr_name, input.len(), input.iter().join(\u0026#34;, \u0026#34;) ) .parse::\u0026lt;proc_macro2::TokenStream\u0026gt;() .expect(\u0026#34;Failed to parse array\u0026#34;) .into() } struct NameAndEnvInput { arr_name: syn::LitStr, _comma0: Token![,], env_var: syn::LitStr, } impl Parse for NameAndEnvInput { fn parse(input: syn::parse::ParseStream) -\u0026gt; syn::Result\u0026lt;Self\u0026gt; { Ok(Self { arr_name: input.parse()?, _comma0: input.parse()?, env_var: input.parse()?, }) } } #[proc_macro] pub fn c(inputs: TokenStream) -\u0026gt; TokenStream { let inputs = parse_macro_input!(inputs as NameAndEnvInput); slice_to_auto_sized( inputs.link_section_name.value(), inputs.arr_name.value(), hex::decode(std::env::var(inputs.env_var.value()).expect(\u0026#34;This env not found\u0026#34;)) .expect(\u0026#34;Can\u0026#39;t decode hex\u0026#34;) .as_slice(), ) } As an example, assume that slice_to_auto_sized!(SOME_DATA, GIVEN_ENV); is declared in main.rs.\nIn const_from_hex_env, it takes three tokens matching the structure of the NameAndEnvInput struct: \u0026ldquo;SOME_DATA\u0026rdquo;, a comma (,), and \u0026ldquo;GIVEN_ENV\u0026rdquo;. These tokens are passed to slice_to_auto_sized at the top, which generates the code to be produced.\nThe above code can be found in the forked env-to-array commit. The code there has been modified to create dummy sections for the linker, so it is slightly different. This code is a slightly modified fork of the env-to-array crate. Data Generation Example for Hex Encoding # fn main { // https://github.com/pmnxis/billmock-mptool/blob/master/otp-proof-of-concept/build.rs // (abbreviated) let fingerprint = MpFingerprint { firmware_fingerprint: FirmwareFingerprint { model_name: main_package.name.clone(), // reference package name temporary model_ver: feature_based_model_ver, firmware_ver: main_package.version.to_string(), firmware_git_hash: format!(\u0026#34;{}\u0026#34;, commit_hash), }, }; // cargo objdump --release -- -s --section .mp_fingerprint println!( \u0026#34;cargo:rustc-env=MP_FINGERPRINT_TOML_HEX={}\u0026#34;, fingerprint.to_hex_string(), ); } When encoding in hex style, you can use hex and encode with hex::encode().\nThe code above creates package information and a git hash in TOML format, then hex-encodes it.\nPractical Applications # Application - Fetching EUC-KR Strings at Compile Time # use encoding_rs::EUC_KR; fn main() { // encoding_rs::Encoding::encode(..) is not const fn let ret: \u0026amp;[u8] = EUC_KR.encode(\u0026#34;ÏïàÎÖïÌïòÏÑ∏Ïöî\u0026#34;).0.to_vec().as_slice(); } While developing billmock-app-rs, I encountered several problems when creating an NDA financial institution protocol communication library. I needed to hold EUC-KR strings as const. However, the EUC-KR string encoding library encoding-rs does not provide const functions.\nSince EUC-KR is ultimately a character encoding, under the assumption that the strings are predetermined, it is binary data that can be generated at compile time.\nBy combining the techniques introduced above, I wrote code in the financial institution protocol communication library that converts EUC-KR strings to const [u8; N] at compile time.\nApplication - Dummy ELF Header # During firmware development, when creating an MP Tool (Mass Production Tool) for flashing firmware in bulk, I inserted a dummy header into the ELF to prevent mistakes and record hardware version information. Since this dummy ELF header is data that is not actually loaded into flash, using variable-length data was no problem at all.\nThe overall structure is similar to what was described above in \u0026ldquo;Fetching Variable-Length Binary Data with proc-macro\u0026rdquo;.\nRelated commits are as follows:\nhttps://github.com/pmnxis/billmock-app-rs/pull/42/files https://github.com/pmnxis/env-to-array/commit/782c2b265d8a23653321d163ac5cea96c04bc85d Wrapping Up # This post is a continuation of the previous post Part 3: Leave It to Compile Time, but focused on build.rs rather than const fn/trait/impl. I covered how to handle fixed-length and variable-length data through build.rs and listed practical usage examples.\nThe topic of proc_macro (procedural macros) was too lengthy to explain in the middle of this post, so I plan to cover it in a future article.\n","date":"13 November 2023","externalUrl":null,"permalink":"/en/posts/my_first_commerical_rust_embedded_product_4/","section":"Posts","summary":" WARN! This article is still a work in progress. Content may change at any time. ","title":"Developing a Mass-Produced Rust Embedded Product - 4 Leveraging Build Scripts","type":"posts"},{"content":"","date":"13 November 2023","externalUrl":null,"permalink":"/en/tags/embedded/","section":"Tags","summary":"","title":"Embedded","type":"tags"},{"content":"","date":"13 November 2023","externalUrl":null,"permalink":"/en/tags/korean_article/","section":"Tags","summary":"","title":"Korean_Article","type":"tags"},{"content":"","date":"13 November 2023","externalUrl":null,"permalink":"/en/categories/my-frist-mass-production-with-rust-embedded/","section":"Categories","summary":"","title":"My Frist Mass Production With Rust Embedded","type":"categories"},{"content":"","date":"13 November 2023","externalUrl":null,"permalink":"/en/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"Rust\n","date":"13 November 2023","externalUrl":null,"permalink":"/en/tags/rust/","section":"Tags","summary":"Rust\n","title":"Rust","type":"tags"},{"content":"\nMore details for rust tags : Rust tag\n","date":"13 November 2023","externalUrl":null,"permalink":"/en/tags/","section":"Tags","summary":"\nMore details for rust tags : Rust tag\n","title":"Tags","type":"tags"},{"content":" Here\u0026rsquo;s my cat LambdaŒª who expert on electronic engineering. This blog mainly cover with Linux, Rust, Embedded, and electronic circuits, and articles in Korean and English are mixed. Sometimes my cat LambdaŒª appears frequently, so I would appreciate it if you liked it. Nyaa ","date":"13 November 2023","externalUrl":null,"permalink":"/en/","section":"Welcome to Jinwoo and Lambda üê± 's blog","summary":" Here‚Äôs my cat LambdaŒª who expert on electronic engineering. This blog mainly cover with Linux, Rust, Embedded, and electronic circuits, and articles in Korean and English are mixed. Sometimes my cat LambdaŒª appears frequently, so I would appreciate it if you liked it. Nyaa ","title":"Welcome to Jinwoo and Lambda üê± 's blog","type":"page"},{"content":"","date":"13 November 2023","externalUrl":null,"permalink":"/en/tags/%ED%9A%8C%EA%B3%A0%EB%A1%9D/","section":"Tags","summary":"","title":"ÌöåÍ≥†Î°ù","type":"tags"},{"content":" WARN! This article is still a work in progress. Content may change at any time. Introduction # Before reading this post, if you are not familiar enough with Rust syntax, I recommend reading the #Studying-Rust section in the previous post Part 2: Study Methods and Key Characteristics. I also recommend the excellent article by Ki-O Kim, A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust.\nLeave It to Compile Time # A typical function will use a constant (immutable value) directly if the result can be predicted at compile time.\nHowever, if storing the value as a constant is deemed inefficient, it remains as a function in the instruction stream.\nIn embedded systems, especially firmware running on low-cost MCUs, RAM is very limited. (The MCU I used, STM32G030C8, has only 8KiB.)\nTo leave complex computations as constant-like data at compile time and load them into the Flash region (.text or .rodata), I occasionally departed from typical Rust programming practices and wrote code with this in mind.\nconst fn # Unlike a regular fn, a const fn guarantees that constant-like data is obtained at compile time.\nconst fn const_add(a: i32, b: i32) -\u0026gt; i32 { a + b } const fn const_add_round_up(a: i32, b: i32) -\u0026gt; i32 { let added = const_add(a, b); // Functions inside must also be const (added / 10) * 10 } However, there are many constraints. Functions within a const fn scope must also be const fn, and other operations must also be computable at compile time.\nConversely, a const fn can be used inside a regular fn or async fn scope.\nconst impl # Making a regular function const is straightforward, but the moment you turn it into a method for a struct, you run into difficult problems. This topic will be covered in the const trait section below.\nFor now, let us look at the simplest case: defining a default for a specific struct.\npub enum Player { Undefined = 0, Player1 = 1, Player2 = 2, } impl Player { pub const fn default() -\u0026gt; Self { Self::Undefined } } The code ends up being very simple, but by doing this, the caller of default() can obtain a constant at compile time. For more complex cases, you can supply more complex values. As mentioned above, as long as the arguments are not dynamic, the function will not remain in function form, so you are guaranteed to skip branching, stack back-and-forth, and the process of backing up and restoring registers.\nconst trait # Now we arrive at the much-anticipated const trait, which at the time of writing (November 2023) is a nightly feature. From here, I will also describe why const fn / impl / trait is still an RFC under discussion in Rust.\nConflicts with Existing Traits # Did you notice anything odd about the pub const fn default() mentioned above?\nThe issue is that a Default trait already exists separately.\nHowever, the definition of the Default trait is not in const form.\nIt is obvious that the core::default::Default trait impl for many structs is trivially simple. But no matter how simple it looks by eye, in this case it cannot be used inside a const fn.\nThe Case of Into/From # So far there has been little need to abstract through the Default trait using const, but surprisingly, Into/From turned out to be the real problem.\nFor now, by modifying the trait definition of core::default::From into ConstInto and ConstFrom compatible with const traits, you can use them as follows:\nConstConvert definition used in the product Example of using const-style Into/From\npub struct UnpackedQuad4Bits { pub b0: u8, pub b1: u8, pub b2: u8, pub b3: u8, } #[derive(PartialEq)] pub struct PackedQuad4Bits { inner: u16, } impl const ConstFrom\u0026lt;UnpackedQuad4Bits\u0026gt; for PackedQuad4Bits { fn const_from(value: UnpackedQuad4Bits) -\u0026gt; Self { PackedQuad4Bits { inner: ((value.b0 as u16 \u0026amp; 0xF) \u0026lt;\u0026lt; 12) | ((value.b1 as u16 \u0026amp; 0xF) \u0026lt;\u0026lt; 8) | ((value.b2 as u16 \u0026amp; 0xF) \u0026lt;\u0026lt; 4) | (value.b3 as u16 \u0026amp; 0xF), } } } #[test] fn test() { assert_eq!( PackedQuad4Bits::const_from(UnpackedQuad4Bits { b0: 0x0, b1: 0x1, b2: 0x2, b3: 0x3 }), PackedQuad4Bits { inner: 0x0123 } ); } When you create ConstInto / ConstFrom in const form, you cannot use them directly via .into() as with regular Into/From. You need to call the preceding const method again from the Into/From trait definition, but you can define the into conversion at compile time.\nconst trait as a Nightly Feature # const trait is still a nightly feature. In my personal experience, I had to change feature flags every time I slightly updated the nightly compiler version. Nevertheless, it is a very necessary feature in certain cases. (Of course, you can get by using only const fn without it.)\nWhen defining a const trait, you need to add #[const_trait] before the trait definition and declare #![feature(const_trait_impl)] in lib.rs or main.rs.\ntodo! Write about the history of discussions around const trait Tracking issue for RFC 2632, impl const Trait for Ty and ~const (tilde const) syntax Check out other posts in this series: Developing a Mass-Produced Rust Embedded Product ","date":"12 November 2023","externalUrl":null,"permalink":"/en/posts/my_first_commerical_rust_embedded_product_3/","section":"Posts","summary":" WARN! This article is still a work in progress. Content may change at any time. ","title":"Developing a Mass-Produced Rust Embedded Product - 3 Leave It to Compile Time","type":"posts"},{"content":" WARN! This article is still a work in progress. Content may change at any time. RIIR BEAM\nIntroduction # Continuing from the previous post, I want to briefly cover the pros and cons of applying Rust to embedded development, as well as how to study Rust for embedded.\nWhat I Felt After Using Rust for Embedded # There is a 38-Year Gap Between C and Rust # Image source: History Of Programming Languages\nC was released in 1972, and Rust was released in 2010. There is at least a 38-year gap between them, during which many languages, concepts, and changes emerged.\nC has structs, but it is fundamentally a procedural and strongly-typed language. Rust is a strongly-typed language with object-oriented capabilities (without inheritance, unlike C++), and like C and C++, it is designed with systems programming in mind.\nIn my personal interpretation, while C is strongly typed, it is a language tightly bound to CPU registers. In comparison, Rust is less dependent on CPU registers than C, but you can still be register-aware when programming in certain situations. I believe Rust has its strong typing characteristics rooted in the concept of \u0026ldquo;objects.\u0026rdquo;\nC has been maintained for a long time, and if you only work on embedded, you can be very fluent in C. However, there can be many challenges when adapting to a modern language like Rust. The biggest challenge is probably designing \u0026ldquo;objects\u0026rdquo; and \u0026ldquo;methods.\u0026rdquo; If you have only done procedural programming, you may struggle with this for at least several months.\nBeyond this, there are many things you need to break out of your existing mental framework \u0026ndash; the philosophy of explicitly distinguishing nullable values, ownership, and more. Understanding these concepts, and occasionally breaking them in low-level control (unsafe), or tuning for program size, is a process where you can gain a lot of CS knowledge and philosophical insight. I believe this is the most valuable part.\nAdvantages of Applying Rust to Embedded (Firmware) Projects # Thanks to built-in test support in the language spec, writing partial unit tests is straightforward. If the logic itself is sound and unit tests back it up, integration testing can be kept to a minimum while still catching bugs. Code written for firmware could be reused to a certain extent on backend servers. clippy and the formatter are built-in, making it easy to eliminate unnecessary code and unify code conventions. Object-oriented design (without inheritance) makes code reuse practical. The Cargo ecosystem makes adding libraries really convenient. Toolchain setup is also very simple. You can use async / await in firmware instead of epoll. Procedural macros are available. It is safer than writing in C, and you can significantly reduce mistakes during the development process. Disadvantages of Applying Rust to Embedded (Firmware) Projects # There are still not many reference projects to look at. It is practically difficult to apply to 8-bit processors. When putting data into queues or arrays, you tend to define separate, smaller types for enums, options, and structs to minimize size. Implementing Into/From for these is a bit tedious. You need to consider nightly features to some extent. When viewing compiled binaries with Ghidra/objdump, the output differs quite a bit from conventional C code. (Static analysis at the assembly level is still difficult. This is more of a characteristic than a disadvantage.) If you lack experience with object-oriented programming, you may end up writing procedural-style Rust code. With All These Disadvantages, Should You Still Use It? # Ultimately, it comes down to individual or organizational choice, but I personally think you should.\nThe reason is that I believe you cannot keep insisting on C forever. No matter how unique manufacturing and low-level domains may be, being an embedded developer does not mean you are outside the category of software developers. The languages developers use across the broader industry have evolved significantly and continue to change. The manufacturing and low-level sectors cannot escape this modern trend, and if they keep avoiding it, I believe the talent pipeline will eventually dry up.\nOf course, you cannot completely abandon C. But not every C developer can write code as rock-solid and performant as the Linux kernel core.\nStudying Rust # Recommended Reading # Ideally, I would like to introduce Rust syntax that would be useful for people new to Rust, from a C developer\u0026rsquo;s perspective. However, Ki-O Kim has already left an excellent article, A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust, so I will simply reference it here.\nThe resources below also do a great job of explaining Rust syntax:\nThe Rust Programming Language Korean Translation Comprehensive Rust Korean A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust Study Approach # If your goal is to study Rust for embedded, jumping straight into MCU or Linux driver development is not a great choice. When we talk about embedded, there are roughly three directions:\n\u0026ldquo;Firmware development running on MCUs\u0026rdquo; \u0026ldquo;Kernel development or kernel driver development\u0026rdquo; \u0026ldquo;FPGA development\u0026rdquo; What I cover here is direction 1, \u0026ldquo;Firmware development running on MCUs.\u0026rdquo; I plan to write about direction 2 separately after gaining more personal study and hands-on experience. Strictly speaking, while the domains share knowledge that is mutually helpful, they are entirely different domains. Direction 3 is even more distinct.\n(There are cases of applying Rust to FPGA, which is why I included it, but since I am not familiar with HDL-type languages, I will not mention it further.)\nIf you set your goals around directions 1 and 2, when it comes to studying just the Rust language itself outside of the domain, you need to study the language first.\nI recommend starting by reviewing the good resources mentioned above and trying out a toy project that runs on top of an OS.\nA language is just a tool, so there may be a temptation to immediately apply it to a domain you already know. However, in the long run, I do not think that is a great choice. I will discuss the reasons for this in another section.\nBe Mindful of no_std # To give a rough analogy for hardware engineers, no_std is like non-eabi. In other words, it refers to an environment that runs without standard APIs provided by an OS. In this case, there are significant constraints around heap or dynamic allocation, and since there is no standard I/O, you have no choice but to develop with hardware considerations in mind, unlike when developing on top of an OS.\nno_std is a reserved keyword for rustc (the compiler) and an implicit reserved keyword for cargo (the package manager). If #![no_std] is annotated at the beginning of a library\u0026rsquo;s lib.rs, it means the library can be used in a no_std environment.\nAdditionally, some crates mark no_std in their Cargo.toml to advertise no_std support on crates.io.\nA no_std Rust Environment Going forward, if you develop on Rust embedded, in both directions 1 and 2, you will frequently write or use no_std libraries. This is because the targets we aim for have very limited operating system support.\nUse core Instead of std for Core Library Imports # use core::borrow::BorrowMut; use core::cell::UnsafeCell; use core::marker::PhantomData; One thing you can immediately keep in mind is to import from core instead of std whenever possible. std re-exports everything from core, so using core imports directly is perfectly fine.\nhttps://doc.rust-lang.org/src/std/lib.rs.html#431-459 Avoid unsafe as Much as Possible at First # While I eventually used unsafe for optimization when writing embedded Rust, unsafe is difficult to use and requires a process of re-understanding your programming model and computer architecture knowledge through the lens of Rust\u0026rsquo;s philosophy. And the biggest problem is that fewer people can help you with it.\nI recommend getting comfortable with the Rust language first before diving into unsafe.\nIf you do need to use it, the following document provides very detailed coverage:\nThe Rustonomicon Check out other posts in this series: Developing a Mass-Produced Rust Embedded Product ","date":"4 November 2023","externalUrl":null,"permalink":"/en/posts/my_first_commerical_rust_embedded_product_2/","section":"Posts","summary":" WARN! This article is still a work in progress. Content may change at any time. RIIR BEAM\n","title":"Developing a Mass-Produced Rust Embedded Product - 2 Study Methods and Key Characteristics","type":"posts"},{"content":"This article is still being written. Content may change along the way.\nA test unit recently sent out to the field\nIntroduction # As a language to replace C, Rust is a language that has been receiving a lot of attention. While I am currently doing backend development, from the perspective of someone who used to live and breathe firmware, I have always held the belief \u0026ndash; past and present \u0026ndash; that if a programming language is not an HDL language, \u0026ldquo;it must be able to run on a 500-won MCU.\u0026rdquo;\nFrom this perspective, aside from zig which is currently gaining traction, I believe Rust is the only language that can replace C. However, this claim had the flaw that \u0026ldquo;I had never developed firmware at a production level with Rust.\u0026rdquo; Being aware of this shortcoming, after several attempts over 2-3 years, a commercial Rust embedded project that I finally started in July 2023 has reached the initial mass production phase.\nI intend to cover my experience with Rust embedded, its advantages, and various techniques across multiple articles. In this article, I would like to introduce the development framework used, what was developed for the project, and briefly share my impressions.\nAs a personal ambition, I would like to write a book about Rust embedded based on this experience, but I have not been able to decide on the target audience from among three categories. Until I settle on a target audience in my mind, I expect to organize things in a free-form manner as they come to me.\n\u0026ldquo;Developers who already have experience with Rust\u0026rdquo; \u0026ldquo;Developers whose primary job is not embedded but who do Arduino as a hobby\u0026rdquo; \u0026ldquo;Existing embedded developers\u0026rdquo; The reason I bother to explain this is that there are so few embedded developers using Rust. Most readers will likely fall into the category of developers interested in Rust, and trying to explain both the unfamiliar Rust and embedded simultaneously would be far too unkind. So even if the writing progresses slowly, I intend to go through the process of providing some perspective on the development process of embedded.\nProduct Planning # To the question of why card payment terminals are only being installed in arcades now in 2023, you need to look at the history of the arcade industry itself. Due to the \u0026ldquo;Sea Story\u0026rdquo; gambling scandal around 2007, it was not possible to install card terminals until 2020. From 2020 onward it became possible, but in that case, the game itself had to go through the approval process again. However, related regulations have recently been relaxed, and a request came in for me to develop a module that enables card terminal installation.\nGame Rating and Administration Committee decides to diversify arcade game payment methods starting next month - 2019-06-28 Regarding changes to payment methods for all-ages arcade games - 2022-03-21 Example of a bill acceptor\nCard terminals use RS232 serial communication, and existing arcade machines use a Molex 2.00mm pitch 10-pin connector for the bill acceptor, or 2-4 pin connectors for the coin acceptor. Unless special features are used, the signal systems of the 10-pin bill acceptor and coin acceptor are compatible. Given that prices have risen significantly compared to the past, 1000-won bills are used much more frequently than 500-won or 100-won coins as a payment method, so I decided to prioritize the bill acceptor wiring.\nTo add a card terminal to an existing arcade machine, the only option is to share the existing currency payment signal lines and generate signals in place of the bill acceptor (or coin acceptor). However, if you simply inject signals onto the existing wiring, the signals from the bill acceptor and the card terminal would overlap. Therefore, a FIFO Queue was applied to each signal output so that bill acceptor and card terminal inputs can be processed sequentially even if they overlap, and the hardware was designed accordingly.\nHardware Development # STM32G030C8Tx Chip Selection # STM32G030C8Tx is a Cortex-M0 (ARM Cortex-Mv6) MCU from ST. An MCU is a device that contains a 32-bit CPU along with peripherals for embedded use. This product has 64 KBytes of Flash for storing programs and 8KB of SRAM (similar to a computer\u0026rsquo;s RAM), and operates at 16 MHz. There is also a variant with half the capacity at 32 KBytes, but based on the experience at my company that 32 KBytes was not enough for a Rust debug build for even simple products, and the expectation that the features and business logic would likely grow, I chose 64 KBytes without going much higher. Additionally, this was based on the belief that being able to create a Rust embedded product on an inexpensive MCU with minimal computing resources would prove that Rust can be used for production and professional embedded development. (I have heard that you can write embedded code in Go, Python, and JavaScript too, but I think it is very difficult to use them in production environments where the cost must be very low, and it is meaningless if it only runs on expensive chips.)\nPCB (Circuit) Development # The Gerber data on the left is not publicly released, but the schematic (circuit diagram) is. BillMock-HW-RELEASE\nKiCad was used for circuit development. KiCad is an open-source EDA CAD program released by CERN. It supports all commonly used operating systems \u0026ndash; Linux, macOS, and Windows. I have been using it since version 5.x, and after going through 6.x, it became quite usable at 7.x, so I applied it to this project as well.\nPCB (circuit) development roughly divides into schematic development and Gerber artwork. A schematic is a diagram that represents how the circuit is to be configured, as shown in the right image. Gerber artwork, as shown in the left image, represents how the copper traces and components will actually be printed/mounted. Depending on the required connector positions in the circuit, the speed of communication on the traces, the magnitude of electrical signals, and power requirements, components are placed closer or farther apart, and traces are routed thicker or relatively thinner.\nJust as programs need optimization, circuits also need optimization. It is important to reduce the number and variety of components, use reasonably priced parts, reduce overall size or lower specifications to cut costs, while maintaining the hardware\u0026rsquo;s functionality and stability as planned.\nPrototype Production # JLCPCB was used for prototyping. For a company project, the orthodox choice would be to use a domestic turnkey manufacturer. However, having already used JLCPCB\u0026rsquo;s SMT (assembly) service several times, I did not need any additional adaptation, and I had confidence that if JLCPCB could produce good results at very low cost for small quantities, it would work fine at another manufacturer for mass production later. (JLCPCB is exceptionally inexpensive for small sample runs.)\nTo draw an analogy for backend server developers, I think it is similar to the thought: \u0026ldquo;If it runs on a 10-year-old school club server, it will probably run fine in the IDC for the final release.\u0026rdquo;\nFinal Mass Production # BOM Organization and Parts Procurement # Unlike software, as you get closer to hardware, you frequently hear the term BOM. Bill of Materials is literally a parts list and inevitably includes pricing and various other information. If the price is too high, you go back to the design stage and either make major design changes or, if there are components that can be replaced without design changes, substitute them with alternatives. During this process, I determined that costs were too high, reduced the number of connectors, and based on some demand forecasting, decided to purchase components in advance in \u0026ldquo;Reel\u0026rdquo; units.\nComponents sent to the assembly factory for mass production. A Reel refers to a cylindrical spool where components are wound up like film tape.\nBOM organization and optimization are very important, but since it is a topic that generally does not excite typical software developers, I think watching YouTuber Seungwoo Daddy\u0026rsquo;s restaurant BOM video can make it interesting. While it is about BOM (ingredient) management in restaurant operations rather than electronics, I think it is very informative.\nLet me tell you why this happens. - Seungwoo Daddy Daily Channel\nProduction Outsourcing / Assembly Outsourcing # Manufacturing a PCB and soldering components onto it (assembly, PCB Assembly) are separate tasks. There are cases where a turnkey company handles parts procurement as well, but in my case, I proceeded with company-supplied materials (purchasing and providing the parts ourselves).\nI used a turnkey company recommended by a senior colleague at the company who had previous mass production experience. (Trust-based, saving the time of searching around.)\nReasons for Domestic Mass Production (Why Not JLCPCB or Other Chinese Manufacturers) # Before present-day China emerged, Korea was capable of quickly handling everything from PCB manufacturing and assembly (+development) to product case injection molding and sheet metal fabrication for the entire world, and that supply chain still remains. Korea is still a country that can handle most processes of electronic product manufacturing and production. However, due to low prices and marketing, the practice of outsourcing sampling and small-scale production to Chinese companies has spread widely through YouTube and online communities. In Korea, if you can find the routes (manufacturers) known only to practitioners, and if those manufacturers accept the work, it is advantageous to conduct mass production domestically up to a certain quantity. If you are producing hundreds of thousands of units per month, it may be more cost-effective to outsource to overseas manufacturers, but for small quantities of several thousand or tens of thousands, you lack the ability and personnel to inspect whether the overseas factory performs well each time, and there is no way to hold them accountable if something goes wrong.\nBased on the PCB I made, assuming a production run of 1,000 units, JLCPCB is overwhelmingly cheaper, but there exists a point where the difference is only about 20-30%. When you factor in shipping costs, customs duties, and other administrative expenses, JLCPCB did not really provide much of an advantage. More importantly, the issue is that they do not properly take responsibility when problems occur. Besides JLCPCB, other overseas manufacturers may offer good quality, but the problem of not being able to visit in person to discuss issues when they arise still remains.\nIn the early days, I ordered 10 PCBs and 5 were defective, but I had to file the claim first.\nProgram Download # MP Tool\nEven after the PCB is manufactured, it does not just work \u0026ndash; you need to load the program onto it. There are cases where the assembly contractor can load the program binary upon request, but this time a custom program was needed, so I decided to handle the flashing directly.\nCovering why that process was necessary and how it was developed would make this too long, so I will address it in a separate article.\nThe rough process is as follows:\ngraph LR; A[Power Up] --\u003e|Flash \\nLock Check| B(Unlock Flash\\nTemporary) B --\u003e C[Program\\nDownload] C --\u003e |OTP section\\n check|D{S/N Exist?} D --\u003e|Yes| E[Update to DB] D --\u003e|No| F[Write New OTP\\n\u0026 Insert to DB] Here, an additional step is included to check the serial number in the OTP section and either add or update the information accordingly. If there is no serial number in the OTP, a serial number is written to the OTP section.\nClosing Remarks # The final mass-produced board\nNext time, I plan to cover the firmware software development side of things developed in Rust, and after that, I expect to cover the Rust embedded ecosystem and techniques I have picked up.\nI am very happy that my first personal mass production experience was built on firmware developed in Rust and that it was completed successfully.\nIf asked to do personal mass production again, I do not think I could. I will treasure it as a valuable experience that helps with development, but handling everything alone as a primary job is too much. Still, I recommend trying it at least once if you get the opportunity to do a production run on your own.\nCheck out other articles in this series: Rust Embedded Mass Production Development Story ","date":"2 November 2023","externalUrl":null,"permalink":"/en/posts/my_first_commerical_rust_embedded_product_1/","section":"Posts","summary":"This article is still being written. Content may change along the way.\nA test unit recently sent out to the field\n","title":"Rust Embedded Mass Production Development Story - 1: From Development to Production","type":"posts"},{"content":"","date":"8 April 2023","externalUrl":null,"permalink":"/en/tags/amd/","section":"Tags","summary":"","title":"AMD","type":"tags"},{"content":"","date":"8 April 2023","externalUrl":null,"permalink":"/en/tags/cache/","section":"Tags","summary":"","title":"Cache","type":"tags"},{"content":"","date":"8 April 2023","externalUrl":null,"permalink":"/en/categories/cpu/","section":"Categories","summary":"","title":"CPU","type":"categories"},{"content":"It has been quite a while since ZEN4 started selling, and ZEN3 has also gone through several internal stepping/revision changes that seem to have improved things, so I feel this is an appropriate time to write this article. I originally posted this on other communities as well, and while it may seem tangential to development, it deals with CPU internals, so I am reposting it on my dev blog.\nInstruction L1/L2 Cache Failures Occur When Power Consumption Changes Drastically # Just searching for \u0026ldquo;WHEA\u0026rdquo; on Quasarzone yields countless posts.\nIn the past, numerous people reported these issues while using AMD Zen2/Zen3:\nWHEA 18 errors suddenly appear in the Windows Event Logger. The system suddenly shuts down. [Halt] (no logs found) The system suddenly resets. [Reset] (no logs found) These symptoms occur even when the system is idle. Disabling C-State reduces the frequency of these issues. \u0026ldquo;Just disable C-State.\u0026rdquo; I also experienced these issues when I was using a 3950X, and it cost me an enormous amount of time. Eventually, I went from the 3950X to a 5950X (a recent stepping revision), and in between, I temporarily used a 5900X that I purchased separately.\nThis led to a situation where my computers self-replicated and I ended up with two systems. I also purchased three motherboards during this process.\nIf you have read this far, you will have noticed a few key terms:\nKeyword 1 Keyword 2 Keyword 3 Instruction L1, L2 cache C-State Reset/Halt What is C-State? # Let me explain C-State first. Source: https://www.dell.com/support/kbdoc/ko-kr/000060621/c-state%EB%8A%94-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80\nC-State is a feature that reduces CPU power consumption, minimizing it as much as possible when the CPU is underutilized.\nIn practice, whether on AMD or Intel, the power consumption difference between C-State enabled and disabled during PC idle is quite significant when measured with a UPS \u0026ndash; around 10W to 20W. That difference alone is enough power to run one of the new Intel Alderlake N100 Mini PCs. Furthermore, this feature has been around since the 1990s, so it is essentially a well-established feature that should just work reliably.\nWhat is Instruction L1/L2 Cache? # Let me start with the memory model taught in undergraduate \u0026ldquo;Computer Architecture\u0026rdquo; courses in Computer Science departments.\n[Source: https://diveintosystems.org/book/C11-MemHierarchy/mem_hierarchy.html ]\nThe modern memory system is structured in this pyramid-like hierarchy.\nFrom registers at the very top, through cache, down to Flash Disk and beyond, access time and capacity scale proportionally as you go down.\nFrom the CPU\u0026rsquo;s perspective, accessing a register takes the shortest time, but the cost per area for registers is extremely high.\nThe further down you go, the more time it takes, but the cheaper it becomes.\nAlthough this diagram does not show the exact capacity differences between registers/cache/Main Memory, the allocation of capacity depending on the system and its purpose is very important. The key is in \u0026ldquo;how you divide it.\u0026rdquo; One thing the user can control is to just pack in as much DRAM as possible.\nSo what exactly is the Instruction L1/L2 cache?\nThe CPU needs cache not only for fast data access/reads,\nbut also for fast instruction execution.\nIf the data needed for reading or the instructions being processed are not in the cache, the CPU effectively stalls while fetching from DRAM (main memory). (We will not consider the pipelining concept here.)\nThe L1/L2 designation refers to levels: L1 is the space closest and fastest for each CPU core to access, while L2 is a slightly more distant level (though still much closer than DRAM).\nComing back to Zen2/3, the CPUs from the Zen2/3 generation with 16 cores have the highest core count. They adopted a multi-die structure, packaging two groups of 8 cores together.\nSo in reality, the memory model does not form a single pyramid shape as shown above. Instead, there are two pyramids on top of one pyramid, and on top of those two pyramids, there are 8 additional pyramids each.\nDetailed Report on the Symptoms Mentioned Above # The majority of users who build their own PCs use Windows. If you experienced the issues mentioned in this article,\nyou would have seen a WHEA18 error in the Windows Event Logger, or the system would have shut down (reset) or frozen (halt) without any error logged at all. Whether it is a reset or halt likely depends on the motherboard. I confirmed this by using Asrock/Gigabyte/Asus boards with B550/X570 chipsets, all three of which exhibited errors in different ways.\nTo analyze this problem accurately, we should not be looking at Windows but rather finding answers in the Linux community.\n[Correctable MCE errors logged for CPU0/CPU12 L1 instruction cache with AMD Ryzen 9 3900X 12-Core Processor] https://bugzilla.redhat.com/show_bug.cgi?id=1830404 [Random freezes and reboots AMD Ryzen] https://bugzilla.kernel.org/show_bug.cgi?id=210261 (There are many more reports beyond these two links, but I will only post these two for now.)\nThe threads themselves are very long, so here is a summary:\nAt random times, the errors below appear and the system freezes. And replacing the CPU just fixes it.\nEnabling C-State prevents or reduces the occurrence of the issue.\nMay 01 15:06:59 kernel: mce: [Hardware Error]: Machine check events logged May 01 15:06:59 kernel: [Hardware Error]: Corrected error, no action required. May 01 15:06:59 kernel: [Hardware Error]: CPU:12 (17:71:0) MC1_STATUS[Over|CE|MiscV|AddrV|-|-|SyndV|-|-|-]: 0xdc20000000030151 May 01 15:06:59 kernel: [Hardware Error]: Error Addr: 0x000000076da32ae0 May 01 15:06:59 kernel: [Hardware Error]: IPID: 0x000100b000000000, Syndrome: 0x000000001a030507 May 01 15:06:59 kernel: [Hardware Error]: Instruction Fetch Unit Ext. Error Code: 3, IC Data Array Parity Error. May 01 15:06:59 kernel: [Hardware Error]: cache level: L1, tx: INSN, mem-tx: IRD May 01 15:06:59 kernel: mce: [Hardware Error]: Machine check events logged May 01 15:06:59 kernel: [Hardware Error]: Corrected error, no action required. May 01 15:06:59 kernel: [Hardware Error]: CPU:0 (17:71:0) MC1_STATUS[Over|CE|MiscV|AddrV|-|-|SyndV|-|-|-]: 0xdc20000000030151 May 01 15:06:59 kernel: [Hardware Error]: Error Addr: 0x0000000fbedc2ae0 May 01 15:06:59 kernel: [Hardware Error]: IPID: 0x000100b000000000, Syndrome: 0x000000001a030507 May 01 15:06:59 kernel: [Hardware Error]: Instruction Fetch Unit Ext. Error Code: 3, IC Data Array Parity Error. May 01 15:06:59 kernel: [Hardware Error]: cache level: L1, tx: INSN, mem-tx: IRD Speculative Analysis of the Error Cause # This particular condition occurs extremely rarely (a CPU running at 3GHz or above executes 3,000,000,000 cycles per second, so from a cycle perspective, occurring once every 30 minutes to 24 hours is extremely rare \u0026ndash; but this is not saying it is rare from a user\u0026rsquo;s perspective).\nThe clue was found in the C-State feature mentioned above:\nIf C-State is enabled, the power delivered to the CPU core goes from very low to very high in a very short time. If C-State is disabled, the power delivered to the CPU core goes from slightly low to very high in a very short time. So the cause relates to the rapid change in power delivered to the CPU core affecting the CPU Instruction L1/L2 cache.\nWhile executing instructions, if the instructions themselves that the CPU fetches from the cache are corrupted, the CPU cannot execute them. It cannot proceed further, and in fact, even producing a core dump (memory dump) in this case would be a miracle. [Broadly speaking, there are two approaches to memory debugging: one is to back up the entire memory via software, and the other is to dump memory using hardware equipment that costs more than a luxury car. In this case, only the latter can provide a proper analysis.]\nWhile the contents of L1/L2 cache are said to be a mirror of DRAM (Main Memory), kept for faster access,\nin actual operating system and program design, variables like Linux\u0026rsquo;s per-cpu variables are typically sized to match or be smaller than each architecture\u0026rsquo;s L1 cache size as a block unit. In SMP (multi-core) systems, there are values where the address and memory information are stored in DRAM, but the accurate information is presumed to reside in the cache rather than DRAM, for faster read/write without going to DRAM. If L1/L2 becomes unreliable, variables with per-cpu-like characteristics (values used by computer programs) would become unusable, and this can similarly affect instructions.\nWhether the root cause is truly the rapid fluctuation in power delivered to the CPU is ultimately speculation,\nbut the fact that so many people are reporting L1/L2 cache problems is, in my personal opinion, recall-worthy.\nThe per-cpu details I mentioned later are not taught at the undergraduate level, but CPU L1/L2 cache is undergraduate-level knowledge, and there appears to be a fundamental design miss.\nDetailed link about per-cpu: http://jake.dothome.co.kr/per-cpu/\nHow Are AMD and Distributors Responding? # So how are AMD and distributors responding? Looking at how distributors check for defects: they boot the system and run a benchmark program. That is it. In reality, finding such problems is very difficult unless you use professional equipment like Trace32.\n[Source: https://www2.lauterbach.com/pdf/general_ref_c.pdf page 172]\nWith Trace32, you can observe all CPU values in real time. The most an average person or even most developers can do is access memory addresses, but there is no way to tell whether the value comes from DRAM or cache. While such advanced development tools are needed, it is practically impossible for distributors to perform after-sales service using these tools. Therefore, the service staff must also find themselves in a very difficult position regarding this issue.\nFrom the consumer\u0026rsquo;s perspective, proving this defect and getting an exchange is extremely difficult.\nIn my opinion, the fault lies with AMD.\nI believe the problem is that there were either QC failures initially, or that AMD failed to properly verify and fix these issues during silicon design before selling the product.\nSo does AMD publicly disclose or share information about defects in their CPUs?\nNo, they hide far more than Intel does.\nFor reference, Intel shared an Errata Sheet (a paper documenting design flaws and issues) for their recently released 13th generation:\n[ Intel Raptor Lake S - Errata Details ] https://edc.intel.com/content/www/us/en/design/products/platforms/details/raptor-lake-s/13th-generation-core-processor-specification-update/errata-details/\nHowever, AMD has not published Errata Sheets for the consumer Zen2: Family 17h Model 71h or Zen3: Family 19h Model 21h.\nThose who purchase chips to design their own PCB circuits or write Linux kernel drivers may have heard of Errata Sheets and have occasionally found problems there, leading them to re-select components or work around silicon bugs in software.\nIt is deeply disappointing that AMD has not issued any notice about such a serious problem and has instead relied on internet posts telling people to disable C-State while hiding these issues.\nI hope that AMD will change its ways and properly disclose defects in products that have serious issues with the memory hierarchy. I will close this article with a photo of a cat that loves memory. ","date":"8 April 2023","externalUrl":null,"permalink":"/en/posts/casts_double_amd_desktop_zen_2_and_3_halt_randomly_kr/","section":"Posts","summary":"It has been quite a while since ZEN4 started selling, and ZEN3 has also gone through several internal stepping/revision changes that seem to have improved things, so I feel this is an appropriate time to write this article. I originally posted this on other communities as well, and while it may seem tangential to development, it deals with CPU internals, so I am reposting it on my dev blog.\n","title":"Raising Suspicions of QC/Design Flaws Causing Intermittent Resets/Freezes in ZEN 2/3","type":"posts"},{"content":"","date":"8 April 2023","externalUrl":null,"permalink":"/en/tags/ryzen/","section":"Tags","summary":"","title":"Ryzen","type":"tags"},{"content":"","date":"8 April 2023","externalUrl":null,"permalink":"/en/tags/silicon-bug/","section":"Tags","summary":"","title":"Silicon Bug","type":"tags"},{"content":" 1. Fourier series coefficients for Continuous signal # Asking deriving coefficients comes with periodic signal.: \\(x(t) \\rightarrow a_k\\)\n1.1 (CT FS) Basic concept of continuous Fourier coefficients # $$ \\begin{gathered} x(t): \\text { Periodic signal } \\ T: \\text { Fundamental Period } \\ \\end{gathered} $$\n$$ \\begin{gathered} \\omega_0=\\frac{2 \\pi}{T} \\quad \u0026amp; \\quad f_0=\\frac{1}{T}(\\text { freq }) \\ \\end{gathered} $$\n$$ \\begin{gathered} \\quad x(t)=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k \\omega_0 t}=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k(2 \\pi / T) t} \\end{gathered} $$\n1.2 (CT FS) Continuous-Time, Fourier Series # Convert periodic signal to fourier coefficients : \\(x(t) \\stackrel{F S}{\\rightarrow} a_k\\)\n$$ \\begin{gathered} a_k=\\frac{1}{T} \\int _T x(t) e^{-j k \\omega_0 t} d t \\ \\end{gathered} $$ $$ or $$\n$$ \\begin{gathered} a_k=\\frac{1}{T} \\int_T x(t) e^{-j k(2 \\pi / T) t} d t \\end{gathered} $$\n1.3 (CT IFS) Continuous-Time, Inverse Fourier Series # Fourier coefficients to peridoic signal : \\(a_k \\stackrel{I F S}{\\longrightarrow} x(t)\\)\n$$ x(t)=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k \\omega_0 t}=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k(2 \\pi / T) t} $$\n1.4 Properties of Continuous-Time Fourier Series # Fourier transform for Continuous-time signal \\(x(t)\\) Most of case, aperiodic signals comes...\n2. Fourier coefficients for Discrete signal # $$ \\begin{gathered} x[n] \\rightarrow \\boldsymbol{a}_{\\boldsymbol{k}} \\end{gathered} $$ Asking deriving coefficients comes with periodic signal.\n2.1 (DT FS) Basic concept of discrete Fourier coefficients \\(x[n]: Periodic\\) # $$ \\begin{gathered} x[n]: \\text { Periodic signal } \\end{gathered} $$\n$$ N \\text { : Fundamental Period (LCM of } 2 \\pi \\text { ) } $$\n$$ \\begin{gathered} \\omega_0=\\frac{2 \\pi}{N} \\quad \u0026amp; \\quad f_0=\\frac{1}{T}(\\text { freq }) \\end{gathered} $$\n$$ x[n]=\\sum_{k=\\langle N\\rangle} a_k e^{j k \\omega_0 n}=\\sum_{k=\\langle N\\rangle} a_k e^{j k(2 \\pi / N) n} $$\n2.3 (DT FS) Discrete-Time, Fourier Series # $$\\begin{gathered} a_{k}=\\frac{1}{N} \\sum_{n=\\langle N\\rangle} x[n] e^{-j k \\omega_{0} n} \\ a_{k}=\\frac{1}{N} \\sum_{n=\\langle N\\rangle} x[n] e^{-j k(2 \\pi / N) n} \\end{gathered}$$\n$$\\begin{aligned} \u0026amp; x[n] \\stackrel{F S}{\\rightarrow} a_{k} \\end{aligned}$$\n2.4 (DT IFS) Discrete-Time, Inverse Fourier Series # $$a_{k} \\stackrel{I F S}{\\rightarrow} x[n] \\quad x[n]=\\sum_{k=\\langle N\\rangle} a_{k} e^{j k \\omega_{0} n}=\\sum_{k=\\langle N\\rangle} a_{k} e^{j k(2 \\pi / N) n}$$\n2.5 Properties of Continuous-Time Fourier Series # 3 Fourier transform for Continuous-time signal \\(x(t)\\) : # 3.1 (CT FT) Continuous-Time, Fourier Transform ( periodic) # $$ x(t) \\stackrel{F T}{\\longrightarrow} X(j \\omega) $$\n$$ \\tilde{x}(t): \\text { single sliced periodic sig } \\ $$\n$$ a_k=\\frac{1}{T} \\int_{-\\frac{T}{2}}^{\\frac{T}{2}} \\tilde{x}(t) e^{-j k \\omega_0 t} d t $$ $$ X(j \\omega)=T a_k $$\n3.2 (CT FT) Continuous-Time, Fourier Transform (aperiodic) # $$x(t) \\stackrel{F T}{\\rightarrow} X(j \\omega) \\quad X(j \\omega)=\\int_{-\\infty}^{+\\infty} x(t) e^{-j \\omega t} d t$$\n3.3 (CT IFT) Continuous-Time, Inverse Fourier Transform # $$X(j w) \\stackrel{I F T}{\\rightarrow} x(t) \\quad x(t)=\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} X(j \\omega) e^{j \\omega t} d \\omega$$\n3.4 Properties of Continuous Fourier Transform # 3.5 Basic Continuous Fourier Transform Pairs # 4 Fourier transform for Discrete-time signal \\(x[n]\\) # Most of case, aperiodic signals comes‚Ä¶\n4.1 (DT FT) Discrete-Time, Fourier Transform # $$x[n] \\stackrel{F T}{\\rightarrow} X\\left(e^{j \\omega}\\right) \\quad X\\left(e^{j \\omega}\\right)=\\sum_{n=-\\infty}^{+\\infty} x[n] e^{-j \\omega n}$$\n4.2 (DT IFT) Discrete-Time, Inverse Fourier Transform # $$X\\left(e^{j \\omega}\\right) \\stackrel{I F T}{\\rightarrow} x[n] \\quad x[n]=\\frac{1}{2 \\pi} \\int_{2 \\pi} X\\left(e^{j \\omega}\\right) e^{j \\omega n} d \\omega$$\n4.3 Properties of Discrete Fourier Transform # 4.4 Basic Discrete Fourier Transform Pairs # PDF version # Related files DSP_Fourier_CheatNote.pdf (275 KBytes) ","date":"20 December 2022","externalUrl":null,"permalink":"/en/posts/discrete_signal_processing_cheat_note/","section":"Posts","summary":"1. Fourier series coefficients for Continuous signal # Asking deriving coefficients comes with periodic signal.: \\(x(t) \\rightarrow a_k\\)\n","title":"Discrete Signal Processing Fourier Transform Cheat Note","type":"posts"},{"content":"","date":"20 December 2022","externalUrl":null,"permalink":"/en/tags/dsp/","section":"Tags","summary":"","title":"DSP","type":"tags"},{"content":"","date":"20 December 2022","externalUrl":null,"permalink":"/en/tags/english_article/","section":"Tags","summary":"","title":"English_Article","type":"tags"},{"content":"","date":"20 December 2022","externalUrl":null,"permalink":"/en/categories/math/","section":"Categories","summary":"","title":"Math","type":"categories"},{"content":"","date":"20 December 2022","externalUrl":null,"permalink":"/en/tags/mathmatics/","section":"Tags","summary":"","title":"Mathmatics","type":"tags"},{"content":"","date":"20 December 2022","externalUrl":null,"permalink":"/en/tags/signal-processing/","section":"Tags","summary":"","title":"Signal Processing","type":"tags"},{"content":"I have been using Rust at the company I recently joined. Five months have passed since I switched jobs, and I would like to describe what I have felt so far. Setting aside the detailed syntactic advantages, I will simply describe my general impressions.\nPros # If there is a developer who knows the domain well and at least two people conduct thorough code reviews for each other, you can code safely. Compared to C, there are many conveniences. As someone who only worked with C and firmware, Rust feels more familiar compared to other modern languages, and most behaviors/designs feel reasonable. In my personal opinion, Rust can be applied to many areas except frontend. [Firmware, OS-dependent utilities, backend] You continuously encounter study/challenge opportunities related to pure CS, rather than just business logic. Regardless of what target architecture (CPU, Operating System) comes along, it is very convenient to adapt. Cons # Can we go beyond FullStack and become EntireStack developers?\nEach difficulty point fundamentally requires a large base of knowledge. Occasionally, the study/challenge demands spill over into personal time. [This is not a con for me, but I think some people may feel it is.] There are significant limitations when hiring. When asked \u0026ldquo;What are the advantages of this language?\u0026rdquo;, the scope of required knowledge inevitably becomes very broad. And that scope of knowledge may lie far beyond most people\u0026rsquo;s areas of interest. If you use it in embedded and look at the domestic developer pool, it is difficult to find embedded developers who will use Rust together, and the range of additional skills required of embedded developers grows almost exponentially. Even without considering Rust, the pool of embedded developers is simply too small, although embedded development is not my primary work. The chip I want to use always has ambiguous Rust embedded support. (The answer to this is for me to contribute myself.) The community is still more focused on chips suitable for toy projects rather than chips that are practical in terms of cost/lead time during the chip shortage situation. Miscellaneous # I was very strict about code reviews at my previous company and was worried about how things would be at my current company. My initial impression was that since Rust\u0026rsquo;s syntax is more sophisticated than C, individual coding styles varied too much, and I thought this would be a bottleneck during reviews. However, clippy handles a lot of that, and as long as there is typo checking and a reasonable level of agreed-upon tests, reviews are not a problem. We can naturally have healthy discussions about CS topics with each other. Proper Support for Multiple Architectures # In theory and concept, pure interpreted languages are advantageous for multi-platform support. However, my actual experience with Rust has led me to feel differently. No matter how theoretically advantageous interpreted languages are supposed to be, for truly and properly supporting all architectures (various CPU architectures and multiple OSes), Rust was extremely convenient.\nFirst of all, properly supporting all architectures is one of the key values of systems programming or firmware programming. So what languages were traditionally used for this kind of programming? That would be C and C++. However, to quickly get started (Getting Start) with these languages, you first had to set up Makefile or CMake configurations, and every time a new architecture was added, you had to accommodate it. On top of that, setting up the compiler, development environment, and libraries for each architecture was a separate task entirely.\nLet me compare with another language. Currently, almost nobody compares Go-Lang and Rust, but five years ago, many people did. When comparing the systems programming domain only on top of an OS, both are excellent languages. What I am about to say is quite a stretch, but in Rust\u0026rsquo;s conceptual no-std scenario \u0026ndash; where there is no OS or the OS is very different from a typical one \u0026ndash; it is difficult to adapt. [The author previously worked in firmware development and is also evaluating whether production-grade firmware development is feasible.]\nRust Is Difficult for Quick Prototyping Right Away # In the previous sections, I praised Rust\u0026rsquo;s advantages, but in this section, I will describe some slightly disappointing aspects. Rust is a difficult language to write. More precisely, it is very difficult to develop in a Rust-like way that maximizes Rust\u0026rsquo;s strengths. Realistically, it would be very difficult with any language to fully leverage its strengths during development. However, if Rust is chosen for commercial purposes (as a language/framework for a company/development team), personal preferences should be set aside in favor of the company\u0026rsquo;s perspective.\nIs it a medium that can realize what we want to develop? Can we adequately recruit developers? How much development time does it require? Does it run fast and correctly? Do the team members want to use it? (In other words, preference.) Rust is likely to score low on items (2) and (3), and I believe this is absolutely the case for (2) in particular.\nIf Rust must be chosen despite these drawbacks, it would largely be due to (4) and (5). In that case, the development team and developers would need tangible events or results that highlight Rust\u0026rsquo;s advantages in order to sustain its use, whether voluntarily or otherwise.\nEven though you can just use whatever language the company assigns, if you have a choice and want to keep using Rust, you would want to highlight its merits. (This is a somewhat difficult topic to articulate, as it overlaps with emotional territory.)\nThen, to develop in a way that maximizes Rust\u0026rsquo;s strengths, a great deal of knowledge is required. In other words, the learning curve becomes steep. Depending on how you look at it, this can be either digging your own grave or creating an opportunity.\nBut an Opportunity to Gain Tremendous Intellectual Value # When C was first created, concepts like multi-processing/processors (SMP), caching, and GPGPU did not exist, and in many details, it was an era with a different memory model from today\u0026rsquo;s. And to this day, C is used to handle these aspects. When you find yourself in a situation where you must develop with these concepts in mind, there are many difficulties.\nHowever, Rust has infrastructure in place to overcome these challenges to some degree, with room for more to come. And while this is an ambiguous statement, through Rust, it feels like opportunities are created to more closely examine the difficult architectural designs of computers and operating systems, albeit indirectly. This can be gained through Rust compiler\u0026rsquo;s safety constraints and warnings, and I believe it is also driven by the influence of a community populated by many expert-level systems programmers. Speaking a bit more about multi-platform support, I also believe that the strength of the community is why multi-platform support is handled so well.\nWhen Can We Say We Have Become Proficient Rust Developers? # People occasionally say things like \u0026ldquo;I am a ____ developer.\u0026rdquo; So when can we say that we have become proficient Rust developers?\nThere is no definitive answer.\nHowever, in my personal opinion, if you can explain the advantages that a given framework or language provides in a way that others can understand, then perhaps you can call yourself a ____ developer.\nBut unfortunately, with Rust, this is very difficult to articulate. You have to start by explaining ownership. And to do that, you first need to understand the stack and heap of a running process.\nReference: 4.1 What is Ownership - The Rust Programming Language Korean Translation\nBecause of this, you either need the ability to explain a great deal to the person you are trying to convince, or the listener must be at a high level, requiring precise and very deep explanations.\nIt is unfortunate that the difficulty level of explanation starts at HARD MODE from the get-go, but we do not develop alone. If we truly want to submit a Pull Request, I think it is necessary to explain well to the reviewer, or to write code in a way that makes explanations easier.\nThrough that process, you can build the knowledge base and communication skills needed to explain things, and going further, I think you can develop the ability to explain any given technology as described above.\nThe next time (or the time after) I write a retrospective, I plan to cover the actual gains and losses from using Rust at work.\n","date":"27 November 2022","externalUrl":null,"permalink":"/en/posts/five_mothes_ago_from_using_rust_as_work_kr/","section":"Posts","summary":"I have been using Rust at the company I recently joined. Five months have passed since I switched jobs, and I would like to describe what I have felt so far. Setting aside the detailed syntactic advantages, I will simply describe my general impressions.\n","title":"About Five Months After Using Rust at Work","type":"posts"},{"content":"","date":"27 November 2022","externalUrl":null,"permalink":"/en/categories/etc/","section":"Categories","summary":"","title":"Etc","type":"categories"},{"content":"","date":"4 October 2022","externalUrl":null,"permalink":"/en/tags/armv8a/","section":"Tags","summary":"","title":"ARMv8A","type":"tags"},{"content":"","date":"4 October 2022","externalUrl":null,"permalink":"/en/tags/cross-compile/","section":"Tags","summary":"","title":"Cross Compile","type":"tags"},{"content":"In October 6, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nCurrent linux 6.1 rc1 doesn\u0026rsquo;t contain rust for linux with ARM64. Thus this article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\nIntroduction # This article describes cross-compiling rust for linux on x86_64 debian. There is still not enough computing power to build arm64 native kernel except for Apple Silicon.\nBtw, this article is in reference to these links\nhttps://github.com/Rust-for-Linux/linux/blob/rust/Documentation/rust/quick-start.rst https://docs.kernel.org/kbuild/llvm.html#cross-compiling Debian / Ubuntu Package Requirements # # Install build-requirements for kernel compile with LLVM. # Biggest difference to native build is # crossbuild-essential-arm64 needed to build` for arm64 apt install clang git llvm-dev libclang-dev build-essential \\ bc kmod cpio flex libncurses5-dev libelf-dev libssl-dev \\ dwarves bison lld curl crossbuild-essential-arm64 Before build kernel, we need to install some packages.\ncurl --proto \u0026#39;=https\u0026#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh rustup default 1.62 rustup component add rust-src # rustfmt and clippy is need for later developing and debugging. rustup component add rustfmt rustup component add clippy Install rust with curl. You can select just default options. Also current rust for linux working with 1.62. Some native compile is working well with recent version (1.64 tested, but cross compile not working).\nArch Package Requirements # TBD Clone linux from Rust-For-Linux # State of current rust-for-linux, they are under 6.0 RC\n# In my case use `Develop` as worksapce, you can replace this word. mkdir -p ~/Develop cd ~/Develop git clone https://github.com/Rust-for-Linux/linux.git -b rust clone like this.\nNecessary some rust scripts in Rust-For-Linux # In cloned linux directory.\ngit clone --recurse-submodules \\ --branch $(scripts/min-tool-version.sh rustc) \\ https://github.com/rust-lang/rust \\ $(rustc --print sysroot)/lib/rustlib/src/rust This work clone rustlib repository in your rust toolchain directory.\ncargo install --locked --version $(scripts/min-tool-version.sh bindgen) bindgen This work need to bind existing c code to rust code. s\nCheck RUST_AVAILABLE # cd ~/Develop/linux make LLVM=1 rustavailable $ make LLVM=1 rustavailable *** *** Rust compiler \u0026#39;rustc\u0026#39; is too new. This may or may not work. *** Your version: 1.62.1 *** Expected version: 1.62.0 *** Rust is available! Than if you get result like this it\u0026rsquo;s good to go (1.62.1 was fine to cross compile, but if you consider best fit, run rustup default 1.62.0.)\nConfigure linux source code with menuconfig # make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- defconfig make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- menuconfig General setup -\u0026gt; Rust support # In General setup -\u0026gt; Rust support , Enable this If you don\u0026rsquo;t see the flag, double-check that the make LLVM=1 rustavailable process was successful. For a detailed mailing thread on CONFIG_RUST see here. See details \u0026rharu; Kernel hacking -\u0026gt; Sample kernel code # For easy to develop rust kernel code we need some examples. You can get them with following menus.\nIn Kernel hacking -\u0026gt; Sample kernel code , enable it (not all of them..) when you interest. I don\u0026rsquo;t recommend you enable them when you write own driver. Because there\u0026rsquo;s some possibility make system slow or make unwanted log in dmesg. In particular, the netflitter example outputs too many dmesg, so it is recommended that you disable it unless you are studying the netfilter example. Kernel hacking -\u0026gt; Rust hacking # For debug rust kernel code or driver, need to enable some debug options.\nIn Kernel hacking -\u0026gt; Rust hacking , enables it and inside menus.\nCross compile # # -j4 for 4 core virtual machine, -j2 for 2 core, -j1 for single core. make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- LLVM=1 -j32 Build with following command. You need to set number of job considering assigned number of cores for virtual machine. (-j#)\nAlso while you build it, it will ask some flag. I just select default in my case.\nSimple compile speed comparation. # Machine / Environment Compile time M1 Max Virtual Machine (4 core 8GB RAM with aarch64 debian11) 16 minutes M1 Asahi Linux (4P+4E core 16GB RAM MacMini with 6.1.0-rc6-asahi) 11 minutes AMD Ryzen 5950x Native (16 core 32 thread, 64GB with x86_64) 3 minutes AMD Threadripper Pro 5975wx Native (32 core 64 thread, 256GB with x86_64) 2 minutes Install cross compiled kernel to arm64 virtual machine # TBD, will update asap. Install cross compiled kernel to raspberry pi # TBD, will update asap. ","date":"4 October 2022","externalUrl":null,"permalink":"/en/posts/cross_compiling_aarch64_rust_for_linux_from_x86_64_linux/","section":"Posts","summary":"In October 6, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nCurrent linux 6.1 rc1 doesn‚Äôt contain rust for linux with ARM64. Thus this article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\n","title":"Cross compiling aarch64(arm64) rust for linux from x86_64 machine","type":"posts"},{"content":"","date":"4 October 2022","externalUrl":null,"permalink":"/en/categories/linux/","section":"Categories","summary":"","title":"Linux","type":"categories"},{"content":"","date":"4 October 2022","externalUrl":null,"permalink":"/en/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"In October, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nmodules, out-of-tree # There are two main ways to develop kernel modules. In-Of-Tree and Out-Of-Tree. In this article, we\u0026rsquo;re going to make the Out-Of-Tree method a Rust kernel module.\nBefore we start # Check your kernel has been compiled with CONFIG_RUST=y. # Check with following command.\nzcat /proc/config.gz | grep -i CONFIG_RUST=y The result comes with CONFIG_RUST=y.\nBut you may not check from /proc/config.gz when using distibution kernel image that downloaded or pre-installed.\nNeed some build \u0026 install rust support kernel see here. See details \u0026rharu; Prepare $KDIR # $KDIR is path of kernel source.\nIn this article path of kernel source that system used for boot with CONFIG_RUST.\nKDIR and other kernel module descriptions See details \u0026rharu; In my case it\u0026rsquo;s ~/Develop/linux\n# /home/pmnxis/Develop/linux export KDIR=$HOME/Develop/linux Looking in to code # Let\u0026rsquo;s preview the code rust_out_of_tree.rs \u0026hellip;\nLicense and imports # 1 2 3 4 5 6 7 8 9 10 11 12 13 // SPDX-License-Identifier: GPL-2.0 //! Rust out-of-tree sample use kernel::prelude::*; module! { type: RustOutOfTree, name: \u0026#34;rust_out_of_tree\u0026#34;, author: \u0026#34;Rust for Linux Contributors\u0026#34;, description: \u0026#34;Rust out-of-tree sample\u0026#34;, license: \u0026#34;GPL\u0026#34;, } Lines 1~3, show file\u0026rsquo;s license information. If you are write the code in company, SomeCompanyName instead GPL-2.0 or just keep GPL-2.0. 1 2 3 4 5 6 7 8 9 10 11 12 13 // SPDX-License-Identifier: GPL-2.0 //! Rust out-of-tree sample use kernel::prelude::*; module! { type: RustOutOfTree, name: \u0026#34;rust_out_of_tree\u0026#34;, author: \u0026#34;Rust for Linux Contributors\u0026#34;, description: \u0026#34;Rust out-of-tree sample\u0026#34;, license: \u0026#34;GPL\u0026#34;, } Line 5 means, bring rust for linux library for this code.\nIn following example module written in C were include like this.\n2 3 4 #include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kthread.h\u0026gt; #include \u0026lt;linux/irq_work.h\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 // SPDX-License-Identifier: GPL-2.0 //! Rust out-of-tree sample use kernel::prelude::*; module! { type: RustOutOfTree, name: \u0026#34;rust_out_of_tree\u0026#34;, author: \u0026#34;Rust for Linux Contributors\u0026#34;, description: \u0026#34;Rust out-of-tree sample\u0026#34;, license: \u0026#34;GPL\u0026#34;, } Line 8, implement of the module trait. Line 9, name of the module, if we written c, it\u0026rsquo;s the name of *.ko name field. Line 10~12, those fields are simillar with below the example written in c. Those fields are same purpose.\n56 57 58 MODULE_AUTHOR(\u0026#34;Steven Rostedt\u0026#34;); MODULE_DESCRIPTION(\u0026#34;trace-printk\u0026#34;); MODULE_LICENSE(\u0026#34;GPL\u0026#34;); We preview macro_rule! module shortly. You can see detail here.\nDetails for module! See details \u0026rharu; Actual implements # 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 struct RustOutOfTree { numbers: Vec\u0026lt;i32\u0026gt;, } impl kernel::Module for RustOutOfTree { fn init(_name: \u0026amp;\u0026#39;static CStr, _module: \u0026amp;\u0026#39;static ThisModule) -\u0026gt; Result\u0026lt;Self\u0026gt; { pr_info!(\u0026#34;Rust out-of-tree sample (init)\\n\u0026#34;); let mut numbers = Vec::new(); numbers.try_push(72)?; numbers.try_push(108)?; numbers.try_push(200)?; Ok(RustOutOfTree { numbers }) } } impl Drop for RustOutOfTree { fn drop(\u0026amp;mut self) { pr_info!(\u0026#34;My numbers are {:?}\\n\u0026#34;, self.numbers); pr_info!(\u0026#34;Rust out-of-tree sample (exit)\\n\u0026#34;); } } I just guess working as \u0026hellip;\nOn init (insmod?), print out somewhere with text Rust out-of-tree sample (init) vec\u0026lt;i32\u0026gt;[72, 108, 200] is stored some kernel memory space with struct RustOutOfTree. When drop the module (rmmod?), will print out with text [72, 108, 200]. By the way, we need to keep on eyes here.\n23 24 let mut numbers = Vec::new(); numbers.try_push(72)?; In line 24, try_push is not exsting in std::Vec. In rust kernel programming, need to use try_push instead std::Vec::push.\nDetails for alloc::vec::Vec See details \u0026rharu; Also there's some `init` and `drop` functions in line 20 and 33. The code covers those function with `impl for` pattern. Details for Implementation in rust See details \u0026rharu; I will explain about implementation and it\u0026rsquo;s philosophy later article.\nRun code # Build it # make LLVM=1 My rust acceptable kernel build were buiten with LLVM.\nSo I compile the kernel module with LLVM.\nInstall module # sudo insmod ./rust_out_of_tree.ko After compile, we can there\u0026rsquo;s rust_out_of_tree.ko inside of project directory.\nWe can install module with insmod that normally used before.\nInspect result # # do `sudo rmmod rust_out_of_tree` if you already install the module` # clear all of dmesg log sudo dmesg -C # install the module sudo insmod ./rust_out_of_tree.ko # see log dmesg # uninstall the module sudo rmmod rust_out_of_tree # check log again. dmesg We can check the inspect actual result with above commands.\nAs we guess it prints with [72, 108, 200].\nConclusion # We can summary from this simple kernel module.\nSummary # Need to use use kernel::prelude::*; on top of code. module! macro to define some description and board my own struct to the kernel module. kernel::Module templete functions \u0026hellip;. -WIP- In kernel programming, use alloc::vec::Vec instead std::Vec. pr_info is just same as way to write with C. Reference # https://github.com/Rust-for-Linux/rust-out-of-tree-module https://www.kernel.org/doc/html/latest/kbuild/modules.html https://github.com/Rust-for-Linux/linux https://rust-for-linux.github.io/docs/kernel/prelude/index.html https://rust-for-linux.github.io/docs/kernel/prelude/macro.module.html https://rust-for-linux.github.io/docs/kernel/prelude/struct.Vec.html ","date":"2 October 2022","externalUrl":null,"permalink":"/en/posts/look_into_simple_rust_out_of_tree/","section":"Posts","summary":"In October, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nmodules, out-of-tree # There are two main ways to develop kernel modules. In-Of-Tree and Out-Of-Tree. In this article, we‚Äôre going to make the Out-Of-Tree method a Rust kernel module.\n","title":"[Rust Driver] Let's try build example rust linux driver.","type":"posts"},{"content":"","date":"2 October 2022","externalUrl":null,"permalink":"/en/tags/rust-driver/","section":"Tags","summary":"","title":"Rust Driver","type":"tags"},{"content":"In October 1, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nThis article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\nIntroduction # Currently Apple Silicon mac series is only one ARM workstation that have powerful performance as normal desktop class workstation and can purchase anywhere. Of course if you have 32GB or bigger memory and least 8 big cores of apple silicon.\nBtw, this article is in reference to https://github.com/Rust-for-Linux/linux/blob/rust/Documentation/rust/quick-start.rst .\nVM hypervisor software selection. # UTM : Free / OpenSource, QEMU based Sometimes tricky. VM Fusion Tech Preview : Free for now / ClosedSource, Moderate Parallels : Non-Free / ClosedSource, not my taste (sorry). There\u0026rsquo;s some option working with Asahi Linux. But in this article is not consider native asahi linux environment.\nIn my case, I was chosen VM Fusion.\nVirtual Machine Configuration # Debian 11 : https://cdimage.debian.org/debian-cd/current/arm64/iso-dvd/ !! Checked working well.\nUbuntu : There were some issue clang and other gcc build tools version mismatch than broken apt things in aarch64 ubuntu apt repo. But you can try with ubuntu.\nArch Linux : https://gitlab.archlinux.org/tpowa/archboot/-/wikis/Archboot-Homepage#aarch64-architecture I didn\u0026rsquo;t tested yet. But tested with Asahi linux with M1 Mac Mini\nDebian / Ubuntu Package Requirements # # Install build-requirements for kernel compile with LLVM. apt install clang git llvm-dev libclang-dev build-essential \\ bc kmod cpio flex libncurses5-dev libelf-dev libssl-dev \\ dwarves bison lld curl Asahi Linux Package Requirements # pacman -S base-devel cpio lld llvm llvm-libs bc libdwarf Ready for rust # Before build kernel, we need to install some packages.\ncurl --proto \u0026#39;=https\u0026#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh rustup default 1.62 rustup component add rust-src # rustfmt and clippy is need for later developing and debugging. rustup component add rustfmt rustup component add clippy Install rust with curl. You can select just default options. Also current rust for linux working with 1.62. Some native compile is working well with recent version (1.64 tested, but cross compile not working).\nClone linux from Rust-For-Linux # State of current rust-for-linux, they are under 6.0 RC\n# In my case use `Develop` as worksapce, you can replace this word. mkdir -p ~/Develop cd ~/Develop git clone https://github.com/Rust-for-Linux/linux.git -b rust clone like this.\nNecessary some rust scripts in Rust-For-Linux # In cloned linux directory.\ngit clone --recurse-submodules \\ --branch $(scripts/min-tool-version.sh rustc) \\ https://github.com/rust-lang/rust \\ $(rustc --print sysroot)/lib/rustlib/src/rust This work clone rustlib repository in your rust toolchain directory.\ncargo install --locked --version $(scripts/min-tool-version.sh bindgen) bindgen This work need to bind existing c code to rust code. s\nCheck RUST_AVAILABLE # cd ~/Develop/linux make LLVM=1 rustavailable $ make LLVM=1 rustavailable *** *** Rust compiler \u0026#39;rustc\u0026#39; is too new. This may or may not work. *** Your version: 1.64.0 *** Expected version: 1.62.0 *** Rust is available! Than if you get result like this it\u0026rsquo;s good to go\nConfigure linux source code with menuconfig # make ARCH=arm64 defconfig make menuconfig Disable GCC plugins # General architecture-dependent options -\u0026gt; GCC plugins For now (6.1 rc*), GCC_PLUGINS config should be disabled for RUST_CONFIG config. Be sure disable it.\nGeneral setup -\u0026gt; Rust support # In General setup -\u0026gt; Rust support , Enable this If you don\u0026rsquo;t see the flag, double-check that the make LLVM=1 rustavailable process was successful. For a detailed mailing thread on CONFIG_RUST see here. See details \u0026rharu; Kernel hacking -\u0026gt; Sample kernel code # For easy to develop rust kernel code we need some examples. You can get them with following menus.\nIn Kernel hacking -\u0026gt; Sample kernel code , enable it (not all of them..) when you interest. I don\u0026rsquo;t recommend you enable them when you write own driver. Because there\u0026rsquo;s some possibility make system slow or make unwanted log in dmesg. In particular, the netflitter example outputs too many dmesg, so it is recommended that you disable it unless you are studying the netfilter example. Kernel hacking -\u0026gt; Rust hacking # For debug rust kernel code or driver, need to enable some debug options.\nIn Kernel hacking -\u0026gt; Rust hacking , enables it and inside menus.\nCompile and install it in virtual machine. # # -j4 for 4 core virtual machine, -j2 for 2 core, -j1 for single core. make LLVM=1 -j4 Build with following command. You need to set number of job considering assigned number of cores for virtual machine. (-j#)\nAlso while you build it, it will ask some flag. I just select default in my case.\nIt takes lot of time (don\u0026rsquo;t worry much better than raspberry pi 4), 13~14 minuites takes in my environment (VM 4core, 8GB)\nAfter than, install via following command\n# should be under the root permision. make modules_install make install update-grub It\u0026rsquo;s done!. Reboot program and then check the kernel working well.\nLinux lambda-next 6.0.0-rc7-175589-g542379556669 #2 SMP PREEMPT Sun Oct 2 19:02:32 KST 2022 aarch64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Sun Oct 2 18:20:21 2022 from 192.168.99.1 pmnxis@lambda-next:~$ uname -r 6.0.0-rc7-175589-g542379556669 Simple compile speed comparation. # Machine / Environment Compile time M1 Max Virtual Machine (4 core 8GB RAM with aarch64 debian11) 16 minutes M1 Asahi Linux (4P+4E core 16GB RAM MacMini with 6.1.0-rc6-asahi) 11 minutes AMD Ryzen 5950x Native (16 core 32 thread, 64GB with x86_64) 3 minutes AMD Threadripper Pro 5975wx Native (32 core 64 thread, 256GB with x86_64) 2 minutes ","date":"1 October 2022","externalUrl":null,"permalink":"/en/posts/rust_for_linux_with_m1/","section":"Posts","summary":"In October 1, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nThis article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\n","title":"Rust For Linux Development Environment with AppleSilicon MacOS","type":"posts"},{"content":" Introduction # ARMv8A, also commonly known as aarch64, is one of the widely used architectures that has largely succeeded ARMv7A. In this article, we will examine the ARMv8A memory system at the IP (Intellectual Property) block level.\nWhile there are slight differences depending on the memory type used (DDR4, LPDDR4, DDR3, LPDDR3, DDR2) and the architecture version (ARM v8.1 or 8.2), the overall structure generally follows the form shown in the diagram above.\nComponents # CPU # Processes instructions.\nGIC # Generic Interrupt Controller; The GIC manages various nested interrupts. When an interrupt occurs, it backs up the PC/registers that were active on the CPU and directs execution to the corresponding interrupt vector.\nCCI / CCN # Cache Coherent Interconnect / Network\nDMC # Manages DRAM. DRAM is volatile memory that requires operations beyond simple Read/Write, such as Refresh and Calibration. Additionally, it handles ECC and RAS management. In the Linux driver codebase, you can find the ECC and RAS management driver code under the edac directory.\nNIC # Used to connect various peripherals.\nMMU # PA/VA (Physical/Virtual Address) translation DMA control Reference # CCI-400 ; https://developer.arm.com/Processors/CoreLink%20CCI-400 CCI-500 ; https://developer.arm.com/Processors/CoreLink%20CCI-500 DMC-400 ; DDR3/DDR2 DMC ; https://developer.arm.com/documentation/ddi0466/f/introduction/about-the-dmc-400 DMC-500 ; LPDDR4/LPDDR3 DMC ; https://developer.arm.com/documentation/100131/0000 ","date":"14 December 2021","externalUrl":null,"permalink":"/en/posts/arm_v8a_memory_ip_review/","section":"Posts","summary":"Introduction # ARMv8A, also commonly known as aarch64, is one of the widely used architectures that has largely succeeded ARMv7A. In this article, we will examine the ARMv8A memory system at the IP (Intellectual Property) block level.\n","title":"ARMv8A Memory IP Review","type":"posts"},{"content":"","date":"14 December 2021","externalUrl":null,"permalink":"/en/tags/electronics/","section":"Tags","summary":"","title":"Electronics","type":"tags"},{"content":"","externalUrl":null,"permalink":"/en/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/en/g-vcbqvyzx51/","section":"G Vcbqvyzx51","summary":"","title":"G Vcbqvyzx51","type":"g-vcbqvyzx51"},{"content":"","externalUrl":null,"permalink":"/en/series/","section":"Series","summary":"","title":"Series","type":"series"}]