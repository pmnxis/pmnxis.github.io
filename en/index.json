[{"content":"Effective Date: February 16, 2026\nThis page is managed via GitHub Pages automatic deployment. Any changes to this Privacy Policy can be verified through the commit history of the GitHub repository.\nChama Optics (hereinafter \u0026ldquo;the App\u0026rdquo;) is a photo post-processing application developed and operated by Jinwoo Park (hereinafter \u0026ldquo;the Developer\u0026rdquo;). This Privacy Policy explains how your personal information is handled when using the App.\n1. Information We Collect # Chama Optics does not collect, store, or transmit any personal information.\nThe App does not require account creation, sign-up, or login. We do not collect any personally identifiable information such as names, email addresses, phone numbers, or location data. We do not collect information for analytics, advertising, or tracking purposes. We do not collect device identifiers, IP addresses, or cookies. 2. App Permissions and Purpose of Access # Chama Optics may request the following device permissions to provide its photo post-processing features.\nPermission Purpose Data Transmission Photo Library Access To load photos selected by the user for applying frames, mosaic, and other post-processing effects None (on-device processing) Storage Access To save processed photos to the device None (on-device storage) Requested permissions are used solely for the App\u0026rsquo;s core functionality (photo post-processing). The App does not request access to camera, microphone, contacts, or location. 3. Photos and Image Data # Photos selected by the user are processed entirely on the device. Photo data is never transmitted to external servers. EXIF data (camera model, lens, shooting settings, etc.) is read locally on the device for frame generation only and is never transmitted externally. Processed photos are saved to the user\u0026rsquo;s device storage and can be managed (deleted, etc.) directly by the user. 4. Face Detection Processing # Chama Optics provides a feature that automatically detects faces in photos and applies mosaic, stickers, or other overlays.\nAll face detection processing is performed entirely on-device. Face data is never transmitted to external servers. Face data is not stored and is immediately removed from memory once processing is complete. Face detection results are not used to identify individuals; they are used solely to determine the areas where mosaic or sticker effects are applied. Technologies used by platform: iOS: Apple Vision Framework (on-device processing) Android: Google ML Kit Face Detection (on-device processing, no data sent to Google servers) Desktop (macOS/Windows/Linux): ONNX Runtime + SCRFD model (on-device processing) Note for Android users: Google ML Kit Face Detection operates entirely on-device. Face images and detection results are not transmitted to Google servers. For more details, see the Google ML Kit Terms of Service.\n5. Data Security # The App does not collect personal information, so no user data is transmitted externally. All photo processing is performed on the user\u0026rsquo;s device, with no communication to external servers. The core libraries of the App are open source and available on GitHub for transparency. 6. Data Retention and Deletion # Chama Optics does not store any user data on servers. Temporary data generated during photo processing (such as face detection coordinates) is immediately deleted from memory upon completion. Processed result images are saved to the user\u0026rsquo;s device storage and can be deleted by the user through the device\u0026rsquo;s file management features. Uninstalling the App removes all local data associated with it. 7. Network Usage # Chama Optics does not require an internet connection for photo processing. The App operates offline by default. Network communication initiated by the platform (App Store, Google Play) for features such as update checks is governed by the respective platform\u0026rsquo;s policies. 8. Third-Party Sharing # Chama Optics does not sell, provide, or share user data with any third parties. The App does not include any third-party advertising SDKs, analytics SDKs, social login SDKs, or similar services. Google ML Kit used in the Android version operates on-device only and does not transmit user data to Google. 9. Children\u0026rsquo;s Privacy # Chama Optics is not directed at children under the age of 13. Since the App does not collect any personal information from any user, there is no separate collection process for children. 10. Changes to This Privacy Policy # If this policy is updated, the changes will be posted on this page and the effective date will be updated. For significant changes, notice will be provided through app updates or the GitHub repository. 11. Contact # If you have any questions or concerns regarding this Privacy Policy, please contact us at:\nDeveloper: Jinwoo Park GitHub: https://github.com/pmnxis/chama-optics Email: pmnxis@gmail.com ","date":"16 February 2026","externalUrl":null,"permalink":"/en/chama-optics-privacy/","section":"Welcome to Jinwoo and Lambda üê± 's blog","summary":"Effective Date: February 16, 2026\nThis page is managed via GitHub Pages automatic deployment. Any changes to this Privacy Policy can be verified through the commit history of the GitHub repository.\n","title":"Chama Optics Privacy Policy","type":"page"},{"content":" Here\u0026rsquo;s my cat LambdaŒª who expert on electronic engineering. This blog mainly cover with Linux, Rust, Embedded, and electronic circuits, and articles in Korean and English are mixed. Sometimes my cat LambdaŒª appears frequently, so I would appreciate it if you liked it. Nyaa ","date":"16 February 2026","externalUrl":null,"permalink":"/en/","section":"Welcome to Jinwoo and Lambda üê± 's blog","summary":" Here‚Äôs my cat LambdaŒª who expert on electronic engineering. This blog mainly cover with Linux, Rust, Embedded, and electronic circuits, and articles in Korean and English are mixed. Sometimes my cat LambdaŒª appears frequently, so I would appreciate it if you liked it. Nyaa ","title":"Welcome to Jinwoo and Lambda üê± 's blog","type":"page"},{"content":"","date":"14 February 2026","externalUrl":null,"permalink":"/en/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"14 February 2026","externalUrl":null,"permalink":"/en/categories/chama-optics/","section":"Categories","summary":"","title":"Chama Optics","type":"categories"},{"content":"EXIF-based photo frame + automatic face detection app, from desktop to mobile with a Rust core\nThis is probably the first time I\u0026rsquo;ve openly written an otaku-ish post on this blog. Honestly, I started writing this quite a while ago, but I couldn\u0026rsquo;t figure out whether to target the audience as developers or VTuber otaku. In the end, I decided to just go with the flow and list everything I developed and contributed.\nThis blog has mainly covered Rust Embedded topics, and I previously worked on a Rust Embedded mass-production project called billmock-app-rs.\nThis post introduces the development journey of Chama Optics.\nThe official release of 0.2.0 for iOS / Android / macOS / Linux / Windows is planned for the last week of February 2026, and this article covers the development process before App Store and Google Play approval.\nüåê ÌïúÍµ≠Ïñ¥ ÏïÑÌã∞ÌÅ¥ | Êó•Êú¨Ë™û„Ç¢„Éº„ÉÜ„Ç£„ÇØ„É´\nProject Introduction # Chama Optics is a photo post-processing application that analyzes EXIF data from photos taken with DSLR/mirrorless cameras, applies various themed frames, and adds effects such as watermarks, mosaics, and stickers. The name \u0026ldquo;Chama\u0026rdquo; is derived from the nickname of travel VTuber Akai Haato (Ëµ§‰∫ï„ÅØ„ÅÇ„Å®).\nI\u0026rsquo;ve gone through countless mobile devices, but my interest has always been on the making side of electronics, and I was far from smartphone app development. As a fan of Hololive JP 1st Generation member Akai Haato (HAACHAMA), my otaku life led me to start my first project in a software development domain outside of embedded systems.\nI first conceptualized this program in March 2025. At the time, I wanted it to run as a web app, and I was testing libraries, the WASM environment, and porting libheif. In August 2025, after attending Amane Kanata\u0026rsquo;s solo live LOCK-ON in Tokyo, Japan, and the AnimeNYC World Tour + EN Concert (All for one) in New York, USA, I keenly felt the need to quickly organize photos, compress them to WEBP, and post them. At the same time, Akai Haato had recently taken a liking to photography \u0026ndash; showing the camera she uses in membership-only posts and encouraging photo posting on #Êé®„ÅóÊ¥ª„ÅØ„ÅÇ„Å®„ÇìÊó•Ë®ò (Oshikatsu Haaton Diary). I wanted to develop an app under the Haato (HAACHAMA) name for her.\nRecent 3D Live Akai Haato X(twitter) /Ôºè üì¢ Êú¨Êó•ÔºíÔºëÔºöÔºêÔºê„Åã„Çâ‚ÄºÔ∏è\n\\Ôºº\nËµ§‰∫ï„ÅØ„ÅÇ„Å®ÁîüË™ï3D LIVEÈñãÂÇ¨!!üéä\nüéÅ„ÉÜ„Éº„Éû„ÅØ„Éõ„É©„Éº‚ÅâÔ∏è\nüéÅ„Ç≤„Çπ„ÉàÂ§öÊï∞\u0026amp;ÂëäÁü•„ÅÇ„Çä‚óé\nüéÅÊºîÂá∫„ÅØ„Åì„Å†„Çè„ÇäÊ∫ÄÂ§©ü•≥\n„ÉÄ„É≥„Çπ„ÇÑÊ≠å„ÇÇÁ≤æ‰∏ÄÊùØ„Åå„Çì„Å∞„Å£„Åü„ÅÆ„Åß\n„Åø„Çì„Å™ÊòØÈùûÔºÅË¶ã„Å´Êù•„Å¶„Å≠„Å£‚ùïüëÄ‚ú®#Ëµ§‰∫ï„ÅØ„ÅÇ„Å®ÁàÜË™ïÁ•≠2025\n„ÄêÈñãÂÇ¨Â†¥ÊâÄ„Äëhttps://t.co/3IUA2stYWi‚Ä¶ pic.twitter.com/A1OqUBCbsM\n\u0026mdash; Ëµ§‰∫ï„ÅØ„ÅÇ„Å®‚ù§Ô∏è‚Äçüî•ÊóÖ„Åô„Çã„Ç¢„Ç§„Éâ„É´ (@akaihaato) August 9, 2025 Âõõ‰∏áÊ∏©Ê≥â„Çπ„ÉÜ„Ç≠„Å™Â†¥ÊâÄ„Åß„Åó„Åü„ÄÇ\n„Åê„Çì„Åæ„ÉºÂ∏ùÂõΩ„ÄÅ„ÅÇ„Çä„Åå„Å®„Çì‚ù§Ô∏è‚Äçüî• pic.twitter.com/Ov0CwFRF7V\n\u0026mdash; Ëµ§‰∫ï„ÅØ„ÅÇ„Å®‚ù§Ô∏è‚Äçüî•ÊóÖ„Åô„Çã„Ç¢„Ç§„Éâ„É´ (@akaihaato) April 26, 2025 When developing the program, I adhered to these principles:\nThere must be no architectural discrimination across desktop platforms. It must be minimally tied to MS or Apple\u0026rsquo;s development ecosystems. It must not use many resources and must be fast. These goals might sound grandiose, but really I\u0026rsquo;m just a Rust enthusiast and that\u0026rsquo;s why these are the goals.\nThe Beginning: Making EXIF Frames Easier # I didn\u0026rsquo;t plan a grand cross-platform app from the start.\nAmong camera enthusiasts, there\u0026rsquo;s a culture of sharing photos with frames that display camera model, lens, shutter speed, and other information based on EXIF data. I enjoyed this practice too, and had been referencing a web-based tool called exif-frame. However, I was frustrated by its lack of HEIF format support and limitations with high-resolution image output, so the idea to build it myself is what sparked Chama Optics.\nInitially, I only considered desktop use. I had vague thoughts about mobile, but since I always carried my MacBook around even when traveling, mobile wasn\u0026rsquo;t on my radar at all. Pulling the SD card from the camera, organizing photos on the MacBook, applying frames, and uploading \u0026ndash; that workflow was second nature.\nChange of Direction: \u0026ldquo;You Can\u0026rsquo;t Take a Laptop at Concert Hall\u0026rdquo; # Two things prompted the change in direction.\nCultural Differences at Events \u0026ndash; What I Noticed at AnimeNYC and East Asia # In August 2025, I visited the US for AnimeNYC and the Hololive World Tour / EN Concert. I noticed an interesting difference there. In the US, people tended not to mosaic other people\u0026rsquo;s faces when posting event photos. But at events in Korea and Japan, mosaicing other people\u0026rsquo;s faces is considered proper etiquette and an unspoken rule.\n\u0026ldquo;Mosaicing other people\u0026rsquo;s faces\u0026rdquo; is too tedious to do manually every time. Especially when you have dozens or hundreds of photos. The thought that automatic face detection + mosaic/sticker functionality was needed started to weigh heavily from this point.\nThe Upcoming Hololive Expo # Another motivator was the Hololive Expo/Festival in March 2026. What if you could take photos at the venue, apply frames on the spot, process mosaics, and post to social media right there? But you can\u0026rsquo;t open a MacBook at an event. It had to be processable directly on a smartphone.\nRequests from Others # On top of this, people around me started requesting an iOS version. So I started developing for iOS, and then requests for an Android version came in too.\nThis is how a desktop-only program expanded to support iOS and eventually Android. For mobile, the design direction shifted to consider the general user experience more than mirrorless camera users. The starting point of EXIF frames remained, but a new use case was added: \u0026ldquo;quickly processing and sharing photos on-site at events.\u0026rdquo;\nArchitecture: From Desktop to Mobile # Originally, I planned to build only a desktop app with Rust + egui. Writing all the core logic in Rust turned out to be a great decision. When expanding to iOS/Android, I was able to reuse the core code for image processing, EXIF parsing, theme rendering, and encoding/decoding as-is.\nOn desktop, the Rust core is used via direct linking. On iOS, it\u0026rsquo;s called from Swift via C FFI. On Android, it\u0026rsquo;s called from Kotlin via JNA (Java Native Access). The Rust core is managed as a git submodule, and core features like EXIF interpretation, image overlays (text, EXIF, margins, scaling, encoding/decoding) are shared across all platforms.\nHowever, face detection uses a different strategy per platform:\nDesktop (macOS/Windows/Linux): ONNX Runtime + InsightFace (SCRFD det_10g) model. Depending on Speed Mode, a sliding window with a fixed 640x640 input size is applied in multiple stages (2560/1280/640) to detect even small faces, with NMS to remove duplicates. iOS: Uses Apple Vision Framework natively. Fast and accurate without ONNX models, and favorable for privacy. Android: Uses Google ML Kit (com.google.mlkit:face-detection) \u0026ndash; Google\u0026rsquo;s on-device face detection library, mapping Rust core\u0026rsquo;s speed_mode to FAST/ACCURATE performance modes. Why I Gave Up on the Web Version # I\u0026rsquo;m not well-versed in web apps or how the web and browsers work. Despite that, Chama Optics was initially designed with Web (WASM) in mind. Since egui supports WASM, I had a vague expectation that \u0026ldquo;desktop and web could work simultaneously.\u0026rdquo; But I gave up after trying to implement these two features:\nHEIF decoding Drag \u0026amp; Drop in egui Web HEIF: WASM on Top of WASM, with JS in Between # Before the difficulty of running libheif in the browser, the fundamental architecture didn\u0026rsquo;t make sense to me. libheif is already compiled to WASM, and the egui app is also WASM. The fact that communication between these two had to go through JavaScript-based FFI multiple times didn\u0026rsquo;t sit right with me. Most cross-language FFI is done through C, so I couldn\u0026rsquo;t understand why the JS ecosystem required this approach.\nDrag \u0026amp; Drop: A Desktop Developer\u0026rsquo;s Expectations vs. Reality # Beyond Drag \u0026amp; Drop, I expected WASM to receive events from the browser in ways more typical of desktop/embedded development \u0026ndash; like receiving the DOM in binary form rather than through JS \u0026ndash; but that wasn\u0026rsquo;t the case.\nHonestly, I Only Know C and Rust # I only know C and Rust. In other words, I\u0026rsquo;m either completely ignorant about web development, or I\u0026rsquo;ve done it in very bizarre ways in the past.\nOnce I had to display a large amount of data on the web, and since I didn\u0026rsquo;t know how, I created the data as CSV, then used a hex editor to do a bulk find-and-replace of , and \\n with HTML tags like \u0026lt;div\u0026gt; to create a static website and deployed it. With 25% of the 21st century already behind us, even I thought \u0026ldquo;what am I doing?\u0026rdquo;\nOf course, since WASM is web technology, following the web ecosystem and its conventions is the norm. But since I\u0026rsquo;m not a web developer, I couldn\u0026rsquo;t get on board. I was very far removed from the JS/Web ecosystem, and building native mobile apps felt far more natural than overcoming these fundamental differences in development philosophy. In v0.1.9-beta, I officially removed WASM support and directed that energy toward iOS/Android native development.\nDevelopment Journey Through the Timeline # v0.1.0~v0.1.1 (2025-10-19~21) \u0026ndash; First Pre-release # First binary release for macOS/Windows. Film theme frame, Japanese translation, batch save, filename prefix/suffix settings. macOS code-signed DMG distribution and Korean/English/Japanese installation guide wiki.\nv0.1.2~v0.1.6 (2025-10-27~11-24) \u0026ndash; Theme Expansion and Watermarks # Film Date Theme Strap Theme Monitor Theme Lightroom Theme Added Film Date/Film Glow/Just Frame/Strap/Monitor/Lightroom themes. Watermark (9 positions, opacity, blend mode), font selection (built-in + OS fonts), automatic camera manufacturer logo, HEIF orientation fix, initial variable font support, Longside scale option.\nv0.1.7 (2025-11-26~12-19) \u0026ndash; CJK Rendering Improvements and Open-Source Contributions # One Line Theme Shot On Two Line Theme Nikon PhotoStyle Lumix Photo Style + LUT One Line/Two Line/Shot On themes. Major CJK glyph rendering improvements with SourceHanSans fallback built-in. Submitted a PR to exif-rs to extract Lumix LUT and Nikon PhotoStyle names from EXIF, pre-applied before merge.\nv0.1.8 (2025-12-25~27) \u0026ndash; UI Renewal and Performance Improvements # Image List Tab Theme Settings Tab Tab-based interface (4 tabs), EXIF variable auto-completion, automatic image grouping, 2MP MPF preview-based theme previews, Rayon multi-core parallel processing, system font loading memory issue fix. Also submitted a PR to egui.\nv0.1.9 (2026-01-18~02-04) \u0026ndash; Face Detection, LUT, and First iOS Release # Face Detection (Desktop) Mosaic Applied Color Grading UI LUT Applied Result iOS Gallery iOS Editing The last desktop-only release and the first iOS app release. ONNX (InsightFace) face detection + mosaic/stroke/sticker overlays. 1D/3D LUT color grading (wagahai-lut). iOS uses SwiftUI + Vision Framework native face detection, with a Rust FFI bridge (ffi_ios.rs + RustBridge.swift). Indonesian translation added.\nTechnical Challenges and Solutions # Let me first summarize the performance strategies applied throughout the project:\nRayon parallel processing \u0026ndash; Multi-core utilization for batch image export. However, for pixel-level processing like color correction, parallelization with par_chunks_exact_mut() is applied only when the image exceeds 100,000 pixels; smaller images use sequential processing to avoid context-switching overhead. fast_image_resize-based resizing \u0026ndash; Instead of the image crate\u0026rsquo;s default resize, SIMD-optimized fast_image_resize significantly improves thumbnail generation and preview resizing speed. Lazy loading and caching \u0026ndash; LUT files are parsed and cached in lut_cache: HashMap\u0026lt;Uuid, CubeLut\u0026gt; on first use, and EXIF thumbnails are lazy-loaded into thumbnail_cache. When cloning for background threads (clone_for_thread()), the cache is excluded to prevent unnecessary memory duplication. Perceptual hash-based image grouping \u0026ndash; On image load, an 8x8 grayscale average hash (64-bit) is pre-computed, enabling subsequent similar image grouping via Hamming distance O(1) comparison. Grouping is done using only metadata without reloading original images. Build profile optimization \u0026ndash; Release builds use opt-level = 3, lto = \u0026quot;fat\u0026quot;, codegen-units = 1. Even in Dev builds, performance-sensitive dependencies like fast_image_resize, mozjpeg, and ab_glyph are individually set to opt-level = 3 to maintain image processing performance during debugging. 1. Cross-Platform FFI Complexity # Different FFI strategies were adopted to use the Rust core across three platforms (desktop/iOS/Android):\nPlatform FFI Method Characteristics Desktop (egui) Direct Linking Rust to Rust, no FFI needed iOS (SwiftUI) C FFI (@_silgen_name) Direct C function calls from Swift Android (Compose) JNA (Java Native Access) .so invocation from Kotlin via JNA The main challenge was maintaining this bridge layer while ensuring stable memory management (string allocation/deallocation, opaque pointer handle patterns).\n2. The Endless Variables of EXIF Parsing # EXIF recording methods differ across cameras:\nShutter speed / F-value floating-point issues \u0026ndash; Cases where 1/125 sec is recorded as a messy value like 0.008000000, requiring automatic correction HEIF/HEIC orientation errors \u0026ndash; Orientation being incorrect in some images Cameras without lens information \u0026ndash; Handling compact cameras like Nikon Coolpix Information hidden in MakerNote \u0026ndash; Parsing vendor-specific non-public EXIF fields like Lumix LUT names, Nikon PhotoStyle, Sony Creative Look For this, I submitted PRs directly to the exif-rs library to add the needed functionality.\n3. MakerNote Parsing: Extracting Per-Manufacturer Shooting Settings # Recent mirrorless cameras have excellent built-in color grading features. Lumix\u0026rsquo;s Photo Style, Nikon\u0026rsquo;s Picture Control, Sony\u0026rsquo;s Creative Look, and so on. Among photographers, \u0026ldquo;which color setting was used\u0026rdquo; is as important as the camera model or lens, and I thought it would be great to include this information in the frame.\nThe EXIF standard\u0026rsquo;s MakerNote (Tag 0x927C) is a non-standard area that camera manufacturers can use freely. The format differs between manufacturers \u0026ndash; and even between models from the same manufacturer \u0026ndash; and documentation is sparse. But it hides information important to photographers, like \u0026ldquo;which color setting was used for the shot.\u0026rdquo;\nIn Chama Optics, the manufacturer is first identified via exif.maker_note_vendor(), then dispatched to manufacturer-specific parsers.\nNikon \u0026ndash; Extracts Picture Control names from the PictureControlData / PictureControlData2 tags. User-defined profile names like \u0026quot;VitalityFilm_Pmango\u0026quot; or preset names like \u0026quot;Flat\u0026quot;, \u0026quot;Vivid\u0026quot; are found here.\nPanasonic (Lumix) \u0026ndash; Provides the richest data. Extracts the base Photo Style name (\u0026quot;NostalgicKintex\u0026quot;) from PhotoStyleName, and the applied LUT filename (\u0026quot;KintexYellow33.CUBE\u0026quot;) along with Gain values from LutPrimaryFile/LutSecondaryFile. This information directly connects to Chama Optics\u0026rsquo; LUT color grading feature.\nSony \u0026ndash; Extracts Creative Style/Creative Look information (\u0026quot;Vivid\u0026quot;, \u0026quot;Standard\u0026quot;, \u0026quot;Portrait\u0026quot;, etc.) from the Sony_0x9416 tag.\nThis MakerNote parsing feature didn\u0026rsquo;t exist in exif-rs, so I implemented it myself and submitted it as PR #57.\nEXIF IFD Entry Structure and MakerNote Offset Issues # To parse MakerNote, you first need to understand EXIF\u0026rsquo;s IFD (Image File Directory) structure. EXIF data is based on the TIFF format, and each IFD entry is exactly 12 bytes:\nTag (2 bytes) \u0026ndash; Field identifier (e.g., 0x927C = MakerNote) Type (2 bytes) \u0026ndash; Data type Count (4 bytes) \u0026ndash; Number of values Value/Offset (4 bytes) \u0026ndash; The value itself if data is 4 bytes or less; otherwise, an offset pointing to the data\u0026rsquo;s location In standard EXIF, this offset is the distance from the TIFF header start. Simple and straightforward. But within MakerNote\u0026rsquo;s internal IFD, this rule breaks down.\nHere\u0026rsquo;s the problem: MakerNote also contains entries with the same structure as IFD entries, but the reference point for offsets \u0026ndash; \u0026ldquo;distance from where?\u0026rdquo; \u0026ndash; differs by manufacturer.\nTIFF-Relative method (Panasonic, Canon, Sony, Leica, Sigma) \u0026ndash; Offsets inside MakerNote are relative to the original TIFF header start. The MakerNote itself has no TIFF header, and you need to subtract tiff_offset (distance from TIFF start to MakerNote) from the offset to find the actual data location. MakerNote-Relative method (Nikon, Olympus, Fujifilm, Samsung, Apple, Pentax) \u0026ndash; Offsets inside MakerNote are relative to the MakerNote start. Self-contained structure; Nikon even has its own TIFF header inside the MakerNote. Additionally, byte order (endianness) also differs by manufacturer. Nikon uses its own TIFF header, Olympus/Apple use \u0026quot;II\u0026quot;/\u0026quot;MM\u0026quot; bytes in the proprietary header, and Samsung auto-detects from IFD tag number patterns.\nIn the end, I implemented header format, offset correction formulas, and byte order detection logic for 10 manufacturers (Panasonic, Nikon, Sony, Canon, Olympus, Fujifilm, Samsung, Apple, Sigma, Pentax), resulting in a PR of 23 files and approximately 5,900 lines.\n4. Camera Manufacturer Logo System: CSV to build.rs to Binary Embedding # To automatically insert camera manufacturer logos into photo frames for themes like Strap and Film, two things are needed: (1) identifying the manufacturer from EXIF, and (2) rendering that manufacturer\u0026rsquo;s SVG logo.\nCompile Time: SVG Download \u0026amp; Embedding from CSV # I previously covered approaches for maximizing work at compile time with const fn/const impl and build.rs build script techniques in a Rust Embedded mass-production project. Chama Optics\u0026rsquo; logo system builds on that experience, extensively using build.rs + include_bytes!().\nassets/logo_mnf.csv defines logo information for 35 manufacturers. When cargo build runs, build.rs reads this CSV and performs the following:\nSVG Download \u0026ndash; Fetches SVGs from the url column of each row. For Wikimedia Commons URLs, it downloads via HTTP; for local paths (assets/logo_mnf/contax.svg), it reads directly. On network failure, it retries up to 3 times with 5-second intervals. MD5 Hash Verification \u0026ndash; Compares the MD5 hash of the downloaded file against the expected_md5 value in the CSV. If the file already exists and the hash matches, the re-download is skipped. If the hash doesn\u0026rsquo;t match, it panic!s to halt the build \u0026ndash; because if the SVG changed on Wikimedia\u0026rsquo;s end, it needs to be intentionally reviewed. Rust Code Generation \u0026ndash; Generates assets/auto_generated/logo_assets.rs, embedding each SVG into the binary via include_bytes!(). No file loading is needed at runtime. // Example of auto-generated code pub const LOGO_ASSETS: \u0026amp;[ArtAsset] = \u0026amp;[ ArtAsset { key: \u0026#34;canon.svg\u0026#34;, data: include_bytes!(\u0026#34;.../assets/download/canon.svg\u0026#34;), color_type: ColorType::Color, mnf: \u0026#34;canon\u0026#34;, model: \u0026#34;\u0026#34;, mnf_model_rel: MnfRelation::Any, }, // ... 35 manufacturers ]; Runtime: EXIF to Logo Matching to SVG Rasterization # When a photo is loaded, Tag::Make (manufacturer) and Tag::Model (model name) are extracted from EXIF, and the LOGO_ASSETS array is iterated for matching.\nThere are two matching rules:\nMnfRelation::Any \u0026ndash; Either the manufacturer name or model name needs to match (most cases) MnfRelation::Both \u0026ndash; Both the manufacturer name and model name must match (special cases) A real-world case where Both is needed: Sigma changed its logo in 2025. The only camera using the new logo is the SIGMA BF model, so sigma2025.svg (new logo) is registered in the CSV as mnf=\u0026quot;sigma\u0026quot;, model=\u0026quot;sigma bf\u0026quot;, mnf_model_rel=Both, while other Sigma cameras use sigma.svg (old logo) with mnf=\u0026quot;sigma\u0026quot;, mnf_model_rel=Any.\nThe matched SVG is parsed with usvg, rasterized with resvg+tiny-skia, and composited at the appropriate position and size within the frame. Rendering behavior varies based on color_type (Black/Color) and fill_ops (Default/Monochrome), allowing logo rendering that matches the background color.\n5. CJK Font Rendering and Variable Font Optimization # Numerous issues arose when rendering Japanese, Korean, and Chinese text on images:\nSome CJK ideographs failing to render Glyph widths being incorrect with variable fonts The solution was to embed SourceHanSans as a built-in fallback font, automatically substituting glyphs unsupported by the selected font. Specifically, the text is iterated character by character, and when the primary font returns GlyphId(0) (no glyph), rendering switches to the SourceHanSans fallback font.\nVariable Font Weight Remapping # The primary font used in Chama Optics, BarlowGX.ttf, is a variable font, but its internal weight axis values used a non-standard range of 22 to 188. This didn\u0026rsquo;t match the 100 to 900 range used by CSS standards, FreeType, etc., so specifying Regular weight with ab_glyph\u0026rsquo;s set_variation(b\u0026quot;wght\u0026quot;, 400.0) didn\u0026rsquo;t produce the intended result. Additionally, the default width was set to wdth=300 (Condensed), causing glyph widths to be wrong too.\nI thought simply modifying fvar (Font Variations metadata) would suffice, but the hmtx table holding actual glyph widths was still based on Condensed metrics. Changing only the metadata doesn\u0026rsquo;t change the rendering result. Ultimately, I extracted 9 weight instances from BarlowGX.ttf at wdth=500 (Regular width), used them as master sources, and completely rebuilt the variable font with fontTools.varLib.build(). The results are Barlow-Variable-Remapped.ttf and Barlow-Variable-Remapped-Narrow.ttf.\nMerging Multiple Font Files into One \u0026ndash; Absolute File Size Reduction # Another advantage of variable fonts is the ability to merge multiple weight files into one. Where previously 9 or more static font files were needed (Barlow-Thin.ttf, Barlow-Light.ttf, Barlow-Regular.ttf, Barlow-Bold.ttf, Barlow-Black.ttf, etc.), a single variable font can replace them all.\nThe same applies to CJK fonts. SourceHanSans (the ideal choice for Japanese, Korean, and Chinese characters) originally ships as separate files per weight, but using the variable font version (SourceHanSansVF) covers all weights from 200 to 800 in a single file. However, this font had the same issue as BarlowGX, so I remapped the weight axis to the standard range to produce SourceHanSansVF-remapped.otf.\nGoing further, I used fontTools to merge fonts with different character sets into one. Latin fonts + Japanese fonts + Korean fonts can be combined into a single file, and by combining WOFF2 decompression, TTC (Font Collection) processing, instance extraction at specific weights, and UTF-8-based character subsetting, the final file size was minimized.\nThe final font files embedded in Chama Optics are:\nFont Static Font Size Variable Font Size Savings Barlow-Variable-Remapped.ttf (100~900) ~1.35 MB (9 weights) 385 KB ~3.5x Barlow-Variable-Remapped-Narrow.ttf (100~900) ~1.45 MB (9 weights) 207 KB ~7x SourceHanSansVF-remapped.otf (200~800) ~105 MB (7 weights) 30 MB ~3.5x DejaVuSansMono.ttf (static) \u0026ndash; 327 KB \u0026ndash; digital-7.ttf (static) \u0026ndash; 34 KB \u0026ndash; Total ~108 MB ~31 MB ~3.5x The Barlow case is especially dramatic. The original Barlow project contains 9 weights x 3 widths x 2 (upright+italic) = 54 static TTF files totaling 8.5 MB, while the two variable fonts needed for Chama Optics (normal + narrow) total just 592 KB. In a mobile app bundle size-sensitive environment, this difference is decisive.\nVariable Font Weight Selection in egui # In the desktop version (egui), the variable font weight can be freely adjusted by the user. The key is the set_variation API from the ab_glyph crate:\npub struct VariableFontPack { pub label: \u0026amp;\u0026#39;static str, pub font: ab_glyph::FontRef\u0026lt;\u0026#39;static\u0026gt;, pub default: u16, // Default weight (e.g., 300) pub start: u16, // Minimum weight (e.g., 100) pub end_include: u16, // Maximum weight (e.g., 900) } impl VariableFontPack { pub fn get_font_by_weight(\u0026amp;self, weight: u16) -\u0026gt; ab_glyph::FontArc { let clamped = weight.clamp(self.start, self.end_include); let mut font = self.font.clone(); font.set_variation(b\u0026#34;wght\u0026#34;, clamped as f32); font.into() } } When the user adjusts the weight slider in theme settings, set_variation(b\u0026quot;wght\u0026quot;, weight) is called with that value to change the font weight at runtime. Continuous values from 100 (Thin) to 900 (Black) can be specified, and intermediate values like 350 or 450 are interpolated for smooth weight transitions.\nThis logic works identically across desktop, iOS, and Android. On iOS, FontSelectionView displays a weight slider only for variable fonts and passes the selected weight value to the Rust core via FFI. Android follows the same structure, passing the fontWeight parameter to Rust FFI from Kotlin.\nCJK fallback also respects the weight. When the primary font is Barlow weight 700 (Bold) and a CJK character appears, SourceHanSans is rendered at a weight close to 700 so that Latin and CJK character weights appear consistent.\nBuilt-in Fonts and System Fonts # Fonts used in Chama Optics fall into two categories: built-in fonts and system (OS) fonts.\nBuilt-in fonts are bundled with the app by default: Barlow (Latin), SourceHanSans (CJK fallback), D2Coding (monospace), Digital-7 (segment display style), etc. System fonts allow users to select from fonts installed on their OS for use in themes. Since users need to be able to freely choose the font for text displayed on EXIF frames, built-in fonts alone aren\u0026rsquo;t sufficient.\nOn desktop, fonts are embedded in the binary via include_bytes!:\npub(crate) const FONT_BARLOW: BuiltInFonts = BuiltInFonts { name: \u0026#34;Barlow\u0026#34;, data: include_bytes!(\u0026#34;../../assets/fonts/Barlow-Variable-Remapped.ttf\u0026#34;), }; Desktop distributes as a single executable for convenience, so font files are included in the binary at compile time. It runs immediately with just the executable, no separate font directory needed.\nOn the other hand, iOS/Android load fonts dynamically via file paths. Mobile apps are sensitive to binary size, and separating resource files within the app bundle is also platform convention. Swift/Kotlin passes the font directory path to the Rust core via FFI, and Rust reads the files at the appropriate time using std::fs::read().\nSystem fonts are supported on desktop only. font-kit crate\u0026rsquo;s SystemSource enumerates OS-installed fonts, and the user\u0026rsquo;s selected font is loaded. This work is performed on a background thread to avoid blocking the UI, shared thread-safely via Arc\u0026lt;RwLock\u0026lt;Vec\u0026lt;SystemFont\u0026gt;\u0026gt;\u0026gt;.\nDebugging font-kit macOS Memory Explosion # After implementing system font enumeration, a serious problem appeared on macOS. Memory usage shot up to 1.0GB, peaking at 1.5GB immediately after app launch. (#5)\nTracing with MallocStackLogging and malloc_history revealed the cause was in font-kit\u0026rsquo;s macOS backend (core_text). font_kit::SystemSource::all_fonts() was reading the entire file data of each font into memory while enumerating system fonts:\n435 calls for 2045941700 bytes: \u0026lt;- ~2GB font_kit::sources::core_text::create_handles_from_core_text_collection font_kit::utils::slurp_file \u0026lt;- reads entire font file into memory alloc::raw_vec::RawVecInner::try_allocate_in macOS has hundreds of system fonts installed, and CJK fonts (like Apple SD Gothic Neo, Hiragino, etc.) can be tens of MB each. slurp_file was loading all of them into memory, allocating about 2GB for 435 fonts. (On Windows, the same code used about 90MB.)\nThe fix was to fork font-kit and modify all_fonts() to collect only metadata (name, path) without reading font data. After the fix, memory usage dropped dramatically to 144.9MB (peak 389.4MB).\n6. LUT Color Grading: wagahai-lut\u0026rsquo;s Optimization Philosophy # The library name comes from a tweet by wagahaida_L (Laplus Darkness).\nLaplusDarknesss wagahaida_L pic.twitter.com/dKCBGYJobj\n\u0026mdash; „É©„Éó„É©„Çπ„Éª„ÉÄ„Éº„ÇØ„Éç„Çπüõ∏üíú (@LaplusDarknesss) July 1, 2025 https://t.co/WjplefTDWX pic.twitter.com/8L19fSqYBg\n\u0026mdash; „É©„ÉóÊßò (@wagahaida_L) November 24, 2025 As an aside, the cheki-style (Polaroid-style) automatic image generation feature being prepared for v0.2.0 was also inspired by Laplus Darkness. I think she\u0026rsquo;s cunningly clever.\nThe LUT color grading feature added in v0.1.9 uses the self-developed wagahai-lut (crates.io) library.\nWhat is a CUBE LUT? # A CUBE LUT (Look-Up Table) is a .cube file format defined by Adobe that contains color transformation data. There are two types: 1D LUT and 3D LUT.\nA 1D LUT transforms each R, G, and B channel independently. It\u0026rsquo;s a simple structure that looks up input values in a table and converts them to output values. Suitable for brightness/contrast adjustment, but cross-channel interactions (e.g., converting red to blue) are impossible. Table sizes are typically 1,024 (10-bit) to 65,536 (16-bit) entries, with values between adjacent entries calculated via linear interpolation.\nA 3D LUT maps the entire RGB 3D color space. Input (R, G, B) can be transformed to a completely different (R\u0026rsquo;, G\u0026rsquo;, B\u0026rsquo;), making it useful for creative color grading in film/photography (film look, color grading). Lattice points within the cube define known mappings, and values between lattice points are calculated via trilinear interpolation from the 8 surrounding vertices. Common sizes are 17^3 (4,913 points), 33^3 (35,937 points), and 65^3 (274,625 points).\nwagahai-lut\u0026rsquo;s Optimization Strategy # Existing Rust LUT libraries focused on generality. wagahai-lut was optimized from memory layout to SIMD level to meet Chama Optics\u0026rsquo; requirement: \u0026ldquo;batch processing dozens of 24MP photos must be fast.\u0026rdquo; However, since both x86_64 and ARM64 need to be supported, instead of writing assembly directly, I used the wide crate for architecture-agnostic vector optimizations.\n1) Structure of Arrays (SoA) Memory Layout\nTypical 3D LUT implementations use an AoS (Array of Structures) layout: [Rgb, Rgb, Rgb, ...]. But trilinear interpolation needs to read 8 vertex values one channel at a time, so in AoS, unnecessary channel data gets loaded into the cache line alongside the needed data.\nwagahai-lut stores 3D LUTs as three separate arrays: r: Vec\u0026lt;f32\u0026gt;, g: Vec\u0026lt;f32\u0026gt;, b: Vec\u0026lt;f32\u0026gt;. Thanks to this SoA layout, the 8 values needed for one channel\u0026rsquo;s interpolation are close together in memory, resulting in higher CPU cache hit rates.\n2) SIMD Parallel Processing (wide::f32x4)\nFor 1D LUT processing, wide crate\u0026rsquo;s f32x4 SIMD vectors perform linear interpolation of all three R, G, B channels in a single vector operation. Three of the four lanes are assigned to R, G, B, with multiplication and addition handled in a single instruction.\n3) Fixed-Size Specialization\n1D LUTs use Box\u0026lt;[Rgb; SIZE]\u0026gt; fixed-size arrays for common sizes: Bit10(1024), Bit12(4096), Bit14(16384), Bit16(65536). Since the size is determined at compile time, bounds checking can be bypassed with direct get_unchecked() access. 3D LUTs also provide separate types for common sizes like 17^3, 33^3, and 65^3.\n4) In-Place Processing and Loop Optimization\nThe apply_rgb_mut() / apply_rgba_mut() functions modify image buffers in-place with zero additional memory allocation. In hot loops, the domain range inverse (inv_domain_range) is pre-computed outside the loop, raw pointer arithmetic eliminates get_pixel()/put_pixel() call overhead, and byte slices are traversed linearly to maximize CPU cache prefetching.\nBenchmark Results # Processing times on M4 Max (Stable Rust), including JPEG decode/encode:\nResolution 1D LUT 3D LUT 1920x1080 (FHD) 14.39 ms 19.40 ms 6000x4000 (24MP) 159.91 ms 223.15 ms 8144x5424 (44MP) 294.34 ms 417.09 ms At about 0.22 seconds for 3D LUT processing of a 24MP photo, combined with Rayon parallelization, practical speed is achieved when batch-processing dozens of photos in Chama Optics.\n7. Desktop Face Detection: Speed Mode and Sliding Window Algorithm # The desktop version uses ONNX Runtime + InsightFace (det_10g) model. This model\u0026rsquo;s input size is a fixed 640x640 pixels. But actual photos are mostly 24MP (6000x4000) or larger, and if the entire image is scaled down to 640x640, faces in group photos where people are photographed small will be missed.\nTo solve this, a multi-stage sliding window algorithm based on Speed Mode was implemented.\nMode max_depth Depth Loop Window Size Overall Behavior Fastest 0 (none) Full image -\u0026gt; 640x640 resize -\u0026gt; single inference Fast 1 (none, depth loop not executed) + Short-side (min(W,H)) sliding window Normal 1 640x640 + 640x640 fine-grained window Slow 2 1280x1280 -\u0026gt; 640x640 + 1280-\u0026gt;640 multi-stage window Slowest 3 2560x2560 -\u0026gt; 1280x1280 -\u0026gt; 640x640 + 2560-\u0026gt;1280-\u0026gt;640 full multi-stage window Depth Loop window size formula: window = 640 x 2^(max_depth - depth - 1)\nExample: Slowest (max_depth=3) -\u0026gt; depth 0: 2560, depth 1: 1280, depth 2: 640\nThe algorithm flow is as follows:\nStage 1 (common): Resize the full image to 640x640 for a single inference. Large faces are caught at this stage. Stage 2 (Fast and above): Move a sliding window of size equal to the image\u0026rsquo;s short side (min(width, height)) with 10% overlap, resizing each window to 640x640 for inference. Prevents misses in unusual aspect ratios (panoramas, etc.). Stage 3 (Normal and above): Iterate through windows of size 640 x 2^(max_depth - depth - 1) per depth. Slowest uses 2560-\u0026gt;1280-\u0026gt;640, Slow uses 1280-\u0026gt;640, Normal uses a single 640 depth. Final: Remove duplicate detections with NMS (Non-Maximum Suppression, IoU threshold 0.4). Diagrams visualizing each Speed Mode\u0026rsquo;s behavior (based on a 6000x4000 source image):\nFastest # Fast # Normal # Slow # Slowest # Below is an example of an actual event photo processed in Slowest mode. Even small faces in the back corners of large group photos are detected without exception and mosaic-processed.\n2025 AGF Amane Kanata fan group photo session\nUsage scenarios for each mode:\nMode Average Processing Time Suitable Situation Fastest ~0.5 sec 1-2 person portraits Fast ~0.6 sec 1-2 person photos with unusual aspect ratios like panoramas Normal ~7 sec Group photos of about 10 people Slow ~13 sec Group photos of 40-50 people Slowest ~28 sec Large group photos of 50+ people Fastest scales the entire image to a single 640x640 and finishes in ~0.5 seconds, while Slowest takes ~28 seconds as it scans with overlapping windows at three stages (2560/1280/640). But capturing even small faces in the back corners of event group photos requires this level of scanning.\nExecution providers are also optimized per platform:\nmacOS/iOS: CoreML Execution Provider auto-selected \u0026ndash; leveraging Apple\u0026rsquo;s Neural Engine/GPU acceleration Windows/Linux: CPU or OnnxAuto (auto-detection) On macOS, even if the user selects CPU, it\u0026rsquo;s internally switched to CoreML to leverage Apple Silicon\u0026rsquo;s Neural Engine. This provides several times the performance improvement over CPU.\nMeanwhile, iOS and Android use each platform\u0026rsquo;s native face detection API instead of this ONNX pipeline:\niOS: Apple Vision Framework \u0026ndash; fast and accurate without ONNX models Android: Google ML Kit (com.google.mlkit:face-detection) \u0026ndash; FAST/ACCURATE performance modes mapped to Rust core\u0026rsquo;s speed_mode (Fastest/Fast -\u0026gt; FAST performance, Slow and above -\u0026gt; ACCURATE performance) 8. iOS Native Integration # The iOS app doesn\u0026rsquo;t merely wrap the Rust core \u0026ndash; it maximizes the platform\u0026rsquo;s strengths:\nVision Framework \u0026ndash; Native iOS face detection for fast and accurate recognition without ONNX models PhotosUI \u0026ndash; Direct image selection from the iOS photo library Metal rendering \u0026ndash; GPU-accelerated image processing iPad support \u0026ndash; Layout optimized for the larger screen 9. MPF and Embedded Preview Image Extraction # Extracting sub-images hidden inside JPEG files plays a decisive role in Chama Optics\u0026rsquo; performance. This feature was implemented as exif-rs PR #58 (+1,364 lines, based on PR #57).\nImages Hidden Inside a JPEG # A single JPEG file can actually contain multiple images.\nImages embedded inside a JPEG can be extracted from three sources:\nEXIF IFD(1) Thumbnail \u0026ndash; Standard EXIF thumbnail (usually 160x120) APP2 Segment (MPF) \u0026ndash; Multi-Picture Format defined in the CIPA DC-007 standard. Stored as separate complete JPEG streams after the main EOI. MakerNote Internal Preview \u0026ndash; Vendor-specific non-standard preview images Why MPF Previews Matter: Memory and Performance # When showing thumbnails in a photo list, the simplest approach is to load the original image and then resize it. But this is horribly inefficient.\nMethod Memory Usage Processing Time Load original (24MP) -\u0026gt; resize ~72MB (24M x 3bytes) Slow Use IFD(1) thumbnail ~76KB (160x120) Fast, but too small and blurry Use MPF preview (~2MP) ~8MB Fast, and visually sufficient IFD(1) thumbnails are too small \u0026ndash; fine for list views but blurry for previews. Loading originals means a 24MP image occupies ~72MB in memory with long decoding times. MPF\u0026rsquo;s 1-2MP preview images are the sweet spot \u0026ndash; visually sharp enough while keeping memory and CPU overhead at less than 1/10 of the original.\nEspecially for a program like Chama Optics that needs to show dozens of photos simultaneously in a list with theme previews, this difference is decisive. Loading 50 24MP photos as originals would take ~3.6GB; loading MPF previews takes ~400MB \u0026ndash; roughly a 9x difference.\nTo avoid impacting existing exif-rs users, this was provided behind the mpf feature flag.\n10. HEIF/HEIC Decoder: Per-Platform Strategy # Beyond JPEG, more devices are saving photos in HEIF (High Efficiency Image Format). iOS in particular uses HEIF by default when shooting, and the OS itself decides whether to convert to JPEG or keep HEIF when transferring photos externally \u0026ndash; it\u0026rsquo;s not easy for apps to control this. Some mirrorless cameras (Sony, Canon, etc.) have also started supporting HEIF shooting. While some users stick to JPEG for compatibility, failing to handle HEIF files is fatal for a photo app. The problem is that HEIF decoding support varies widely across platforms.\nChama Optics adopted the strategy of using OS native decoders wherever possible, and only using libheif on platforms without native support.\niOS/macOS \u0026ndash; Apple\u0026rsquo;s ImageIO framework natively supports HEIF. Decoding is possible using only the OS API without external libraries. On iOS, the decoded pixel buffer is passed from the Swift app layer to Rust via C FFI; on macOS, Rust calls macOS API bindings directly.\nAndroid \u0026ndash; API 26 (Android 8.0) and above natively support HEIF via BitmapFactory and MediaCodec. The Kotlin app decodes and passes the result to Rust via JNA.\nWindows/Linux \u0026ndash; No native HEIF decoder, or it\u0026rsquo;s limited. In this case, libheif_rs (Rust bindings for libheif) is used. Since libheif_rs handles C FFI internally, Rust code only calls safe APIs. libheif internally uses libde265 (HEVC decoder) and libaom (AV1/AVIF).\nThe key to this strategy is #[cfg(target_os)] conditional compilation. Platforms with native decoders get optimal performance with no external dependencies, and libheif_rs is linked only on platforms that need it. As a result, libheif-related code isn\u0026rsquo;t even compiled in macOS builds.\n11. Theme Parameter System: Rust to JSON to Platform-Specific UI # Chama Optics themes have over 40 configuration parameters \u0026ndash; font weight, watermark position/opacity, frame style, logo visibility, colors, margins, and more. The core requirement was that these parameters must produce identical results on desktop and mobile.\nOn desktop (egui), Rust structs are directly referenced to draw UI widgets. Code like Slider::new(\u0026amp;mut config.font_weight, 100..=900) means the struct field is the UI state \u0026ndash; no JSON serialization, no intermediate conversion.\nThe problem is mobile. iOS (SwiftUI) and Android (Jetpack Compose) can\u0026rsquo;t directly access Rust structs. If we manually built UI for each of the 40+ parameters on the Swift/Kotlin side and wrote FFI code to pass values back and forth for each one? Every time a parameter is added, Rust, Swift, and Kotlin would all need simultaneous modifications.\nI solved this with proc_macro. When #[derive(ThemeParam)] is added to a Rust struct definition, the following is auto-generated at compile time:\nJSON schema: JSON containing each field\u0026rsquo;s UI type (slider, toggle, enum selector, color picker, etc.), range, and default values FFI functions: C ABI functions callable from mobile, such as get_param_json(), set_param() Deserialization logic: Code that applies JSON-received values to the Rust struct The mobile app parses this JSON to dynamically generate native UI elements. \u0026quot;type\u0026quot;: \u0026quot;slider\u0026quot; becomes SwiftUI\u0026rsquo;s Slider, Jetpack Compose\u0026rsquo;s Slider(). \u0026quot;type\u0026quot;: \u0026quot;toggle\u0026quot; becomes Toggle / Switch. When the user changes a value, it\u0026rsquo;s passed to the Rust core via FFI, and the Rust core returns results through the same rendering pipeline.\nAs a result, a single Rust struct simultaneously serves as UI specification, data model, and serialization format. When adding a new parameter, just add a field to Rust and annotate it with UI hints \u0026ndash; the proc_macro updates the JSON schema, and the mobile app automatically displays the corresponding UI on the next build. No Swift/Kotlin code modifications needed.\nThe build.rs overuse and const fn obsession from embedded development found its application here. Honestly, I\u0026rsquo;m not sure if using proc_macro for this is clean \u0026ndash; even I think it\u0026rsquo;s \u0026ldquo;grotesque.\u0026rdquo; But it\u0026rsquo;s definitely better than manually synchronizing 40+ parameters across 3 platforms. For those wanting to learn more about Rust\u0026rsquo;s procedural macros, this article is a good reference.\n12. Multilingual Translation System: Auto-Generating Translations for 3 Platforms from a Single YAML # Supporting 4 languages (English, Korean, Japanese, Indonesian) while keeping translation strings synchronized across 3 platforms. If you had to manually edit iOS\u0026rsquo;s .strings, Android\u0026rsquo;s strings.xml, and the desktop\u0026rsquo;s Rust code every time you add or modify a translation key? You\u0026rsquo;d inevitably miss something or fall out of sync.\nThe solution is simple. Use YAML files in rust-core as the single source of truth, and automatically convert them to each platform\u0026rsquo;s format at build time.\nYAML: The Source of Truth # There are 23 YAML files in the rust-core/locales/ directory. They\u0026rsquo;re split by feature \u0026ndash; common.yml, gallery.yml, theme.yml, face_detection.yml, etc. \u0026ndash; totaling approximately 3,900 lines.\n# rust-core/locales/gallery.yml gallery: empty_state_title: en: \u0026#34;No Images Yet\u0026#34; ko: \u0026#34;Ïù¥ÎØ∏ÏßÄ ÏóÜÏùå\u0026#34; ja: \u0026#34;ÁîªÂÉè„Åå„ÅÇ„Çä„Åæ„Åõ„Çì\u0026#34; id: \u0026#34;Belum Ada Gambar\u0026#34; This structure matches the format required by the rust_i18n crate exactly. On desktop, rust_i18n::i18n!(\u0026quot;locales\u0026quot;) embeds the YAML at compile time, and t!(\u0026quot;gallery.empty_state_title\u0026quot;) is called at runtime. No separate conversion needed. Since cargo:rerun-if-changed=locales is declared in build.rs, modifying YAML triggers automatic recompilation.\nThe problem is iOS and Android.\niOS: generate_ios_strings.sh # iOS uses NSLocalizedString and .strings files. generate_ios_strings.sh parses YAML using Python3 + PyYAML and generates per-locale Localizable.strings.\n# Automatically called from build_ios.sh ./generate_ios_strings.sh It flattens the YAML hierarchy into dot notation for the .strings format.\n/* Auto-generated from rust-core/locales - DO NOT EDIT */ \u0026#34;gallery.empty_state_title\u0026#34; = \u0026#34;Ïù¥ÎØ∏ÏßÄ ÏóÜÏùå\u0026#34;; \u0026#34;common.actions.save\u0026#34; = \u0026#34;Ï†ÄÏû•\u0026#34;; There were also iOS-specific requirements. Sometimes the same key needs different phrasing on iOS \u0026ndash; for example, where desktop says \u0026ldquo;Load file,\u0026rdquo; iOS should say \u0026ldquo;Select photo\u0026rdquo; for a more natural feel. To handle this, I implemented _ios suffix overrides. If import.label_ios is defined in YAML, the iOS build uses that value instead of import.label. Desktop and Android are unaffected.\nThis script is automatically called from build_ios.sh before Rust cross-compilation, so editing YAML and running an Xcode build automatically reflects the translations.\nAndroid: generate_android_strings.sh # Android uses strings.xml and the R.string.* resource system. There are two key differences.\nFirst, the key format is different. Android resource names cannot use dots (.). YAML\u0026rsquo;s gallery.empty_state_title must be converted to gallery_empty_state_title for Android.\ndef yml_key_to_android_key(yml_key): return yml_key.replace(\u0026#39;.\u0026#39;, \u0026#39;_\u0026#39;) Second, the locale directory conventions differ. Android represents Indonesian as in instead of id \u0026ndash; values-in/strings.xml. The script handles this mapping.\nANDROID_LOCALE_MAP[\u0026#34;en\u0026#34;]=\u0026#34;values\u0026#34; ANDROID_LOCALE_MAP[\u0026#34;ko\u0026#34;]=\u0026#34;values-ko\u0026#34; ANDROID_LOCALE_MAP[\u0026#34;ja\u0026#34;]=\u0026#34;values-ja\u0026#34; ANDROID_LOCALE_MAP[\u0026#34;id\u0026#34;]=\u0026#34;values-in\u0026#34; # Android uses \u0026#34;in\u0026#34; for Indonesian Another difference from the iOS script is that it uses diff-based synchronization. While iOS overwrites files entirely each time, the Android script leaves already-existing keys untouched and only adds missing keys. This preserves entries managed manually on the Android side (like app names). Running with --check mode reports missing translations without modifying files.\nWhen actually using these keys in Android, ThemeI18n.kt maps YAML dot-notation keys to R.string.* resource IDs.\nobject ThemeI18n { fun translate(context: Context, key: String): String { val resourceId = keyToResourceId(key) return if (resourceId != 0) context.getString(resourceId) else key } } Key Conversion Comparison Across Three Platforms # Element Desktop (Rust) iOS (Swift) Android (Kotlin) Source t!(\u0026quot;gallery.empty_state_title\u0026quot;) NSLocalizedString(\u0026quot;gallery.empty_state_title\u0026quot;) R.string.gallery_empty_state_title Key separator . (dot) . (dot) _ (underscore) Generation method Compile-time embedding Build script auto-generation Build script diff sync Platform override ‚Äî _ios suffix ‚Äî Indonesian code id id in Thanks to this structure, editing a single YAML file reflects changes across all three platforms. Manually synchronizing 23 YAML files, 4 languages, and 3 platforms is practically impossible \u0026ndash; automation was the only approach I could think of.\nOpen-Source Contributions # Throughout the development of Chama Optics, I actively contributed to the open-source projects it depends on.\nProject Contribution exif-rs MakerNote parsing \u0026ndash; 10 manufacturer support (PR #57, +5,946 lines) exif-rs MPF and embedded preview image extraction (PR #58, +1,364 lines) exif-rs TIFF field access improvements (PR #51, approved) font-kit Fix macOS system font enumeration memory explosion (PR #271) egui Improve main weight setting on variable font load (PR #7790, approved) wagahai-lut 1D/3D LUT color grading library (crates.io) Release Summary # Version Date Major Changes v0.1.0 2025-10-19 First pre-release, macOS/Windows, Film theme v0.1.1 2025-10-19 Japanese translation, batch save, prefix/suffix v0.1.2 2025-10-27 Glow effect, Film Date/Glow themes v0.1.3 2025-11-03 Watermark (9 positions), font selection v0.1.4~5 2025-11-05~12 Just Frame, Strap themes, camera logos v0.1.6 2025-11-24 Monitor, Lightroom themes, Longside scale v0.1.7 2025-12-19 One/Two Line, Shot On themes, CJK fix, PhotoStyle v0.1.8 2025-12-27 Tab UI, grouping, theme preview, multi-core v0.1.9 2026-02-04 Face detection, LUT color grading, iOS TestFlight first release Programming with AI (Vibe Coding?) # I was initially skeptical about AI coding.\nThat\u0026rsquo;s why the majority of the desktop version still relies on my hand-written code + cargo fmt/clippy/check. AI (Claude) still doesn\u0026rsquo;t properly understand my intention to overuse const on desktop \u0026ndash; a habit from Rust Embedded.\nBut while developing for mobile, I thought doing all of this alone would be insane. The priority was to deliver the same results as the existing desktop version on mobile, and I expected there would be a lot of calling native APIs and Rust FFI directly.\nAround that time, while going to a friend\u0026rsquo;s wedding invitation gathering, a friend riding in the car with me said, \u0026ldquo;Liquid UI in Flutter isn\u0026rsquo;t working properly on iOS 26 right now.\u0026rdquo; That cemented my decision to only develop natively, and simultaneously I decided to let AI handle the mobile code.\nThe result was a division of labor: I wrote the Rust core myself, while the mobile UI (SwiftUI/Jetpack Compose) and FFI bridges were written together with AI. On the Rust side, I have specific patterns and styles that AI can\u0026rsquo;t match well, but for writing platform-native code in languages I don\u0026rsquo;t know well, like Swift/Kotlin, AI was a huge help.\nAfter this experience, I started thinking about the position of cross-platform frameworks like Flutter. Of course, the problem that Flutter and React Native solve \u0026ndash; covering multiple platforms with a single codebase \u0026ndash; is still valid. But as AI becomes capable enough to write native code for each platform, the motivation of \u0026ldquo;choosing cross-platform because you don\u0026rsquo;t know native\u0026rdquo; may gradually weaken. The fact that someone like me, who knew nothing about mobile development, could write SwiftUI and Jetpack Compose natively with AI assistance alone might be one case showing that possibility.\nFuture Plans # Starting from v0.1.9, desktop-only releases are over, and from v0.2.0 onward, releases will include iOS and Android mobile apps. Rather than adding more features, I plan to focus on occasional stabilization and theme additions.\nThe immediate goal is real-world deployment at the Hololive Expo/Festival in March 2026. Taking photos with a mirrorless camera at the venue, applying frames directly on iPhone, automatically mosaicing faces, and posting to social media \u0026ndash; providing a workflow where camera users and general smartphone users alike can comfortably use the app in their own environment.\nAs a side project, Chama Optics aims to be \u0026ldquo;a tool that helps photographers better showcase their photos,\u0026rdquo; providing an ever more convenient workflow. And based on the procedural macro and optimization experience built up during this development, I also plan to put more effort back into Rust Embedded.\nReferences and Citations # Standards Documents # CIPA DC-008 \u0026ndash; Exchangeable image file format (Exif) Version 3.0 CIPA DC-007 \u0026ndash; Multi-Picture Format (MPF) Adobe ‚Äî Adobe Cube LUT Spec 1.0 Libraries and Frameworks # exif-rs \u0026ndash; Rust EXIF parsing library egui \u0026ndash; Rust immediate mode GUI framework font-kit \u0026ndash; Cross-platform font loading library wagahai-lut (crates.io) \u0026ndash; 1D/3D LUT color grading library libheif-rs \u0026ndash; libheif Rust bindings wide \u0026ndash; Cross-platform SIMD vector crate ONNX Runtime \u0026ndash; Cross-platform ML inference engine InsightFace SCRFD \u0026ndash; Face detection model (det_10g) exif-frame \u0026ndash; EXIF frame web tool (initial reference for Chama Optics) Reference Materials # Rust Procedural Macros \u0026ndash; Procedural macro reference ExifTool TagNames \u0026ndash; Manufacturer-specific MakerNote tag reference Exiv2 MakerNote Documentation \u0026ndash; MakerNote structure and manufacturer-specific format reference Special Thanks # SkuldNorniern \u0026ndash; Debugging and face detection assistance miniex \u0026ndash; Font system debugging and face detection assistance jcm7612 \u0026ndash; Debugging and feedback shiemika324 \u0026ndash; Illustration and icon illustration ","date":"14 February 2026","externalUrl":null,"permalink":"/en/posts/chama-optics-dev-story/","section":"Posts","summary":"EXIF-based photo frame + automatic face detection app, from desktop to mobile with a Rust core\nThis is probably the first time I‚Äôve openly written an otaku-ish post on this blog. Honestly, I started writing this quite a while ago, but I couldn‚Äôt figure out whether to target the audience as developers or VTuber otaku. In the end, I decided to just go with the flow and list everything I developed and contributed.\n","title":"Chama Optics Development Story","type":"posts"},{"content":"","date":"14 February 2026","externalUrl":null,"permalink":"/en/tags/cross-platform/","section":"Tags","summary":"","title":"Cross-Platform","type":"tags"},{"content":"","date":"14 February 2026","externalUrl":null,"permalink":"/en/tags/exif/","section":"Tags","summary":"","title":"EXIF","type":"tags"},{"content":"","date":"14 February 2026","externalUrl":null,"permalink":"/en/tags/ios/","section":"Tags","summary":"","title":"IOS","type":"tags"},{"content":"","date":"14 February 2026","externalUrl":null,"permalink":"/en/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"Rust\n","date":"14 February 2026","externalUrl":null,"permalink":"/en/tags/rust/","section":"Tags","summary":"Rust\n","title":"Rust","type":"tags"},{"content":"\nMore details for rust tags : Rust tag\n","date":"14 February 2026","externalUrl":null,"permalink":"/en/tags/","section":"Tags","summary":"\nMore details for rust tags : Rust tag\n","title":"Tags","type":"tags"},{"content":" WARN! This article is still a work in progress. Content may change at any time. Before Reading # This post is a continuation of the previous post Part 3: Leave It to Compile Time, but focuses on build.rs rather than const fn/trait/impl.\nIf you are not familiar enough with Rust syntax, I recommend reading the #Studying-Rust section in the previous post Part 2: Study Methods and Key Characteristics. I also recommend the excellent article by Ki-O Kim, A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust.\nBuild Scripts (build.rs) # Just as C and C++ have Makefiles, Rust has Cargo. Cargo provides build.rs, which allows you to easily write scripts that run before compilation begins.\nFor detailed documentation on build.rs, see: The Cargo Book - Build Scripts\nbuild.rs runs before compiling the source code in the src directory or external libraries. Importantly, even if you are developing code for no_std, build.rs can use libraries available on the host OS, including no_std and the alloc crate.\nA separate program in main.rs must create const data at compile time, but there are cases where the functions and methods you need are not available in const form.\nFetching Strings with build.rs and env!() # Let us practice fetching a string (\u0026amp;str) at compile time using build.rs and the env!() macro.\nThe project structure looks like this. build.rs is not in the src directory; it goes in the root directory of the project.\nCargo.toml Example # # End of Cargo.toml [build-dependencies] chrono = \u0026#34;0.4.31\u0026#34; As mentioned above, build.rs can use libraries available for OS targets. If there is a crate you want to use, add it under build-dependencies below dependencies. Here we have added the chrono crate for our example.\nbuild.rs Example # // build.rs fn main() { let now = chrono::Utc::now().to_rfc3339(); println!(\u0026#34;cargo:rustc-env=GIVEN_BUILD_TIME={}\u0026#34;, now); } When Cargo compiles and runs build.rs, it uses the chrono library to get the current time in UTC and converts it to a String.\nThen it passes it to rustc (the compiler) as the \u0026ldquo;GIVEN_BUILD_TIME\u0026rdquo; environment variable via println!.\nsrc/main.rs Example # // src/main.rs const BUILD_TIME: \u0026amp;str = env!(\u0026#34;GIVEN_BUILD_TIME\u0026#34;); fn main() { // if you working with firmware environment, // use defmt::info!(..) instead of println!(..) println!(\u0026#34;passed build time is {}\u0026#34;, BUILD_TIME); // \u0026#34;passed build time is 2023-11-14T06:14:02.366899222+00:00\u0026#34; } In src/main.rs, the \u0026ldquo;GIVEN_BUILD_TIME\u0026rdquo; environment variable is retrieved as a const \u0026amp;str using the built-in env!(..) macro.\nThe exact module path of env!(..) is core::env!(..), and core::env!(..) fetches environment variables at compile time. If you are developing for an OS target and want to get runtime environment variables or execution arguments rather than compile-time ones, you should use the items in the std::env module. Since you may end up using both when working with build.rs, be careful not to confuse them.\nFor detailed documentation on the env!() macro, see: https://doc.rust-lang.org/core/macro.env.html\nCreating Fixed-Length Binary Data # Fetching with include_bytes # core::include_bytes can load a file from the project directory as binary data at compile time. https://doc.rust-lang.org/core/macro.include_bytes.html\nCreating a Dummy Binary # echo -n \u0026#34;\\x00\\x01\\x02\\x03\u0026#34; \u0026gt;\u0026gt; ./src/stuff0123.bin Create a dummy binary for our exercise. It is [0x00, 0x01, 0x02, 0x03], totaling 4 bytes, and is placed in the same location as main.rs.\nIn this post we create the dummy binary from the terminal, but it can also be done from build.rs.\nsrc/main.rs Example # const DATA0123: \u0026amp;[u8; 4] = include_bytes!(\u0026#34;stuff0123.bin\u0026#34;); fn main() { println!(\u0026#34;binary data is {:?}\u0026#34;, DATA0123); } In src/main.rs, the binary created earlier is fetched at compile time as const \u0026amp;[u8; 4]. Note that unlike fetching a \u0026amp;str above, you must specify the number of elements like [u8; N].\nTo fetch data without worrying about the number of elements, you need to use macros. This is covered later in this post.\nFetching Variable-Length Binary Data # build.rs src/**.rs String const \u0026amp;str Vec\u0026lt;u8\u0026gt; const [u8; N] In build.rs, data has variable-length characteristics, but when compiling for the target inside src/**.rs, you need the help of proc_macro. However, if the data size changes variably with each compilation and is not strictly controlled, it can be dangerous, so keep this in mind when using it.\nFetching Variable-Length Binary Data with proc-macro # There is also an approach of saving data to a tmp file and using include_bytes! with proc_macro, but the method introduced here uses env! together with proc_macro.\nTo explain proc_macro: in the past with C, you would use ## to concatenate tokens to generate code, or use compiler-specific features for black magic. Proc_macro brings in the concepts of tokens and parsers to enable reasonably stable metaprogramming through a macro system.\nIn Korean it is called procedural macros (jeolchahyeong maekeullo). If you master proc_macro and procedural macros, you can achieve excellent metaprogramming. I will write about this in more detail in a future post.\nFor the official detailed explanation of proc_macro, see: Procedural Macros\nOverall Flow # stateDiagram-v2 state \"Total flow\" as total_flow state \"data prepare\" as data_prepare state \"hex::encode(..)\" as hex_encode state \"hex encoded\" as hex_encoded state \"passing to env\" as passing_to state \"passing from env\" as passing_from state \"proc_macro\" as proc_macro state \"decoding at build time\" as decoding state \"decoded data\" as decoded_data state \"code generation\" as code_generation state \"src/**.rs\" as src_rs state \"const NAME: [u8; N] = [...]\" as const_u8_n state total_flow { [*] --\u003e build.rs state build.rs { [*] --\u003e data_prepare data_prepare --\u003e hex_encode hex_encode --\u003e hex_encoded hex_encoded --\u003e passing_to } -- state src_rs { passing_from --\u003e proc_macro state proc_macro { [*] --\u003e decoding decoding --\u003e decoded_data decoded_data --\u003e code_generation } proc_macro --\u003e const_u8_n } } The overall flow is as follows:\nPrepare the data to inject in build.rs. Encode it as hex and pass it as an environment variable to rustc. In src/**.rs, receive the environment variable and pass it to a function created with proc_macro. The macro function decodes the data at compile time and turns it into an array of the original data. Generate const data as a code declaration with the specified name and the array length. proc_macro Code for Decoding at Compile Time # To perform steps 4 and 5 described above, the following code is needed:\nfn slice_to_auto_sized ( arr_name: String, input: \u0026amp;[u8], ) -\u0026gt; TokenStream { format!( \u0026#34;const {}: [u8; {}] = [{}];\u0026#34;, arr_name, input.len(), input.iter().join(\u0026#34;, \u0026#34;) ) .parse::\u0026lt;proc_macro2::TokenStream\u0026gt;() .expect(\u0026#34;Failed to parse array\u0026#34;) .into() } struct NameAndEnvInput { arr_name: syn::LitStr, _comma0: Token![,], env_var: syn::LitStr, } impl Parse for NameAndEnvInput { fn parse(input: syn::parse::ParseStream) -\u0026gt; syn::Result\u0026lt;Self\u0026gt; { Ok(Self { arr_name: input.parse()?, _comma0: input.parse()?, env_var: input.parse()?, }) } } #[proc_macro] pub fn c(inputs: TokenStream) -\u0026gt; TokenStream { let inputs = parse_macro_input!(inputs as NameAndEnvInput); slice_to_auto_sized( inputs.link_section_name.value(), inputs.arr_name.value(), hex::decode(std::env::var(inputs.env_var.value()).expect(\u0026#34;This env not found\u0026#34;)) .expect(\u0026#34;Can\u0026#39;t decode hex\u0026#34;) .as_slice(), ) } As an example, assume that slice_to_auto_sized!(SOME_DATA, GIVEN_ENV); is declared in main.rs.\nIn const_from_hex_env, it takes three tokens matching the structure of the NameAndEnvInput struct: \u0026ldquo;SOME_DATA\u0026rdquo;, a comma (,), and \u0026ldquo;GIVEN_ENV\u0026rdquo;. These tokens are passed to slice_to_auto_sized at the top, which generates the code to be produced.\nThe above code can be found in the forked env-to-array commit. The code there has been modified to create dummy sections for the linker, so it is slightly different. This code is a slightly modified fork of the env-to-array crate. Data Generation Example for Hex Encoding # fn main { // https://github.com/pmnxis/billmock-mptool/blob/master/otp-proof-of-concept/build.rs // (abbreviated) let fingerprint = MpFingerprint { firmware_fingerprint: FirmwareFingerprint { model_name: main_package.name.clone(), // reference package name temporary model_ver: feature_based_model_ver, firmware_ver: main_package.version.to_string(), firmware_git_hash: format!(\u0026#34;{}\u0026#34;, commit_hash), }, }; // cargo objdump --release -- -s --section .mp_fingerprint println!( \u0026#34;cargo:rustc-env=MP_FINGERPRINT_TOML_HEX={}\u0026#34;, fingerprint.to_hex_string(), ); } When encoding in hex style, you can use hex and encode with hex::encode().\nThe code above creates package information and a git hash in TOML format, then hex-encodes it.\nPractical Applications # Application - Fetching EUC-KR Strings at Compile Time # use encoding_rs::EUC_KR; fn main() { // encoding_rs::Encoding::encode(..) is not const fn let ret: \u0026amp;[u8] = EUC_KR.encode(\u0026#34;ÏïàÎÖïÌïòÏÑ∏Ïöî\u0026#34;).0.to_vec().as_slice(); } While developing billmock-app-rs, I encountered several problems when creating an NDA financial institution protocol communication library. I needed to hold EUC-KR strings as const. However, the EUC-KR string encoding library encoding-rs does not provide const functions.\nSince EUC-KR is ultimately a character encoding, under the assumption that the strings are predetermined, it is binary data that can be generated at compile time.\nBy combining the techniques introduced above, I wrote code in the financial institution protocol communication library that converts EUC-KR strings to const [u8; N] at compile time.\nApplication - Dummy ELF Header # During firmware development, when creating an MP Tool (Mass Production Tool) for flashing firmware in bulk, I inserted a dummy header into the ELF to prevent mistakes and record hardware version information. Since this dummy ELF header is data that is not actually loaded into flash, using variable-length data was no problem at all.\nThe overall structure is similar to what was described above in \u0026ldquo;Fetching Variable-Length Binary Data with proc-macro\u0026rdquo;.\nRelated commits are as follows:\nhttps://github.com/pmnxis/billmock-app-rs/pull/42/files https://github.com/pmnxis/env-to-array/commit/782c2b265d8a23653321d163ac5cea96c04bc85d Wrapping Up # This post is a continuation of the previous post Part 3: Leave It to Compile Time, but focused on build.rs rather than const fn/trait/impl. I covered how to handle fixed-length and variable-length data through build.rs and listed practical usage examples.\nThe topic of proc_macro (procedural macros) was too lengthy to explain in the middle of this post, so I plan to cover it in a future article.\n","date":"13 November 2023","externalUrl":null,"permalink":"/en/posts/my_first_commerical_rust_embedded_product_4/","section":"Posts","summary":" WARN! This article is still a work in progress. Content may change at any time. ","title":"Developing a Mass-Produced Rust Embedded Product - 4 Leveraging Build Scripts","type":"posts"},{"content":"","date":"13 November 2023","externalUrl":null,"permalink":"/en/tags/embedded/","section":"Tags","summary":"","title":"Embedded","type":"tags"},{"content":"","date":"13 November 2023","externalUrl":null,"permalink":"/en/tags/korean_article/","section":"Tags","summary":"","title":"Korean_Article","type":"tags"},{"content":"","date":"13 November 2023","externalUrl":null,"permalink":"/en/categories/my-frist-mass-production-with-rust-embedded/","section":"Categories","summary":"","title":"My Frist Mass Production With Rust Embedded","type":"categories"},{"content":"","date":"13 November 2023","externalUrl":null,"permalink":"/en/tags/%ED%9A%8C%EA%B3%A0%EB%A1%9D/","section":"Tags","summary":"","title":"ÌöåÍ≥†Î°ù","type":"tags"},{"content":" WARN! This article is still a work in progress. Content may change at any time. Introduction # Before reading this post, if you are not familiar enough with Rust syntax, I recommend reading the #Studying-Rust section in the previous post Part 2: Study Methods and Key Characteristics. I also recommend the excellent article by Ki-O Kim, A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust.\nLeave It to Compile Time # A typical function will use a constant (immutable value) directly if the result can be predicted at compile time.\nHowever, if storing the value as a constant is deemed inefficient, it remains as a function in the instruction stream.\nIn embedded systems, especially firmware running on low-cost MCUs, RAM is very limited. (The MCU I used, STM32G030C8, has only 8KiB.)\nTo leave complex computations as constant-like data at compile time and load them into the Flash region (.text or .rodata), I occasionally departed from typical Rust programming practices and wrote code with this in mind.\nconst fn # Unlike a regular fn, a const fn guarantees that constant-like data is obtained at compile time.\nconst fn const_add(a: i32, b: i32) -\u0026gt; i32 { a + b } const fn const_add_round_up(a: i32, b: i32) -\u0026gt; i32 { let added = const_add(a, b); // Functions inside must also be const (added / 10) * 10 } However, there are many constraints. Functions within a const fn scope must also be const fn, and other operations must also be computable at compile time.\nConversely, a const fn can be used inside a regular fn or async fn scope.\nconst impl # Making a regular function const is straightforward, but the moment you turn it into a method for a struct, you run into difficult problems. This topic will be covered in the const trait section below.\nFor now, let us look at the simplest case: defining a default for a specific struct.\npub enum Player { Undefined = 0, Player1 = 1, Player2 = 2, } impl Player { pub const fn default() -\u0026gt; Self { Self::Undefined } } The code ends up being very simple, but by doing this, the caller of default() can obtain a constant at compile time. For more complex cases, you can supply more complex values. As mentioned above, as long as the arguments are not dynamic, the function will not remain in function form, so you are guaranteed to skip branching, stack back-and-forth, and the process of backing up and restoring registers.\nconst trait # Now we arrive at the much-anticipated const trait, which at the time of writing (November 2023) is a nightly feature. From here, I will also describe why const fn / impl / trait is still an RFC under discussion in Rust.\nConflicts with Existing Traits # Did you notice anything odd about the pub const fn default() mentioned above?\nThe issue is that a Default trait already exists separately.\nHowever, the definition of the Default trait is not in const form.\nIt is obvious that the core::default::Default trait impl for many structs is trivially simple. But no matter how simple it looks by eye, in this case it cannot be used inside a const fn.\nThe Case of Into/From # So far there has been little need to abstract through the Default trait using const, but surprisingly, Into/From turned out to be the real problem.\nFor now, by modifying the trait definition of core::default::From into ConstInto and ConstFrom compatible with const traits, you can use them as follows:\nConstConvert definition used in the product Example of using const-style Into/From\npub struct UnpackedQuad4Bits { pub b0: u8, pub b1: u8, pub b2: u8, pub b3: u8, } #[derive(PartialEq)] pub struct PackedQuad4Bits { inner: u16, } impl const ConstFrom\u0026lt;UnpackedQuad4Bits\u0026gt; for PackedQuad4Bits { fn const_from(value: UnpackedQuad4Bits) -\u0026gt; Self { PackedQuad4Bits { inner: ((value.b0 as u16 \u0026amp; 0xF) \u0026lt;\u0026lt; 12) | ((value.b1 as u16 \u0026amp; 0xF) \u0026lt;\u0026lt; 8) | ((value.b2 as u16 \u0026amp; 0xF) \u0026lt;\u0026lt; 4) | (value.b3 as u16 \u0026amp; 0xF), } } } #[test] fn test() { assert_eq!( PackedQuad4Bits::const_from(UnpackedQuad4Bits { b0: 0x0, b1: 0x1, b2: 0x2, b3: 0x3 }), PackedQuad4Bits { inner: 0x0123 } ); } When you create ConstInto / ConstFrom in const form, you cannot use them directly via .into() as with regular Into/From. You need to call the preceding const method again from the Into/From trait definition, but you can define the into conversion at compile time.\nconst trait as a Nightly Feature # const trait is still a nightly feature. In my personal experience, I had to change feature flags every time I slightly updated the nightly compiler version. Nevertheless, it is a very necessary feature in certain cases. (Of course, you can get by using only const fn without it.)\nWhen defining a const trait, you need to add #[const_trait] before the trait definition and declare #![feature(const_trait_impl)] in lib.rs or main.rs.\ntodo! Write about the history of discussions around const trait Tracking issue for RFC 2632, impl const Trait for Ty and ~const (tilde const) syntax Check out other posts in this series: Developing a Mass-Produced Rust Embedded Product ","date":"12 November 2023","externalUrl":null,"permalink":"/en/posts/my_first_commerical_rust_embedded_product_3/","section":"Posts","summary":" WARN! This article is still a work in progress. Content may change at any time. ","title":"Developing a Mass-Produced Rust Embedded Product - 3 Leave It to Compile Time","type":"posts"},{"content":" WARN! This article is still a work in progress. Content may change at any time. RIIR BEAM\nIntroduction # Continuing from the previous post, I want to briefly cover the pros and cons of applying Rust to embedded development, as well as how to study Rust for embedded.\nWhat I Felt After Using Rust for Embedded # There is a 38-Year Gap Between C and Rust # Image source: History Of Programming Languages\nC was released in 1972, and Rust was released in 2010. There is at least a 38-year gap between them, during which many languages, concepts, and changes emerged.\nC has structs, but it is fundamentally a procedural and strongly-typed language. Rust is a strongly-typed language with object-oriented capabilities (without inheritance, unlike C++), and like C and C++, it is designed with systems programming in mind.\nIn my personal interpretation, while C is strongly typed, it is a language tightly bound to CPU registers. In comparison, Rust is less dependent on CPU registers than C, but you can still be register-aware when programming in certain situations. I believe Rust has its strong typing characteristics rooted in the concept of \u0026ldquo;objects.\u0026rdquo;\nC has been maintained for a long time, and if you only work on embedded, you can be very fluent in C. However, there can be many challenges when adapting to a modern language like Rust. The biggest challenge is probably designing \u0026ldquo;objects\u0026rdquo; and \u0026ldquo;methods.\u0026rdquo; If you have only done procedural programming, you may struggle with this for at least several months.\nBeyond this, there are many things you need to break out of your existing mental framework \u0026ndash; the philosophy of explicitly distinguishing nullable values, ownership, and more. Understanding these concepts, and occasionally breaking them in low-level control (unsafe), or tuning for program size, is a process where you can gain a lot of CS knowledge and philosophical insight. I believe this is the most valuable part.\nAdvantages of Applying Rust to Embedded (Firmware) Projects # Thanks to built-in test support in the language spec, writing partial unit tests is straightforward. If the logic itself is sound and unit tests back it up, integration testing can be kept to a minimum while still catching bugs. Code written for firmware could be reused to a certain extent on backend servers. clippy and the formatter are built-in, making it easy to eliminate unnecessary code and unify code conventions. Object-oriented design (without inheritance) makes code reuse practical. The Cargo ecosystem makes adding libraries really convenient. Toolchain setup is also very simple. You can use async / await in firmware instead of epoll. Procedural macros are available. It is safer than writing in C, and you can significantly reduce mistakes during the development process. Disadvantages of Applying Rust to Embedded (Firmware) Projects # There are still not many reference projects to look at. It is practically difficult to apply to 8-bit processors. When putting data into queues or arrays, you tend to define separate, smaller types for enums, options, and structs to minimize size. Implementing Into/From for these is a bit tedious. You need to consider nightly features to some extent. When viewing compiled binaries with Ghidra/objdump, the output differs quite a bit from conventional C code. (Static analysis at the assembly level is still difficult. This is more of a characteristic than a disadvantage.) If you lack experience with object-oriented programming, you may end up writing procedural-style Rust code. With All These Disadvantages, Should You Still Use It? # Ultimately, it comes down to individual or organizational choice, but I personally think you should.\nThe reason is that I believe you cannot keep insisting on C forever. No matter how unique manufacturing and low-level domains may be, being an embedded developer does not mean you are outside the category of software developers. The languages developers use across the broader industry have evolved significantly and continue to change. The manufacturing and low-level sectors cannot escape this modern trend, and if they keep avoiding it, I believe the talent pipeline will eventually dry up.\nOf course, you cannot completely abandon C. But not every C developer can write code as rock-solid and performant as the Linux kernel core.\nStudying Rust # Recommended Reading # Ideally, I would like to introduce Rust syntax that would be useful for people new to Rust, from a C developer\u0026rsquo;s perspective. However, Ki-O Kim has already left an excellent article, A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust, so I will simply reference it here.\nThe resources below also do a great job of explaining Rust syntax:\nThe Rust Programming Language Korean Translation Comprehensive Rust Korean A Typical C Developer\u0026rsquo;s Journey into Rust: A Guide for C Developers Entering Rust Study Approach # If your goal is to study Rust for embedded, jumping straight into MCU or Linux driver development is not a great choice. When we talk about embedded, there are roughly three directions:\n\u0026ldquo;Firmware development running on MCUs\u0026rdquo; \u0026ldquo;Kernel development or kernel driver development\u0026rdquo; \u0026ldquo;FPGA development\u0026rdquo; What I cover here is direction 1, \u0026ldquo;Firmware development running on MCUs.\u0026rdquo; I plan to write about direction 2 separately after gaining more personal study and hands-on experience. Strictly speaking, while the domains share knowledge that is mutually helpful, they are entirely different domains. Direction 3 is even more distinct.\n(There are cases of applying Rust to FPGA, which is why I included it, but since I am not familiar with HDL-type languages, I will not mention it further.)\nIf you set your goals around directions 1 and 2, when it comes to studying just the Rust language itself outside of the domain, you need to study the language first.\nI recommend starting by reviewing the good resources mentioned above and trying out a toy project that runs on top of an OS.\nA language is just a tool, so there may be a temptation to immediately apply it to a domain you already know. However, in the long run, I do not think that is a great choice. I will discuss the reasons for this in another section.\nBe Mindful of no_std # To give a rough analogy for hardware engineers, no_std is like non-eabi. In other words, it refers to an environment that runs without standard APIs provided by an OS. In this case, there are significant constraints around heap or dynamic allocation, and since there is no standard I/O, you have no choice but to develop with hardware considerations in mind, unlike when developing on top of an OS.\nno_std is a reserved keyword for rustc (the compiler) and an implicit reserved keyword for cargo (the package manager). If #![no_std] is annotated at the beginning of a library\u0026rsquo;s lib.rs, it means the library can be used in a no_std environment.\nAdditionally, some crates mark no_std in their Cargo.toml to advertise no_std support on crates.io.\nA no_std Rust Environment Going forward, if you develop on Rust embedded, in both directions 1 and 2, you will frequently write or use no_std libraries. This is because the targets we aim for have very limited operating system support.\nUse core Instead of std for Core Library Imports # use core::borrow::BorrowMut; use core::cell::UnsafeCell; use core::marker::PhantomData; One thing you can immediately keep in mind is to import from core instead of std whenever possible. std re-exports everything from core, so using core imports directly is perfectly fine.\nhttps://doc.rust-lang.org/src/std/lib.rs.html#431-459 Avoid unsafe as Much as Possible at First # While I eventually used unsafe for optimization when writing embedded Rust, unsafe is difficult to use and requires a process of re-understanding your programming model and computer architecture knowledge through the lens of Rust\u0026rsquo;s philosophy. And the biggest problem is that fewer people can help you with it.\nI recommend getting comfortable with the Rust language first before diving into unsafe.\nIf you do need to use it, the following document provides very detailed coverage:\nThe Rustonomicon Check out other posts in this series: Developing a Mass-Produced Rust Embedded Product ","date":"4 November 2023","externalUrl":null,"permalink":"/en/posts/my_first_commerical_rust_embedded_product_2/","section":"Posts","summary":" WARN! This article is still a work in progress. Content may change at any time. RIIR BEAM\n","title":"Developing a Mass-Produced Rust Embedded Product - 2 Study Methods and Key Characteristics","type":"posts"},{"content":"This article is still being written. Content may change along the way.\nA test unit recently sent out to the field\nIntroduction # As a language to replace C, Rust is a language that has been receiving a lot of attention. While I am currently doing backend development, from the perspective of someone who used to live and breathe firmware, I have always held the belief \u0026ndash; past and present \u0026ndash; that if a programming language is not an HDL language, \u0026ldquo;it must be able to run on a 500-won MCU.\u0026rdquo;\nFrom this perspective, aside from zig which is currently gaining traction, I believe Rust is the only language that can replace C. However, this claim had the flaw that \u0026ldquo;I had never developed firmware at a production level with Rust.\u0026rdquo; Being aware of this shortcoming, after several attempts over 2-3 years, a commercial Rust embedded project that I finally started in July 2023 has reached the initial mass production phase.\nI intend to cover my experience with Rust embedded, its advantages, and various techniques across multiple articles. In this article, I would like to introduce the development framework used, what was developed for the project, and briefly share my impressions.\nAs a personal ambition, I would like to write a book about Rust embedded based on this experience, but I have not been able to decide on the target audience from among three categories. Until I settle on a target audience in my mind, I expect to organize things in a free-form manner as they come to me.\n\u0026ldquo;Developers who already have experience with Rust\u0026rdquo; \u0026ldquo;Developers whose primary job is not embedded but who do Arduino as a hobby\u0026rdquo; \u0026ldquo;Existing embedded developers\u0026rdquo; The reason I bother to explain this is that there are so few embedded developers using Rust. Most readers will likely fall into the category of developers interested in Rust, and trying to explain both the unfamiliar Rust and embedded simultaneously would be far too unkind. So even if the writing progresses slowly, I intend to go through the process of providing some perspective on the development process of embedded.\nProduct Planning # To the question of why card payment terminals are only being installed in arcades now in 2023, you need to look at the history of the arcade industry itself. Due to the \u0026ldquo;Sea Story\u0026rdquo; gambling scandal around 2007, it was not possible to install card terminals until 2020. From 2020 onward it became possible, but in that case, the game itself had to go through the approval process again. However, related regulations have recently been relaxed, and a request came in for me to develop a module that enables card terminal installation.\nGame Rating and Administration Committee decides to diversify arcade game payment methods starting next month - 2019-06-28 Regarding changes to payment methods for all-ages arcade games - 2022-03-21 Example of a bill acceptor\nCard terminals use RS232 serial communication, and existing arcade machines use a Molex 2.00mm pitch 10-pin connector for the bill acceptor, or 2-4 pin connectors for the coin acceptor. Unless special features are used, the signal systems of the 10-pin bill acceptor and coin acceptor are compatible. Given that prices have risen significantly compared to the past, 1000-won bills are used much more frequently than 500-won or 100-won coins as a payment method, so I decided to prioritize the bill acceptor wiring.\nTo add a card terminal to an existing arcade machine, the only option is to share the existing currency payment signal lines and generate signals in place of the bill acceptor (or coin acceptor). However, if you simply inject signals onto the existing wiring, the signals from the bill acceptor and the card terminal would overlap. Therefore, a FIFO Queue was applied to each signal output so that bill acceptor and card terminal inputs can be processed sequentially even if they overlap, and the hardware was designed accordingly.\nHardware Development # STM32G030C8Tx Chip Selection # STM32G030C8Tx is a Cortex-M0 (ARM Cortex-Mv6) MCU from ST. An MCU is a device that contains a 32-bit CPU along with peripherals for embedded use. This product has 64 KBytes of Flash for storing programs and 8KB of SRAM (similar to a computer\u0026rsquo;s RAM), and operates at 16 MHz. There is also a variant with half the capacity at 32 KBytes, but based on the experience at my company that 32 KBytes was not enough for a Rust debug build for even simple products, and the expectation that the features and business logic would likely grow, I chose 64 KBytes without going much higher. Additionally, this was based on the belief that being able to create a Rust embedded product on an inexpensive MCU with minimal computing resources would prove that Rust can be used for production and professional embedded development. (I have heard that you can write embedded code in Go, Python, and JavaScript too, but I think it is very difficult to use them in production environments where the cost must be very low, and it is meaningless if it only runs on expensive chips.)\nPCB (Circuit) Development # The Gerber data on the left is not publicly released, but the schematic (circuit diagram) is. BillMock-HW-RELEASE\nKiCad was used for circuit development. KiCad is an open-source EDA CAD program released by CERN. It supports all commonly used operating systems \u0026ndash; Linux, macOS, and Windows. I have been using it since version 5.x, and after going through 6.x, it became quite usable at 7.x, so I applied it to this project as well.\nPCB (circuit) development roughly divides into schematic development and Gerber artwork. A schematic is a diagram that represents how the circuit is to be configured, as shown in the right image. Gerber artwork, as shown in the left image, represents how the copper traces and components will actually be printed/mounted. Depending on the required connector positions in the circuit, the speed of communication on the traces, the magnitude of electrical signals, and power requirements, components are placed closer or farther apart, and traces are routed thicker or relatively thinner.\nJust as programs need optimization, circuits also need optimization. It is important to reduce the number and variety of components, use reasonably priced parts, reduce overall size or lower specifications to cut costs, while maintaining the hardware\u0026rsquo;s functionality and stability as planned.\nPrototype Production # JLCPCB was used for prototyping. For a company project, the orthodox choice would be to use a domestic turnkey manufacturer. However, having already used JLCPCB\u0026rsquo;s SMT (assembly) service several times, I did not need any additional adaptation, and I had confidence that if JLCPCB could produce good results at very low cost for small quantities, it would work fine at another manufacturer for mass production later. (JLCPCB is exceptionally inexpensive for small sample runs.)\nTo draw an analogy for backend server developers, I think it is similar to the thought: \u0026ldquo;If it runs on a 10-year-old school club server, it will probably run fine in the IDC for the final release.\u0026rdquo;\nFinal Mass Production # BOM Organization and Parts Procurement # Unlike software, as you get closer to hardware, you frequently hear the term BOM. Bill of Materials is literally a parts list and inevitably includes pricing and various other information. If the price is too high, you go back to the design stage and either make major design changes or, if there are components that can be replaced without design changes, substitute them with alternatives. During this process, I determined that costs were too high, reduced the number of connectors, and based on some demand forecasting, decided to purchase components in advance in \u0026ldquo;Reel\u0026rdquo; units.\nComponents sent to the assembly factory for mass production. A Reel refers to a cylindrical spool where components are wound up like film tape.\nBOM organization and optimization are very important, but since it is a topic that generally does not excite typical software developers, I think watching YouTuber Seungwoo Daddy\u0026rsquo;s restaurant BOM video can make it interesting. While it is about BOM (ingredient) management in restaurant operations rather than electronics, I think it is very informative.\nLet me tell you why this happens. - Seungwoo Daddy Daily Channel\nProduction Outsourcing / Assembly Outsourcing # Manufacturing a PCB and soldering components onto it (assembly, PCB Assembly) are separate tasks. There are cases where a turnkey company handles parts procurement as well, but in my case, I proceeded with company-supplied materials (purchasing and providing the parts ourselves).\nI used a turnkey company recommended by a senior colleague at the company who had previous mass production experience. (Trust-based, saving the time of searching around.)\nReasons for Domestic Mass Production (Why Not JLCPCB or Other Chinese Manufacturers) # Before present-day China emerged, Korea was capable of quickly handling everything from PCB manufacturing and assembly (+development) to product case injection molding and sheet metal fabrication for the entire world, and that supply chain still remains. Korea is still a country that can handle most processes of electronic product manufacturing and production. However, due to low prices and marketing, the practice of outsourcing sampling and small-scale production to Chinese companies has spread widely through YouTube and online communities. In Korea, if you can find the routes (manufacturers) known only to practitioners, and if those manufacturers accept the work, it is advantageous to conduct mass production domestically up to a certain quantity. If you are producing hundreds of thousands of units per month, it may be more cost-effective to outsource to overseas manufacturers, but for small quantities of several thousand or tens of thousands, you lack the ability and personnel to inspect whether the overseas factory performs well each time, and there is no way to hold them accountable if something goes wrong.\nBased on the PCB I made, assuming a production run of 1,000 units, JLCPCB is overwhelmingly cheaper, but there exists a point where the difference is only about 20-30%. When you factor in shipping costs, customs duties, and other administrative expenses, JLCPCB did not really provide much of an advantage. More importantly, the issue is that they do not properly take responsibility when problems occur. Besides JLCPCB, other overseas manufacturers may offer good quality, but the problem of not being able to visit in person to discuss issues when they arise still remains.\nIn the early days, I ordered 10 PCBs and 5 were defective, but I had to file the claim first.\nProgram Download # MP Tool\nEven after the PCB is manufactured, it does not just work \u0026ndash; you need to load the program onto it. There are cases where the assembly contractor can load the program binary upon request, but this time a custom program was needed, so I decided to handle the flashing directly.\nCovering why that process was necessary and how it was developed would make this too long, so I will address it in a separate article.\nThe rough process is as follows:\ngraph LR; A[Power Up] --\u003e|Flash \\nLock Check| B(Unlock Flash\\nTemporary) B --\u003e C[Program\\nDownload] C --\u003e |OTP section\\n check|D{S/N Exist?} D --\u003e|Yes| E[Update to DB] D --\u003e|No| F[Write New OTP\\n\u0026 Insert to DB] Here, an additional step is included to check the serial number in the OTP section and either add or update the information accordingly. If there is no serial number in the OTP, a serial number is written to the OTP section.\nClosing Remarks # The final mass-produced board\nNext time, I plan to cover the firmware software development side of things developed in Rust, and after that, I expect to cover the Rust embedded ecosystem and techniques I have picked up.\nI am very happy that my first personal mass production experience was built on firmware developed in Rust and that it was completed successfully.\nIf asked to do personal mass production again, I do not think I could. I will treasure it as a valuable experience that helps with development, but handling everything alone as a primary job is too much. Still, I recommend trying it at least once if you get the opportunity to do a production run on your own.\nCheck out other articles in this series: Rust Embedded Mass Production Development Story ","date":"2 November 2023","externalUrl":null,"permalink":"/en/posts/my_first_commerical_rust_embedded_product_1/","section":"Posts","summary":"This article is still being written. Content may change along the way.\nA test unit recently sent out to the field\n","title":"Rust Embedded Mass Production Development Story - 1: From Development to Production","type":"posts"},{"content":"","date":"8 April 2023","externalUrl":null,"permalink":"/en/tags/amd/","section":"Tags","summary":"","title":"AMD","type":"tags"},{"content":"","date":"8 April 2023","externalUrl":null,"permalink":"/en/tags/cache/","section":"Tags","summary":"","title":"Cache","type":"tags"},{"content":"","date":"8 April 2023","externalUrl":null,"permalink":"/en/categories/cpu/","section":"Categories","summary":"","title":"CPU","type":"categories"},{"content":"It has been quite a while since ZEN4 started selling, and ZEN3 has also gone through several internal stepping/revision changes that seem to have improved things, so I feel this is an appropriate time to write this article. I originally posted this on other communities as well, and while it may seem tangential to development, it deals with CPU internals, so I am reposting it on my dev blog.\nInstruction L1/L2 Cache Failures Occur When Power Consumption Changes Drastically # Just searching for \u0026ldquo;WHEA\u0026rdquo; on Quasarzone yields countless posts.\nIn the past, numerous people reported these issues while using AMD Zen2/Zen3:\nWHEA 18 errors suddenly appear in the Windows Event Logger. The system suddenly shuts down. [Halt] (no logs found) The system suddenly resets. [Reset] (no logs found) These symptoms occur even when the system is idle. Disabling C-State reduces the frequency of these issues. \u0026ldquo;Just disable C-State.\u0026rdquo; I also experienced these issues when I was using a 3950X, and it cost me an enormous amount of time. Eventually, I went from the 3950X to a 5950X (a recent stepping revision), and in between, I temporarily used a 5900X that I purchased separately.\nThis led to a situation where my computers self-replicated and I ended up with two systems. I also purchased three motherboards during this process.\nIf you have read this far, you will have noticed a few key terms:\nKeyword 1 Keyword 2 Keyword 3 Instruction L1, L2 cache C-State Reset/Halt What is C-State? # Let me explain C-State first. Source: https://www.dell.com/support/kbdoc/ko-kr/000060621/c-state%EB%8A%94-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80\nC-State is a feature that reduces CPU power consumption, minimizing it as much as possible when the CPU is underutilized.\nIn practice, whether on AMD or Intel, the power consumption difference between C-State enabled and disabled during PC idle is quite significant when measured with a UPS \u0026ndash; around 10W to 20W. That difference alone is enough power to run one of the new Intel Alderlake N100 Mini PCs. Furthermore, this feature has been around since the 1990s, so it is essentially a well-established feature that should just work reliably.\nWhat is Instruction L1/L2 Cache? # Let me start with the memory model taught in undergraduate \u0026ldquo;Computer Architecture\u0026rdquo; courses in Computer Science departments.\n[Source: https://diveintosystems.org/book/C11-MemHierarchy/mem_hierarchy.html ]\nThe modern memory system is structured in this pyramid-like hierarchy.\nFrom registers at the very top, through cache, down to Flash Disk and beyond, access time and capacity scale proportionally as you go down.\nFrom the CPU\u0026rsquo;s perspective, accessing a register takes the shortest time, but the cost per area for registers is extremely high.\nThe further down you go, the more time it takes, but the cheaper it becomes.\nAlthough this diagram does not show the exact capacity differences between registers/cache/Main Memory, the allocation of capacity depending on the system and its purpose is very important. The key is in \u0026ldquo;how you divide it.\u0026rdquo; One thing the user can control is to just pack in as much DRAM as possible.\nSo what exactly is the Instruction L1/L2 cache?\nThe CPU needs cache not only for fast data access/reads,\nbut also for fast instruction execution.\nIf the data needed for reading or the instructions being processed are not in the cache, the CPU effectively stalls while fetching from DRAM (main memory). (We will not consider the pipelining concept here.)\nThe L1/L2 designation refers to levels: L1 is the space closest and fastest for each CPU core to access, while L2 is a slightly more distant level (though still much closer than DRAM).\nComing back to Zen2/3, the CPUs from the Zen2/3 generation with 16 cores have the highest core count. They adopted a multi-die structure, packaging two groups of 8 cores together.\nSo in reality, the memory model does not form a single pyramid shape as shown above. Instead, there are two pyramids on top of one pyramid, and on top of those two pyramids, there are 8 additional pyramids each.\nDetailed Report on the Symptoms Mentioned Above # The majority of users who build their own PCs use Windows. If you experienced the issues mentioned in this article,\nyou would have seen a WHEA18 error in the Windows Event Logger, or the system would have shut down (reset) or frozen (halt) without any error logged at all. Whether it is a reset or halt likely depends on the motherboard. I confirmed this by using Asrock/Gigabyte/Asus boards with B550/X570 chipsets, all three of which exhibited errors in different ways.\nTo analyze this problem accurately, we should not be looking at Windows but rather finding answers in the Linux community.\n[Correctable MCE errors logged for CPU0/CPU12 L1 instruction cache with AMD Ryzen 9 3900X 12-Core Processor] https://bugzilla.redhat.com/show_bug.cgi?id=1830404 [Random freezes and reboots AMD Ryzen] https://bugzilla.kernel.org/show_bug.cgi?id=210261 (There are many more reports beyond these two links, but I will only post these two for now.)\nThe threads themselves are very long, so here is a summary:\nAt random times, the errors below appear and the system freezes. And replacing the CPU just fixes it.\nEnabling C-State prevents or reduces the occurrence of the issue.\nMay 01 15:06:59 kernel: mce: [Hardware Error]: Machine check events logged May 01 15:06:59 kernel: [Hardware Error]: Corrected error, no action required. May 01 15:06:59 kernel: [Hardware Error]: CPU:12 (17:71:0) MC1_STATUS[Over|CE|MiscV|AddrV|-|-|SyndV|-|-|-]: 0xdc20000000030151 May 01 15:06:59 kernel: [Hardware Error]: Error Addr: 0x000000076da32ae0 May 01 15:06:59 kernel: [Hardware Error]: IPID: 0x000100b000000000, Syndrome: 0x000000001a030507 May 01 15:06:59 kernel: [Hardware Error]: Instruction Fetch Unit Ext. Error Code: 3, IC Data Array Parity Error. May 01 15:06:59 kernel: [Hardware Error]: cache level: L1, tx: INSN, mem-tx: IRD May 01 15:06:59 kernel: mce: [Hardware Error]: Machine check events logged May 01 15:06:59 kernel: [Hardware Error]: Corrected error, no action required. May 01 15:06:59 kernel: [Hardware Error]: CPU:0 (17:71:0) MC1_STATUS[Over|CE|MiscV|AddrV|-|-|SyndV|-|-|-]: 0xdc20000000030151 May 01 15:06:59 kernel: [Hardware Error]: Error Addr: 0x0000000fbedc2ae0 May 01 15:06:59 kernel: [Hardware Error]: IPID: 0x000100b000000000, Syndrome: 0x000000001a030507 May 01 15:06:59 kernel: [Hardware Error]: Instruction Fetch Unit Ext. Error Code: 3, IC Data Array Parity Error. May 01 15:06:59 kernel: [Hardware Error]: cache level: L1, tx: INSN, mem-tx: IRD Speculative Analysis of the Error Cause # This particular condition occurs extremely rarely (a CPU running at 3GHz or above executes 3,000,000,000 cycles per second, so from a cycle perspective, occurring once every 30 minutes to 24 hours is extremely rare \u0026ndash; but this is not saying it is rare from a user\u0026rsquo;s perspective).\nThe clue was found in the C-State feature mentioned above:\nIf C-State is enabled, the power delivered to the CPU core goes from very low to very high in a very short time. If C-State is disabled, the power delivered to the CPU core goes from slightly low to very high in a very short time. So the cause relates to the rapid change in power delivered to the CPU core affecting the CPU Instruction L1/L2 cache.\nWhile executing instructions, if the instructions themselves that the CPU fetches from the cache are corrupted, the CPU cannot execute them. It cannot proceed further, and in fact, even producing a core dump (memory dump) in this case would be a miracle. [Broadly speaking, there are two approaches to memory debugging: one is to back up the entire memory via software, and the other is to dump memory using hardware equipment that costs more than a luxury car. In this case, only the latter can provide a proper analysis.]\nWhile the contents of L1/L2 cache are said to be a mirror of DRAM (Main Memory), kept for faster access,\nin actual operating system and program design, variables like Linux\u0026rsquo;s per-cpu variables are typically sized to match or be smaller than each architecture\u0026rsquo;s L1 cache size as a block unit. In SMP (multi-core) systems, there are values where the address and memory information are stored in DRAM, but the accurate information is presumed to reside in the cache rather than DRAM, for faster read/write without going to DRAM. If L1/L2 becomes unreliable, variables with per-cpu-like characteristics (values used by computer programs) would become unusable, and this can similarly affect instructions.\nWhether the root cause is truly the rapid fluctuation in power delivered to the CPU is ultimately speculation,\nbut the fact that so many people are reporting L1/L2 cache problems is, in my personal opinion, recall-worthy.\nThe per-cpu details I mentioned later are not taught at the undergraduate level, but CPU L1/L2 cache is undergraduate-level knowledge, and there appears to be a fundamental design miss.\nDetailed link about per-cpu: http://jake.dothome.co.kr/per-cpu/\nHow Are AMD and Distributors Responding? # So how are AMD and distributors responding? Looking at how distributors check for defects: they boot the system and run a benchmark program. That is it. In reality, finding such problems is very difficult unless you use professional equipment like Trace32.\n[Source: https://www2.lauterbach.com/pdf/general_ref_c.pdf page 172]\nWith Trace32, you can observe all CPU values in real time. The most an average person or even most developers can do is access memory addresses, but there is no way to tell whether the value comes from DRAM or cache. While such advanced development tools are needed, it is practically impossible for distributors to perform after-sales service using these tools. Therefore, the service staff must also find themselves in a very difficult position regarding this issue.\nFrom the consumer\u0026rsquo;s perspective, proving this defect and getting an exchange is extremely difficult.\nIn my opinion, the fault lies with AMD.\nI believe the problem is that there were either QC failures initially, or that AMD failed to properly verify and fix these issues during silicon design before selling the product.\nSo does AMD publicly disclose or share information about defects in their CPUs?\nNo, they hide far more than Intel does.\nFor reference, Intel shared an Errata Sheet (a paper documenting design flaws and issues) for their recently released 13th generation:\n[ Intel Raptor Lake S - Errata Details ] https://edc.intel.com/content/www/us/en/design/products/platforms/details/raptor-lake-s/13th-generation-core-processor-specification-update/errata-details/\nHowever, AMD has not published Errata Sheets for the consumer Zen2: Family 17h Model 71h or Zen3: Family 19h Model 21h.\nThose who purchase chips to design their own PCB circuits or write Linux kernel drivers may have heard of Errata Sheets and have occasionally found problems there, leading them to re-select components or work around silicon bugs in software.\nIt is deeply disappointing that AMD has not issued any notice about such a serious problem and has instead relied on internet posts telling people to disable C-State while hiding these issues.\nI hope that AMD will change its ways and properly disclose defects in products that have serious issues with the memory hierarchy. I will close this article with a photo of a cat that loves memory. ","date":"8 April 2023","externalUrl":null,"permalink":"/en/posts/casts_double_amd_desktop_zen_2_and_3_halt_randomly_kr/","section":"Posts","summary":"It has been quite a while since ZEN4 started selling, and ZEN3 has also gone through several internal stepping/revision changes that seem to have improved things, so I feel this is an appropriate time to write this article. I originally posted this on other communities as well, and while it may seem tangential to development, it deals with CPU internals, so I am reposting it on my dev blog.\n","title":"Raising Suspicions of QC/Design Flaws Causing Intermittent Resets/Freezes in ZEN 2/3","type":"posts"},{"content":"","date":"8 April 2023","externalUrl":null,"permalink":"/en/tags/ryzen/","section":"Tags","summary":"","title":"Ryzen","type":"tags"},{"content":"","date":"8 April 2023","externalUrl":null,"permalink":"/en/tags/silicon-bug/","section":"Tags","summary":"","title":"Silicon Bug","type":"tags"},{"content":" 1. Fourier series coefficients for Continuous signal # Asking deriving coefficients comes with periodic signal.: \\(x(t) \\rightarrow a_k\\)\n1.1 (CT FS) Basic concept of continuous Fourier coefficients # $$ \\begin{gathered} x(t): \\text { Periodic signal } \\ T: \\text { Fundamental Period } \\ \\end{gathered} $$\n$$ \\begin{gathered} \\omega_0=\\frac{2 \\pi}{T} \\quad \u0026amp; \\quad f_0=\\frac{1}{T}(\\text { freq }) \\ \\end{gathered} $$\n$$ \\begin{gathered} \\quad x(t)=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k \\omega_0 t}=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k(2 \\pi / T) t} \\end{gathered} $$\n1.2 (CT FS) Continuous-Time, Fourier Series # Convert periodic signal to fourier coefficients : \\(x(t) \\stackrel{F S}{\\rightarrow} a_k\\)\n$$ \\begin{gathered} a_k=\\frac{1}{T} \\int _T x(t) e^{-j k \\omega_0 t} d t \\ \\end{gathered} $$ $$ or $$\n$$ \\begin{gathered} a_k=\\frac{1}{T} \\int_T x(t) e^{-j k(2 \\pi / T) t} d t \\end{gathered} $$\n1.3 (CT IFS) Continuous-Time, Inverse Fourier Series # Fourier coefficients to peridoic signal : \\(a_k \\stackrel{I F S}{\\longrightarrow} x(t)\\)\n$$ x(t)=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k \\omega_0 t}=\\sum_{k=-\\infty}^{+\\infty} a_k e^{j k(2 \\pi / T) t} $$\n1.4 Properties of Continuous-Time Fourier Series # Fourier transform for Continuous-time signal \\(x(t)\\) Most of case, aperiodic signals comes...\n2. Fourier coefficients for Discrete signal # $$ \\begin{gathered} x[n] \\rightarrow \\boldsymbol{a}_{\\boldsymbol{k}} \\end{gathered} $$ Asking deriving coefficients comes with periodic signal.\n2.1 (DT FS) Basic concept of discrete Fourier coefficients \\(x[n]: Periodic\\) # $$ \\begin{gathered} x[n]: \\text { Periodic signal } \\end{gathered} $$\n$$ N \\text { : Fundamental Period (LCM of } 2 \\pi \\text { ) } $$\n$$ \\begin{gathered} \\omega_0=\\frac{2 \\pi}{N} \\quad \u0026amp; \\quad f_0=\\frac{1}{T}(\\text { freq }) \\end{gathered} $$\n$$ x[n]=\\sum_{k=\\langle N\\rangle} a_k e^{j k \\omega_0 n}=\\sum_{k=\\langle N\\rangle} a_k e^{j k(2 \\pi / N) n} $$\n2.3 (DT FS) Discrete-Time, Fourier Series # $$\\begin{gathered} a_{k}=\\frac{1}{N} \\sum_{n=\\langle N\\rangle} x[n] e^{-j k \\omega_{0} n} \\ a_{k}=\\frac{1}{N} \\sum_{n=\\langle N\\rangle} x[n] e^{-j k(2 \\pi / N) n} \\end{gathered}$$\n$$\\begin{aligned} \u0026amp; x[n] \\stackrel{F S}{\\rightarrow} a_{k} \\end{aligned}$$\n2.4 (DT IFS) Discrete-Time, Inverse Fourier Series # $$a_{k} \\stackrel{I F S}{\\rightarrow} x[n] \\quad x[n]=\\sum_{k=\\langle N\\rangle} a_{k} e^{j k \\omega_{0} n}=\\sum_{k=\\langle N\\rangle} a_{k} e^{j k(2 \\pi / N) n}$$\n2.5 Properties of Continuous-Time Fourier Series # 3 Fourier transform for Continuous-time signal \\(x(t)\\) : # 3.1 (CT FT) Continuous-Time, Fourier Transform ( periodic) # $$ x(t) \\stackrel{F T}{\\longrightarrow} X(j \\omega) $$\n$$ \\tilde{x}(t): \\text { single sliced periodic sig } \\ $$\n$$ a_k=\\frac{1}{T} \\int_{-\\frac{T}{2}}^{\\frac{T}{2}} \\tilde{x}(t) e^{-j k \\omega_0 t} d t $$ $$ X(j \\omega)=T a_k $$\n3.2 (CT FT) Continuous-Time, Fourier Transform (aperiodic) # $$x(t) \\stackrel{F T}{\\rightarrow} X(j \\omega) \\quad X(j \\omega)=\\int_{-\\infty}^{+\\infty} x(t) e^{-j \\omega t} d t$$\n3.3 (CT IFT) Continuous-Time, Inverse Fourier Transform # $$X(j w) \\stackrel{I F T}{\\rightarrow} x(t) \\quad x(t)=\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} X(j \\omega) e^{j \\omega t} d \\omega$$\n3.4 Properties of Continuous Fourier Transform # 3.5 Basic Continuous Fourier Transform Pairs # 4 Fourier transform for Discrete-time signal \\(x[n]\\) # Most of case, aperiodic signals comes‚Ä¶\n4.1 (DT FT) Discrete-Time, Fourier Transform # $$x[n] \\stackrel{F T}{\\rightarrow} X\\left(e^{j \\omega}\\right) \\quad X\\left(e^{j \\omega}\\right)=\\sum_{n=-\\infty}^{+\\infty} x[n] e^{-j \\omega n}$$\n4.2 (DT IFT) Discrete-Time, Inverse Fourier Transform # $$X\\left(e^{j \\omega}\\right) \\stackrel{I F T}{\\rightarrow} x[n] \\quad x[n]=\\frac{1}{2 \\pi} \\int_{2 \\pi} X\\left(e^{j \\omega}\\right) e^{j \\omega n} d \\omega$$\n4.3 Properties of Discrete Fourier Transform # 4.4 Basic Discrete Fourier Transform Pairs # PDF version # Related files DSP_Fourier_CheatNote.pdf (275 KBytes) ","date":"20 December 2022","externalUrl":null,"permalink":"/en/posts/discrete_signal_processing_cheat_note/","section":"Posts","summary":"1. Fourier series coefficients for Continuous signal # Asking deriving coefficients comes with periodic signal.: \\(x(t) \\rightarrow a_k\\)\n","title":"Discrete Signal Processing Fourier Transform Cheat Note","type":"posts"},{"content":"","date":"20 December 2022","externalUrl":null,"permalink":"/en/tags/dsp/","section":"Tags","summary":"","title":"DSP","type":"tags"},{"content":"","date":"20 December 2022","externalUrl":null,"permalink":"/en/tags/english_article/","section":"Tags","summary":"","title":"English_Article","type":"tags"},{"content":"","date":"20 December 2022","externalUrl":null,"permalink":"/en/categories/math/","section":"Categories","summary":"","title":"Math","type":"categories"},{"content":"","date":"20 December 2022","externalUrl":null,"permalink":"/en/tags/mathmatics/","section":"Tags","summary":"","title":"Mathmatics","type":"tags"},{"content":"","date":"20 December 2022","externalUrl":null,"permalink":"/en/tags/signal-processing/","section":"Tags","summary":"","title":"Signal Processing","type":"tags"},{"content":"I have been using Rust at the company I recently joined. Five months have passed since I switched jobs, and I would like to describe what I have felt so far. Setting aside the detailed syntactic advantages, I will simply describe my general impressions.\nPros # If there is a developer who knows the domain well and at least two people conduct thorough code reviews for each other, you can code safely. Compared to C, there are many conveniences. As someone who only worked with C and firmware, Rust feels more familiar compared to other modern languages, and most behaviors/designs feel reasonable. In my personal opinion, Rust can be applied to many areas except frontend. [Firmware, OS-dependent utilities, backend] You continuously encounter study/challenge opportunities related to pure CS, rather than just business logic. Regardless of what target architecture (CPU, Operating System) comes along, it is very convenient to adapt. Cons # Can we go beyond FullStack and become EntireStack developers?\nEach difficulty point fundamentally requires a large base of knowledge. Occasionally, the study/challenge demands spill over into personal time. [This is not a con for me, but I think some people may feel it is.] There are significant limitations when hiring. When asked \u0026ldquo;What are the advantages of this language?\u0026rdquo;, the scope of required knowledge inevitably becomes very broad. And that scope of knowledge may lie far beyond most people\u0026rsquo;s areas of interest. If you use it in embedded and look at the domestic developer pool, it is difficult to find embedded developers who will use Rust together, and the range of additional skills required of embedded developers grows almost exponentially. Even without considering Rust, the pool of embedded developers is simply too small, although embedded development is not my primary work. The chip I want to use always has ambiguous Rust embedded support. (The answer to this is for me to contribute myself.) The community is still more focused on chips suitable for toy projects rather than chips that are practical in terms of cost/lead time during the chip shortage situation. Miscellaneous # I was very strict about code reviews at my previous company and was worried about how things would be at my current company. My initial impression was that since Rust\u0026rsquo;s syntax is more sophisticated than C, individual coding styles varied too much, and I thought this would be a bottleneck during reviews. However, clippy handles a lot of that, and as long as there is typo checking and a reasonable level of agreed-upon tests, reviews are not a problem. We can naturally have healthy discussions about CS topics with each other. Proper Support for Multiple Architectures # In theory and concept, pure interpreted languages are advantageous for multi-platform support. However, my actual experience with Rust has led me to feel differently. No matter how theoretically advantageous interpreted languages are supposed to be, for truly and properly supporting all architectures (various CPU architectures and multiple OSes), Rust was extremely convenient.\nFirst of all, properly supporting all architectures is one of the key values of systems programming or firmware programming. So what languages were traditionally used for this kind of programming? That would be C and C++. However, to quickly get started (Getting Start) with these languages, you first had to set up Makefile or CMake configurations, and every time a new architecture was added, you had to accommodate it. On top of that, setting up the compiler, development environment, and libraries for each architecture was a separate task entirely.\nLet me compare with another language. Currently, almost nobody compares Go-Lang and Rust, but five years ago, many people did. When comparing the systems programming domain only on top of an OS, both are excellent languages. What I am about to say is quite a stretch, but in Rust\u0026rsquo;s conceptual no-std scenario \u0026ndash; where there is no OS or the OS is very different from a typical one \u0026ndash; it is difficult to adapt. [The author previously worked in firmware development and is also evaluating whether production-grade firmware development is feasible.]\nRust Is Difficult for Quick Prototyping Right Away # In the previous sections, I praised Rust\u0026rsquo;s advantages, but in this section, I will describe some slightly disappointing aspects. Rust is a difficult language to write. More precisely, it is very difficult to develop in a Rust-like way that maximizes Rust\u0026rsquo;s strengths. Realistically, it would be very difficult with any language to fully leverage its strengths during development. However, if Rust is chosen for commercial purposes (as a language/framework for a company/development team), personal preferences should be set aside in favor of the company\u0026rsquo;s perspective.\nIs it a medium that can realize what we want to develop? Can we adequately recruit developers? How much development time does it require? Does it run fast and correctly? Do the team members want to use it? (In other words, preference.) Rust is likely to score low on items (2) and (3), and I believe this is absolutely the case for (2) in particular.\nIf Rust must be chosen despite these drawbacks, it would largely be due to (4) and (5). In that case, the development team and developers would need tangible events or results that highlight Rust\u0026rsquo;s advantages in order to sustain its use, whether voluntarily or otherwise.\nEven though you can just use whatever language the company assigns, if you have a choice and want to keep using Rust, you would want to highlight its merits. (This is a somewhat difficult topic to articulate, as it overlaps with emotional territory.)\nThen, to develop in a way that maximizes Rust\u0026rsquo;s strengths, a great deal of knowledge is required. In other words, the learning curve becomes steep. Depending on how you look at it, this can be either digging your own grave or creating an opportunity.\nBut an Opportunity to Gain Tremendous Intellectual Value # When C was first created, concepts like multi-processing/processors (SMP), caching, and GPGPU did not exist, and in many details, it was an era with a different memory model from today\u0026rsquo;s. And to this day, C is used to handle these aspects. When you find yourself in a situation where you must develop with these concepts in mind, there are many difficulties.\nHowever, Rust has infrastructure in place to overcome these challenges to some degree, with room for more to come. And while this is an ambiguous statement, through Rust, it feels like opportunities are created to more closely examine the difficult architectural designs of computers and operating systems, albeit indirectly. This can be gained through Rust compiler\u0026rsquo;s safety constraints and warnings, and I believe it is also driven by the influence of a community populated by many expert-level systems programmers. Speaking a bit more about multi-platform support, I also believe that the strength of the community is why multi-platform support is handled so well.\nWhen Can We Say We Have Become Proficient Rust Developers? # People occasionally say things like \u0026ldquo;I am a ____ developer.\u0026rdquo; So when can we say that we have become proficient Rust developers?\nThere is no definitive answer.\nHowever, in my personal opinion, if you can explain the advantages that a given framework or language provides in a way that others can understand, then perhaps you can call yourself a ____ developer.\nBut unfortunately, with Rust, this is very difficult to articulate. You have to start by explaining ownership. And to do that, you first need to understand the stack and heap of a running process.\nReference: 4.1 What is Ownership - The Rust Programming Language Korean Translation\nBecause of this, you either need the ability to explain a great deal to the person you are trying to convince, or the listener must be at a high level, requiring precise and very deep explanations.\nIt is unfortunate that the difficulty level of explanation starts at HARD MODE from the get-go, but we do not develop alone. If we truly want to submit a Pull Request, I think it is necessary to explain well to the reviewer, or to write code in a way that makes explanations easier.\nThrough that process, you can build the knowledge base and communication skills needed to explain things, and going further, I think you can develop the ability to explain any given technology as described above.\nThe next time (or the time after) I write a retrospective, I plan to cover the actual gains and losses from using Rust at work.\n","date":"27 November 2022","externalUrl":null,"permalink":"/en/posts/five_mothes_ago_from_using_rust_as_work_kr/","section":"Posts","summary":"I have been using Rust at the company I recently joined. Five months have passed since I switched jobs, and I would like to describe what I have felt so far. Setting aside the detailed syntactic advantages, I will simply describe my general impressions.\n","title":"About Five Months After Using Rust at Work","type":"posts"},{"content":"","date":"27 November 2022","externalUrl":null,"permalink":"/en/categories/etc/","section":"Categories","summary":"","title":"Etc","type":"categories"},{"content":"","date":"4 October 2022","externalUrl":null,"permalink":"/en/tags/armv8a/","section":"Tags","summary":"","title":"ARMv8A","type":"tags"},{"content":"","date":"4 October 2022","externalUrl":null,"permalink":"/en/tags/cross-compile/","section":"Tags","summary":"","title":"Cross Compile","type":"tags"},{"content":"In October 6, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nCurrent linux 6.1 rc1 doesn\u0026rsquo;t contain rust for linux with ARM64. Thus this article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\nIntroduction # This article describes cross-compiling rust for linux on x86_64 debian. There is still not enough computing power to build arm64 native kernel except for Apple Silicon.\nBtw, this article is in reference to these links\nhttps://github.com/Rust-for-Linux/linux/blob/rust/Documentation/rust/quick-start.rst https://docs.kernel.org/kbuild/llvm.html#cross-compiling Debian / Ubuntu Package Requirements # # Install build-requirements for kernel compile with LLVM. # Biggest difference to native build is # crossbuild-essential-arm64 needed to build` for arm64 apt install clang git llvm-dev libclang-dev build-essential \\ bc kmod cpio flex libncurses5-dev libelf-dev libssl-dev \\ dwarves bison lld curl crossbuild-essential-arm64 Before build kernel, we need to install some packages.\ncurl --proto \u0026#39;=https\u0026#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh rustup default 1.62 rustup component add rust-src # rustfmt and clippy is need for later developing and debugging. rustup component add rustfmt rustup component add clippy Install rust with curl. You can select just default options. Also current rust for linux working with 1.62. Some native compile is working well with recent version (1.64 tested, but cross compile not working).\nArch Package Requirements # TBD Clone linux from Rust-For-Linux # State of current rust-for-linux, they are under 6.0 RC\n# In my case use `Develop` as worksapce, you can replace this word. mkdir -p ~/Develop cd ~/Develop git clone https://github.com/Rust-for-Linux/linux.git -b rust clone like this.\nNecessary some rust scripts in Rust-For-Linux # In cloned linux directory.\ngit clone --recurse-submodules \\ --branch $(scripts/min-tool-version.sh rustc) \\ https://github.com/rust-lang/rust \\ $(rustc --print sysroot)/lib/rustlib/src/rust This work clone rustlib repository in your rust toolchain directory.\ncargo install --locked --version $(scripts/min-tool-version.sh bindgen) bindgen This work need to bind existing c code to rust code. s\nCheck RUST_AVAILABLE # cd ~/Develop/linux make LLVM=1 rustavailable $ make LLVM=1 rustavailable *** *** Rust compiler \u0026#39;rustc\u0026#39; is too new. This may or may not work. *** Your version: 1.62.1 *** Expected version: 1.62.0 *** Rust is available! Than if you get result like this it\u0026rsquo;s good to go (1.62.1 was fine to cross compile, but if you consider best fit, run rustup default 1.62.0.)\nConfigure linux source code with menuconfig # make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- defconfig make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- menuconfig General setup -\u0026gt; Rust support # In General setup -\u0026gt; Rust support , Enable this If you don\u0026rsquo;t see the flag, double-check that the make LLVM=1 rustavailable process was successful. For a detailed mailing thread on CONFIG_RUST see here. See details \u0026rharu; Kernel hacking -\u0026gt; Sample kernel code # For easy to develop rust kernel code we need some examples. You can get them with following menus.\nIn Kernel hacking -\u0026gt; Sample kernel code , enable it (not all of them..) when you interest. I don\u0026rsquo;t recommend you enable them when you write own driver. Because there\u0026rsquo;s some possibility make system slow or make unwanted log in dmesg. In particular, the netflitter example outputs too many dmesg, so it is recommended that you disable it unless you are studying the netfilter example. Kernel hacking -\u0026gt; Rust hacking # For debug rust kernel code or driver, need to enable some debug options.\nIn Kernel hacking -\u0026gt; Rust hacking , enables it and inside menus.\nCross compile # # -j4 for 4 core virtual machine, -j2 for 2 core, -j1 for single core. make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- LLVM=1 -j32 Build with following command. You need to set number of job considering assigned number of cores for virtual machine. (-j#)\nAlso while you build it, it will ask some flag. I just select default in my case.\nSimple compile speed comparation. # Machine / Environment Compile time M1 Max Virtual Machine (4 core 8GB RAM with aarch64 debian11) 16 minutes M1 Asahi Linux (4P+4E core 16GB RAM MacMini with 6.1.0-rc6-asahi) 11 minutes AMD Ryzen 5950x Native (16 core 32 thread, 64GB with x86_64) 3 minutes AMD Threadripper Pro 5975wx Native (32 core 64 thread, 256GB with x86_64) 2 minutes Install cross compiled kernel to arm64 virtual machine # TBD, will update asap. Install cross compiled kernel to raspberry pi # TBD, will update asap. ","date":"4 October 2022","externalUrl":null,"permalink":"/en/posts/cross_compiling_aarch64_rust_for_linux_from_x86_64_linux/","section":"Posts","summary":"In October 6, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nCurrent linux 6.1 rc1 doesn‚Äôt contain rust for linux with ARM64. Thus this article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\n","title":"Cross compiling aarch64(arm64) rust for linux from x86_64 machine","type":"posts"},{"content":"","date":"4 October 2022","externalUrl":null,"permalink":"/en/categories/linux/","section":"Categories","summary":"","title":"Linux","type":"categories"},{"content":"","date":"4 October 2022","externalUrl":null,"permalink":"/en/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"In October, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nmodules, out-of-tree # There are two main ways to develop kernel modules. In-Of-Tree and Out-Of-Tree. In this article, we\u0026rsquo;re going to make the Out-Of-Tree method a Rust kernel module.\nBefore we start # Check your kernel has been compiled with CONFIG_RUST=y. # Check with following command.\nzcat /proc/config.gz | grep -i CONFIG_RUST=y The result comes with CONFIG_RUST=y.\nBut you may not check from /proc/config.gz when using distibution kernel image that downloaded or pre-installed.\nNeed some build \u0026 install rust support kernel see here. See details \u0026rharu; Prepare $KDIR # $KDIR is path of kernel source.\nIn this article path of kernel source that system used for boot with CONFIG_RUST.\nKDIR and other kernel module descriptions See details \u0026rharu; In my case it\u0026rsquo;s ~/Develop/linux\n# /home/pmnxis/Develop/linux export KDIR=$HOME/Develop/linux Looking in to code # Let\u0026rsquo;s preview the code rust_out_of_tree.rs \u0026hellip;\nLicense and imports # 1 2 3 4 5 6 7 8 9 10 11 12 13 // SPDX-License-Identifier: GPL-2.0 //! Rust out-of-tree sample use kernel::prelude::*; module! { type: RustOutOfTree, name: \u0026#34;rust_out_of_tree\u0026#34;, author: \u0026#34;Rust for Linux Contributors\u0026#34;, description: \u0026#34;Rust out-of-tree sample\u0026#34;, license: \u0026#34;GPL\u0026#34;, } Lines 1~3, show file\u0026rsquo;s license information. If you are write the code in company, SomeCompanyName instead GPL-2.0 or just keep GPL-2.0. 1 2 3 4 5 6 7 8 9 10 11 12 13 // SPDX-License-Identifier: GPL-2.0 //! Rust out-of-tree sample use kernel::prelude::*; module! { type: RustOutOfTree, name: \u0026#34;rust_out_of_tree\u0026#34;, author: \u0026#34;Rust for Linux Contributors\u0026#34;, description: \u0026#34;Rust out-of-tree sample\u0026#34;, license: \u0026#34;GPL\u0026#34;, } Line 5 means, bring rust for linux library for this code.\nIn following example module written in C were include like this.\n2 3 4 #include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kthread.h\u0026gt; #include \u0026lt;linux/irq_work.h\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 // SPDX-License-Identifier: GPL-2.0 //! Rust out-of-tree sample use kernel::prelude::*; module! { type: RustOutOfTree, name: \u0026#34;rust_out_of_tree\u0026#34;, author: \u0026#34;Rust for Linux Contributors\u0026#34;, description: \u0026#34;Rust out-of-tree sample\u0026#34;, license: \u0026#34;GPL\u0026#34;, } Line 8, implement of the module trait. Line 9, name of the module, if we written c, it\u0026rsquo;s the name of *.ko name field. Line 10~12, those fields are simillar with below the example written in c. Those fields are same purpose.\n56 57 58 MODULE_AUTHOR(\u0026#34;Steven Rostedt\u0026#34;); MODULE_DESCRIPTION(\u0026#34;trace-printk\u0026#34;); MODULE_LICENSE(\u0026#34;GPL\u0026#34;); We preview macro_rule! module shortly. You can see detail here.\nDetails for module! See details \u0026rharu; Actual implements # 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 struct RustOutOfTree { numbers: Vec\u0026lt;i32\u0026gt;, } impl kernel::Module for RustOutOfTree { fn init(_name: \u0026amp;\u0026#39;static CStr, _module: \u0026amp;\u0026#39;static ThisModule) -\u0026gt; Result\u0026lt;Self\u0026gt; { pr_info!(\u0026#34;Rust out-of-tree sample (init)\\n\u0026#34;); let mut numbers = Vec::new(); numbers.try_push(72)?; numbers.try_push(108)?; numbers.try_push(200)?; Ok(RustOutOfTree { numbers }) } } impl Drop for RustOutOfTree { fn drop(\u0026amp;mut self) { pr_info!(\u0026#34;My numbers are {:?}\\n\u0026#34;, self.numbers); pr_info!(\u0026#34;Rust out-of-tree sample (exit)\\n\u0026#34;); } } I just guess working as \u0026hellip;\nOn init (insmod?), print out somewhere with text Rust out-of-tree sample (init) vec\u0026lt;i32\u0026gt;[72, 108, 200] is stored some kernel memory space with struct RustOutOfTree. When drop the module (rmmod?), will print out with text [72, 108, 200]. By the way, we need to keep on eyes here.\n23 24 let mut numbers = Vec::new(); numbers.try_push(72)?; In line 24, try_push is not exsting in std::Vec. In rust kernel programming, need to use try_push instead std::Vec::push.\nDetails for alloc::vec::Vec See details \u0026rharu; Also there's some `init` and `drop` functions in line 20 and 33. The code covers those function with `impl for` pattern. Details for Implementation in rust See details \u0026rharu; I will explain about implementation and it\u0026rsquo;s philosophy later article.\nRun code # Build it # make LLVM=1 My rust acceptable kernel build were buiten with LLVM.\nSo I compile the kernel module with LLVM.\nInstall module # sudo insmod ./rust_out_of_tree.ko After compile, we can there\u0026rsquo;s rust_out_of_tree.ko inside of project directory.\nWe can install module with insmod that normally used before.\nInspect result # # do `sudo rmmod rust_out_of_tree` if you already install the module` # clear all of dmesg log sudo dmesg -C # install the module sudo insmod ./rust_out_of_tree.ko # see log dmesg # uninstall the module sudo rmmod rust_out_of_tree # check log again. dmesg We can check the inspect actual result with above commands.\nAs we guess it prints with [72, 108, 200].\nConclusion # We can summary from this simple kernel module.\nSummary # Need to use use kernel::prelude::*; on top of code. module! macro to define some description and board my own struct to the kernel module. kernel::Module templete functions \u0026hellip;. -WIP- In kernel programming, use alloc::vec::Vec instead std::Vec. pr_info is just same as way to write with C. Reference # https://github.com/Rust-for-Linux/rust-out-of-tree-module https://www.kernel.org/doc/html/latest/kbuild/modules.html https://github.com/Rust-for-Linux/linux https://rust-for-linux.github.io/docs/kernel/prelude/index.html https://rust-for-linux.github.io/docs/kernel/prelude/macro.module.html https://rust-for-linux.github.io/docs/kernel/prelude/struct.Vec.html ","date":"2 October 2022","externalUrl":null,"permalink":"/en/posts/look_into_simple_rust_out_of_tree/","section":"Posts","summary":"In October, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nmodules, out-of-tree # There are two main ways to develop kernel modules. In-Of-Tree and Out-Of-Tree. In this article, we‚Äôre going to make the Out-Of-Tree method a Rust kernel module.\n","title":"[Rust Driver] Let's try build example rust linux driver.","type":"posts"},{"content":"","date":"2 October 2022","externalUrl":null,"permalink":"/en/tags/rust-driver/","section":"Tags","summary":"","title":"Rust Driver","type":"tags"},{"content":"In October 1, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nThis article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\nIntroduction # Currently Apple Silicon mac series is only one ARM workstation that have powerful performance as normal desktop class workstation and can purchase anywhere. Of course if you have 32GB or bigger memory and least 8 big cores of apple silicon.\nBtw, this article is in reference to https://github.com/Rust-for-Linux/linux/blob/rust/Documentation/rust/quick-start.rst .\nVM hypervisor software selection. # UTM : Free / OpenSource, QEMU based Sometimes tricky. VM Fusion Tech Preview : Free for now / ClosedSource, Moderate Parallels : Non-Free / ClosedSource, not my taste (sorry). There\u0026rsquo;s some option working with Asahi Linux. But in this article is not consider native asahi linux environment.\nIn my case, I was chosen VM Fusion.\nVirtual Machine Configuration # Debian 11 : https://cdimage.debian.org/debian-cd/current/arm64/iso-dvd/ !! Checked working well.\nUbuntu : There were some issue clang and other gcc build tools version mismatch than broken apt things in aarch64 ubuntu apt repo. But you can try with ubuntu.\nArch Linux : https://gitlab.archlinux.org/tpowa/archboot/-/wikis/Archboot-Homepage#aarch64-architecture I didn\u0026rsquo;t tested yet. But tested with Asahi linux with M1 Mac Mini\nDebian / Ubuntu Package Requirements # # Install build-requirements for kernel compile with LLVM. apt install clang git llvm-dev libclang-dev build-essential \\ bc kmod cpio flex libncurses5-dev libelf-dev libssl-dev \\ dwarves bison lld curl Asahi Linux Package Requirements # pacman -S base-devel cpio lld llvm llvm-libs bc libdwarf Ready for rust # Before build kernel, we need to install some packages.\ncurl --proto \u0026#39;=https\u0026#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh rustup default 1.62 rustup component add rust-src # rustfmt and clippy is need for later developing and debugging. rustup component add rustfmt rustup component add clippy Install rust with curl. You can select just default options. Also current rust for linux working with 1.62. Some native compile is working well with recent version (1.64 tested, but cross compile not working).\nClone linux from Rust-For-Linux # State of current rust-for-linux, they are under 6.0 RC\n# In my case use `Develop` as worksapce, you can replace this word. mkdir -p ~/Develop cd ~/Develop git clone https://github.com/Rust-for-Linux/linux.git -b rust clone like this.\nNecessary some rust scripts in Rust-For-Linux # In cloned linux directory.\ngit clone --recurse-submodules \\ --branch $(scripts/min-tool-version.sh rustc) \\ https://github.com/rust-lang/rust \\ $(rustc --print sysroot)/lib/rustlib/src/rust This work clone rustlib repository in your rust toolchain directory.\ncargo install --locked --version $(scripts/min-tool-version.sh bindgen) bindgen This work need to bind existing c code to rust code. s\nCheck RUST_AVAILABLE # cd ~/Develop/linux make LLVM=1 rustavailable $ make LLVM=1 rustavailable *** *** Rust compiler \u0026#39;rustc\u0026#39; is too new. This may or may not work. *** Your version: 1.64.0 *** Expected version: 1.62.0 *** Rust is available! Than if you get result like this it\u0026rsquo;s good to go\nConfigure linux source code with menuconfig # make ARCH=arm64 defconfig make menuconfig Disable GCC plugins # General architecture-dependent options -\u0026gt; GCC plugins For now (6.1 rc*), GCC_PLUGINS config should be disabled for RUST_CONFIG config. Be sure disable it.\nGeneral setup -\u0026gt; Rust support # In General setup -\u0026gt; Rust support , Enable this If you don\u0026rsquo;t see the flag, double-check that the make LLVM=1 rustavailable process was successful. For a detailed mailing thread on CONFIG_RUST see here. See details \u0026rharu; Kernel hacking -\u0026gt; Sample kernel code # For easy to develop rust kernel code we need some examples. You can get them with following menus.\nIn Kernel hacking -\u0026gt; Sample kernel code , enable it (not all of them..) when you interest. I don\u0026rsquo;t recommend you enable them when you write own driver. Because there\u0026rsquo;s some possibility make system slow or make unwanted log in dmesg. In particular, the netflitter example outputs too many dmesg, so it is recommended that you disable it unless you are studying the netfilter example. Kernel hacking -\u0026gt; Rust hacking # For debug rust kernel code or driver, need to enable some debug options.\nIn Kernel hacking -\u0026gt; Rust hacking , enables it and inside menus.\nCompile and install it in virtual machine. # # -j4 for 4 core virtual machine, -j2 for 2 core, -j1 for single core. make LLVM=1 -j4 Build with following command. You need to set number of job considering assigned number of cores for virtual machine. (-j#)\nAlso while you build it, it will ask some flag. I just select default in my case.\nIt takes lot of time (don\u0026rsquo;t worry much better than raspberry pi 4), 13~14 minuites takes in my environment (VM 4core, 8GB)\nAfter than, install via following command\n# should be under the root permision. make modules_install make install update-grub It\u0026rsquo;s done!. Reboot program and then check the kernel working well.\nLinux lambda-next 6.0.0-rc7-175589-g542379556669 #2 SMP PREEMPT Sun Oct 2 19:02:32 KST 2022 aarch64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Sun Oct 2 18:20:21 2022 from 192.168.99.1 pmnxis@lambda-next:~$ uname -r 6.0.0-rc7-175589-g542379556669 Simple compile speed comparation. # Machine / Environment Compile time M1 Max Virtual Machine (4 core 8GB RAM with aarch64 debian11) 16 minutes M1 Asahi Linux (4P+4E core 16GB RAM MacMini with 6.1.0-rc6-asahi) 11 minutes AMD Ryzen 5950x Native (16 core 32 thread, 64GB with x86_64) 3 minutes AMD Threadripper Pro 5975wx Native (32 core 64 thread, 256GB with x86_64) 2 minutes ","date":"1 October 2022","externalUrl":null,"permalink":"/en/posts/rust_for_linux_with_m1/","section":"Posts","summary":"In October 1, Rust for linux is under the linux-next, not stable\nThus this article would be out-of-date before Linux 6.1 stable comes.\nThis article play with https://github.com/Rust-for-Linux/linux/tree/for-next/rust\n","title":"Rust For Linux Development Environment with AppleSilicon MacOS","type":"posts"},{"content":" Introduction # ARMv8A, also commonly known as aarch64, is one of the widely used architectures that has largely succeeded ARMv7A. In this article, we will examine the ARMv8A memory system at the IP (Intellectual Property) block level.\nWhile there are slight differences depending on the memory type used (DDR4, LPDDR4, DDR3, LPDDR3, DDR2) and the architecture version (ARM v8.1 or 8.2), the overall structure generally follows the form shown in the diagram above.\nComponents # CPU # Processes instructions.\nGIC # Generic Interrupt Controller; The GIC manages various nested interrupts. When an interrupt occurs, it backs up the PC/registers that were active on the CPU and directs execution to the corresponding interrupt vector.\nCCI / CCN # Cache Coherent Interconnect / Network\nDMC # Manages DRAM. DRAM is volatile memory that requires operations beyond simple Read/Write, such as Refresh and Calibration. Additionally, it handles ECC and RAS management. In the Linux driver codebase, you can find the ECC and RAS management driver code under the edac directory.\nNIC # Used to connect various peripherals.\nMMU # PA/VA (Physical/Virtual Address) translation DMA control Reference # CCI-400 ; https://developer.arm.com/Processors/CoreLink%20CCI-400 CCI-500 ; https://developer.arm.com/Processors/CoreLink%20CCI-500 DMC-400 ; DDR3/DDR2 DMC ; https://developer.arm.com/documentation/ddi0466/f/introduction/about-the-dmc-400 DMC-500 ; LPDDR4/LPDDR3 DMC ; https://developer.arm.com/documentation/100131/0000 ","date":"14 December 2021","externalUrl":null,"permalink":"/en/posts/arm_v8a_memory_ip_review/","section":"Posts","summary":"Introduction # ARMv8A, also commonly known as aarch64, is one of the widely used architectures that has largely succeeded ARMv7A. In this article, we will examine the ARMv8A memory system at the IP (Intellectual Property) block level.\n","title":"ARMv8A Memory IP Review","type":"posts"},{"content":"","date":"14 December 2021","externalUrl":null,"permalink":"/en/tags/electronics/","section":"Tags","summary":"","title":"Electronics","type":"tags"},{"content":"","externalUrl":null,"permalink":"/en/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/en/g-vcbqvyzx51/","section":"G Vcbqvyzx51","summary":"","title":"G Vcbqvyzx51","type":"g-vcbqvyzx51"},{"content":"","externalUrl":null,"permalink":"/en/series/","section":"Series","summary":"","title":"Series","type":"series"}]