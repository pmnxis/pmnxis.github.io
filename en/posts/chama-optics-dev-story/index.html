<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=false><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta name=theme-color><title>Chama Optics Development Story &#183; Jinwoo Park Blog</title><meta name=title content="Chama Optics Development Story &#183; Jinwoo Park Blog"><meta name=description content="EXIF-based photo frame + automatic face detection app, from desktop to mobile with a Rust core"><meta name=keywords content="Rust,iOS,Cross-Platform,EXIF,"><link rel=canonical href=https://pmnxis.github.io/en/posts/chama-optics-dev-story/><meta property="og:url" content="https://pmnxis.github.io/en/posts/chama-optics-dev-story/"><meta property="og:site_name" content="Jinwoo Park Blog"><meta property="og:title" content="Chama Optics Development Story"><meta property="og:description" content="EXIF-based photo frame + automatic face detection app, from desktop to mobile with a Rust core"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-02-14T00:00:00+09:00"><meta property="article:modified_time" content="2026-02-14T00:00:00+09:00"><meta property="article:tag" content="Rust"><meta property="article:tag" content="IOS"><meta property="article:tag" content="Cross-Platform"><meta property="article:tag" content="EXIF"><meta property="og:image" content="https://pmnxis.github.io/en/posts/chama-optics-dev-story/feature.webp"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://pmnxis.github.io/en/posts/chama-optics-dev-story/feature.webp"><meta name=twitter:title content="Chama Optics Development Story"><meta name=twitter:description content="EXIF-based photo frame + automatic face detection app, from desktop to mobile with a Rust core"><meta name=google-site-verification content="VmKxOzBA6bj36Pwan0cjJGtyjeD7hzi9UDxXJ4kCjhI"><link type=text/css rel=stylesheet href=/css/main.bundle.min.b5bc3f4587655153415b7825fd1716f97df9c99f87c23f81146f4dd4f9f49f04ad031e3b5f0ee5c0416707a1455ca2cfa8fc1f3a19ece1486b0126dcd310a63e.css integrity="sha512-tbw/RYdlUVNBW3gl/RcW+X35yZ+Hwj+BFG9N1Pn0nwStAx47Xw7lwEFnB6FFXKLPqPwfOhns4UhrASbc0xCmPg=="><script type=text/javascript src=/js/appearance.min.6f41174b3a05b680820fe08cadbfa5fb7a7ca347b76a0955cdc68b9d8aca1ce24f0547e138cea33bcc7904d551a90afcb1cc7f2d9fe8557075d501419046c08c.js integrity="sha512-b0EXSzoFtoCCD+CMrb+l+3p8o0e3aglVzcaLnYrKHOJPBUfhOM6jO8x5BNVRqQr8scx/LZ/oVXB11QFBkEbAjA=="></script><script src=/lib/zoom/zoom.min.umd.a527109b68c082a70f3697716dd72a9d5aa8b545cf800cecbbc7399f2ca6f6e0ce3e431f2062b48bbfa47c9ea42822714060bef309be073f49b9c0e30d318d7b.js integrity="sha512-pScQm2jAgqcPNpdxbdcqnVqotUXPgAzsu8c5nyym9uDOPkMfIGK0i7+kfJ6kKCJxQGC+8wm+Bz9JucDjDTGNew=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.bdda7dece6cbaf08deef7d254f7f842f3261c2524d247905127c9a20decc03f1011a2950048464c79272c1ce0705a49a41147f39f2b95163bb71d404b33263ef.js integrity="sha512-vdp97ObLrwje730lT3+ELzJhwlJNJHkFEnyaIN7MA/EBGilQBIRkx5Jywc4HBaSaQRR/OfK5UWO7cdQEszJj7w==" data-copy=Copy data-copied=Copied></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"Chama Optics Development Story","headline":"Chama Optics Development Story","description":"EXIF-based photo frame \u002b automatic face detection app, from desktop to mobile with a Rust core","inLanguage":"en","url":"https://pmnxis.github.io/en/posts/chama-optics-dev-story/","author":{"@type":"Person","name":""},"copyrightYear":"2026","dateCreated":"2026-02-14T00:00:00\u002b09:00","datePublished":"2026-02-14T00:00:00\u002b09:00","dateModified":"2026-02-14T00:00:00\u002b09:00","keywords":["Rust","iOS","Cross-Platform","EXIF"],"mainEntityOfPage":"true","wordCount":"7884"}]</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-VCBQVYZX51"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-VCBQVYZX51")</script></head><body class="flex flex-col h-screen m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32 text-lg bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral bf-scrollbar"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 pe-2 dark:text-primary-400">&darr;</span>
Skip to main content</a></div><div class="main-menu flex items-center w-full gap-2 p-1 pl-0"><div><a href=/en/ class=flex><span class=sr-only>Jinwoo Park Blog</span>
<img src=/img/LambdaEE.png width=295 height=182 class="logo max-h-20 max-w-20 object-scale-down object-left nozoom" alt></a></div><a href=/en/ class="text-base font-medium truncate min-w-0 shrink">Jinwoo Park Blog</a><div class="flex items-center ms-auto"><div class="hidden md:flex"><nav class="flex items-center gap-x-5 h-12"><a href=/en/posts/ class="flex items-center bf-icon-color-hover" aria-label=Blog title=Posts><span class="text-base font-medium break-normal">Blog
</span></a><a href=/en/tags/ class="flex items-center bf-icon-color-hover" aria-label=Tags title=Tags><span class="text-base font-medium break-normal">Tags
</span></a><a href=/en/categories/ class="flex items-center bf-icon-color-hover" aria-label=Categories title=Categories><span class="text-base font-medium break-normal">Categories
</span></a><a href=https://github.com/pmnxis target=_blank class="flex items-center bf-icon-color-hover" aria-label=GitHub title><span class="text-base font-medium break-normal">GitHub</span></a><div class="translation nested-menu"><button class="cursor-pointer flex items-center">
<span class=me-1><span class="relative block icon"><svg viewBox="0 0 640 512"><path fill="currentColor" d="M0 128C0 92.7 28.7 64 64 64H256h48 16H576c35.3.0 64 28.7 64 64V384c0 35.3-28.7 64-64 64H320 304 256 64c-35.3.0-64-28.7-64-64V128zm320 0V384H576V128H320zM178.3 175.9c-3.2-7.2-10.4-11.9-18.3-11.9s-15.1 4.7-18.3 11.9l-64 144c-4.5 10.1.1 21.9 10.2 26.4s21.9-.1 26.4-10.2l8.9-20.1h73.6l8.9 20.1c4.5 10.1 16.3 14.6 26.4 10.2s14.6-16.3 10.2-26.4l-64-144zM160 233.2 179 276H141l19-42.8zM448 164c11 0 20 9 20 20v4h44 16c11 0 20 9 20 20s-9 20-20 20h-2l-1.6 4.5c-8.9 24.4-22.4 46.6-39.6 65.4.9.6 1.8 1.1 2.7 1.6l18.9 11.3c9.5 5.7 12.5 18 6.9 27.4s-18 12.5-27.4 6.9L467 333.8c-4.5-2.7-8.8-5.5-13.1-8.5-10.6 7.5-21.9 14-34 19.4l-3.6 1.6c-10.1 4.5-21.9-.1-26.4-10.2s.1-21.9 10.2-26.4l3.6-1.6c6.4-2.9 12.6-6.1 18.5-9.8L410 286.1c-7.8-7.8-7.8-20.5.0-28.3s20.5-7.8 28.3.0l14.6 14.6.5.5c12.4-13.1 22.5-28.3 29.8-45H448 376c-11 0-20-9-20-20s9-20 20-20h52v-4c0-11 9-20 20-20z"/></svg></span>
</span><span class="text-sm font-medium bf-icon-color-hover" title="Chama Optics Development Story">EN</span></button><ul class=menuhide><li class="rounded-xl backdrop-blur shadow-2xl p-2 flex flex-col gap-1"><a href=/ko/posts/chama-optics-dev-story/ class="flex items-center bf-icon-color-hover px-3 py-1"><span class="text-sm font-sm" title="Chama Optics Í∞úÎ∞úÍ∏∞">KO
</span></a><a href=/ja/posts/chama-optics-dev-story/ class="flex items-center bf-icon-color-hover px-3 py-1"><span class="text-sm font-sm" title="Chama Optics ÈñãÁô∫Ë®ò">JA
</span></a><a href=/en/posts/chama-optics-dev-story/ class="flex items-center bf-icon-color-hover px-3 py-1"><span class="text-sm font-sm" title="Chama Optics Development Story">EN</span></a></li></ul></div><button id=search-button aria-label=Search class="text-base bf-icon-color-hover" title="Search (/)">
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base bf-icon-color-hover"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav></div><div class="flex md:hidden"><div class="flex items-center h-14 gap-4"><button id=search-button-mobile aria-label=Search class="flex items-center justify-center bf-icon-color-hover" title="Search (/)">
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile type=button aria-label="Dark mode switcher" class="flex items-center justify-center text-neutral-900 hover:text-primary-600 dark:text-neutral-200 dark:hover:text-primary-400"><div class=dark:hidden><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="hidden dark:block"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button>
<input type=checkbox id=mobile-menu-toggle autocomplete=off class="hidden peer">
<label for=mobile-menu-toggle class="flex items-center justify-center cursor-pointer bf-icon-color-hover"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></label><div role=dialog aria-modal=true style=scrollbar-gutter:stable class="fixed inset-0 z-50 invisible overflow-y-auto px-6 py-20 opacity-0 transition-[opacity,visibility] duration-300 peer-checked:visible peer-checked:opacity-100 bg-neutral-50/97 dark:bg-neutral-900/99
bf-scrollbar"><label for=mobile-menu-toggle class="fixed end-8 top-5 flex items-center justify-center z-50 h-12 w-12 cursor-pointer select-none rounded-full bf-icon-color-hover border bf-border-color bf-border-color-hover bg-neutral-50 dark:bg-neutral-900"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></label><nav class="mx-auto max-w-md space-y-6"><div class=px-2><a href=/en/posts/ aria-label=Blog class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200"><span title=Posts class="text-2xl font-bold tracking-tight">Blog</span></a></div><div class=px-2><a href=/en/tags/ aria-label=Tags class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200"><span title=Tags class="text-2xl font-bold tracking-tight">Tags</span></a></div><div class=px-2><a href=/en/categories/ aria-label=Categories class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200"><span title=Categories class="text-2xl font-bold tracking-tight">Categories</span></a></div><div class=px-2><a href=https://github.com/pmnxis aria-label=GitHub target=_blank class="flex items-center gap-4 group bf-icon-color-hover text-neutral-700 dark:text-neutral-200"><span title class="text-2xl font-bold tracking-tight">GitHub</span></a></div><div class="flex flex-wrap items-center [&_span]:text-2xl [&_.translation_button_.icon]:text-4xl! [&_.translation_button_span]:text-base! [&_.translation_.menuhide_span]:text-sm! gap-x-6 ps-2 mt-8 pt-8 border-t bf-border-color"><div class="translation nested-menu"><button class="cursor-pointer flex items-center">
<span class=me-1><span class="relative block icon"><svg viewBox="0 0 640 512"><path fill="currentColor" d="M0 128C0 92.7 28.7 64 64 64H256h48 16H576c35.3.0 64 28.7 64 64V384c0 35.3-28.7 64-64 64H320 304 256 64c-35.3.0-64-28.7-64-64V128zm320 0V384H576V128H320zM178.3 175.9c-3.2-7.2-10.4-11.9-18.3-11.9s-15.1 4.7-18.3 11.9l-64 144c-4.5 10.1.1 21.9 10.2 26.4s21.9-.1 26.4-10.2l8.9-20.1h73.6l8.9 20.1c4.5 10.1 16.3 14.6 26.4 10.2s14.6-16.3 10.2-26.4l-64-144zM160 233.2 179 276H141l19-42.8zM448 164c11 0 20 9 20 20v4h44 16c11 0 20 9 20 20s-9 20-20 20h-2l-1.6 4.5c-8.9 24.4-22.4 46.6-39.6 65.4.9.6 1.8 1.1 2.7 1.6l18.9 11.3c9.5 5.7 12.5 18 6.9 27.4s-18 12.5-27.4 6.9L467 333.8c-4.5-2.7-8.8-5.5-13.1-8.5-10.6 7.5-21.9 14-34 19.4l-3.6 1.6c-10.1 4.5-21.9-.1-26.4-10.2s.1-21.9 10.2-26.4l3.6-1.6c6.4-2.9 12.6-6.1 18.5-9.8L410 286.1c-7.8-7.8-7.8-20.5.0-28.3s20.5-7.8 28.3.0l14.6 14.6.5.5c12.4-13.1 22.5-28.3 29.8-45H448 376c-11 0-20-9-20-20s9-20 20-20h52v-4c0-11 9-20 20-20z"/></svg></span>
</span><span class="text-sm font-medium bf-icon-color-hover" title="Chama Optics Development Story">EN</span></button><ul class=menuhide><li class="rounded-xl backdrop-blur shadow-2xl p-2 flex flex-col gap-1"><a href=/ko/posts/chama-optics-dev-story/ class="flex items-center bf-icon-color-hover px-3 py-1"><span class="text-sm font-sm" title="Chama Optics Í∞úÎ∞úÍ∏∞">KO
</span></a><a href=/ja/posts/chama-optics-dev-story/ class="flex items-center bf-icon-color-hover px-3 py-1"><span class="text-sm font-sm" title="Chama Optics ÈñãÁô∫Ë®ò">JA
</span></a><a href=/en/posts/chama-optics-dev-story/ class="flex items-center bf-icon-color-hover px-3 py-1"><span class="text-sm font-sm" title="Chama Optics Development Story">EN</span></a></li></ul></div></div></nav></div></div></div></div></div><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Chama Optics Development Story</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2026-02-14T00:00:00+09:00>14 February 2026</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">16 mins</span></div><div class="flex flex-row flex-wrap items-center"><a class="relative mt-[0.5rem] me-2" href=/en/categories/chama-optics/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Chama Optics
</span></span></a><a class="relative mt-[0.5rem] me-2" href=/en/tags/rust/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Rust
</span></span></a><a class="relative mt-[0.5rem] me-2" href=/en/tags/ios/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">IOS
</span></span></a><a class="relative mt-[0.5rem] me-2" href=/en/tags/cross-platform/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Cross-Platform
</span></span></a><a class="relative mt-[0.5rem] me-2" href=/en/tags/exif/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">EXIF</span></span></a></div></div><div class="flex author"><div class=place-self-center><div class="text-2xl sm:text-lg"></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ms-auto px-0 lg:order-last lg:ps-8 lg:max-w-2xs"><div class="toc ps-5 print:hidden lg:sticky lg:top-10"><details open id=TOCView class="toc-right mt-0 overflow-y-auto overscroll-contain bf-scrollbar rounded-lg -ms-5 ps-5 pe-2 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 -ms-5 ps-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted border-s-1 -ms-5 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#project-introduction>Project Introduction</a></li><li><a href=#the-beginning-making-exif-frames-easier>The Beginning: Making EXIF Frames Easier</a></li><li><a href=#change-of-direction-you-cant-take-a-laptop-at-concert-hall>Change of Direction: &ldquo;You Can&rsquo;t Take a Laptop at Concert Hall&rdquo;</a><ul><li><a href=#cultural-differences-at-events--what-i-noticed-at-animenyc-and-east-asia>Cultural Differences at Events &ndash; What I Noticed at AnimeNYC and East Asia</a></li><li><a href=#the-upcoming-hololive-expo>The Upcoming Hololive Expo</a></li><li><a href=#requests-from-others>Requests from Others</a></li></ul></li><li><a href=#architecture-from-desktop-to-mobile>Architecture: From Desktop to Mobile</a></li><li><a href=#why-i-gave-up-on-the-web-version>Why I Gave Up on the Web Version</a><ul><li><a href=#heif-wasm-on-top-of-wasm-with-js-in-between>HEIF: WASM on Top of WASM, with JS in Between</a></li><li><a href=#drag--drop-a-desktop-developers-expectations-vs-reality>Drag & Drop: A Desktop Developer&rsquo;s Expectations vs. Reality</a></li><li><a href=#honestly-i-only-know-c-and-rust>Honestly, I Only Know C and Rust</a></li></ul></li><li><a href=#development-journey-through-the-timeline>Development Journey Through the Timeline</a><ul><li><a href=#v010v011-2025-10-1921--first-pre-release>v0.1.0~v0.1.1 (2025-10-19~21) &ndash; First Pre-release</a></li><li><a href=#v012v016-2025-10-2711-24--theme-expansion-and-watermarks>v0.1.2~v0.1.6 (2025-10-27~11-24) &ndash; Theme Expansion and Watermarks</a></li><li><a href=#v017-2025-11-2612-19--cjk-rendering-improvements-and-open-source-contributions>v0.1.7 (2025-11-26~12-19) &ndash; CJK Rendering Improvements and Open-Source Contributions</a></li><li><a href=#v018-2025-12-2527--ui-renewal-and-performance-improvements>v0.1.8 (2025-12-25~27) &ndash; UI Renewal and Performance Improvements</a></li><li><a href=#v019-2026-01-1802-04--face-detection-lut-and-first-ios-release>v0.1.9 (2026-01-18~02-04) &ndash; Face Detection, LUT, and First iOS Release</a></li></ul></li><li><a href=#technical-challenges-and-solutions>Technical Challenges and Solutions</a><ul><li><a href=#1-cross-platform-ffi-complexity>1. Cross-Platform FFI Complexity</a></li><li><a href=#2-the-endless-variables-of-exif-parsing>2. The Endless Variables of EXIF Parsing</a></li><li><a href=#3-makernote-parsing-extracting-per-manufacturer-shooting-settings>3. MakerNote Parsing: Extracting Per-Manufacturer Shooting Settings</a><ul><li><a href=#exif-ifd-entry-structure-and-makernote-offset-issues>EXIF IFD Entry Structure and MakerNote Offset Issues</a></li></ul></li><li><a href=#4-camera-manufacturer-logo-system-csv-to-buildrs-to-binary-embedding>4. Camera Manufacturer Logo System: CSV to build.rs to Binary Embedding</a><ul><li><a href=#compile-time-svg-download--embedding-from-csv>Compile Time: SVG Download & Embedding from CSV</a></li><li><a href=#runtime-exif-to-logo-matching-to-svg-rasterization>Runtime: EXIF to Logo Matching to SVG Rasterization</a></li></ul></li><li><a href=#5-cjk-font-rendering-and-variable-font-optimization>5. CJK Font Rendering and Variable Font Optimization</a><ul><li><a href=#variable-font-weight-remapping>Variable Font Weight Remapping</a></li><li><a href=#merging-multiple-font-files-into-one--absolute-file-size-reduction>Merging Multiple Font Files into One &ndash; Absolute File Size Reduction</a></li><li><a href=#variable-font-weight-selection-in-egui>Variable Font Weight Selection in egui</a></li><li><a href=#built-in-fonts-and-system-fonts>Built-in Fonts and System Fonts</a></li><li><a href=#debugging-font-kit-macos-memory-explosion>Debugging font-kit macOS Memory Explosion</a></li></ul></li><li><a href=#6-lut-color-grading-wagahai-luts-optimization-philosophy>6. LUT Color Grading: wagahai-lut&rsquo;s Optimization Philosophy</a><ul><li><a href=#what-is-a-cube-lut>What is a CUBE LUT?</a></li><li><a href=#wagahai-luts-optimization-strategy>wagahai-lut&rsquo;s Optimization Strategy</a></li><li><a href=#benchmark-results>Benchmark Results</a></li></ul></li><li><a href=#7-desktop-face-detection-speed-mode-and-sliding-window-algorithm>7. Desktop Face Detection: Speed Mode and Sliding Window Algorithm</a><ul><li><a href=#fastest>Fastest</a></li><li><a href=#fast>Fast</a></li><li><a href=#normal>Normal</a></li><li><a href=#slow>Slow</a></li><li><a href=#slowest>Slowest</a></li></ul></li><li><a href=#8-ios-native-integration>8. iOS Native Integration</a></li><li><a href=#9-mpf-and-embedded-preview-image-extraction>9. MPF and Embedded Preview Image Extraction</a><ul><li><a href=#images-hidden-inside-a-jpeg>Images Hidden Inside a JPEG</a></li><li><a href=#why-mpf-previews-matter-memory-and-performance>Why MPF Previews Matter: Memory and Performance</a></li></ul></li><li><a href=#10-heifheic-decoder-per-platform-strategy>10. HEIF/HEIC Decoder: Per-Platform Strategy</a></li><li><a href=#11-theme-parameter-system-rust-to-json-to-platform-specific-ui>11. Theme Parameter System: Rust to JSON to Platform-Specific UI</a></li><li><a href=#12-multilingual-translation-system-auto-generating-translations-for-3-platforms-from-a-single-yaml>12. Multilingual Translation System: Auto-Generating Translations for 3 Platforms from a Single YAML</a><ul><li><a href=#yaml-the-source-of-truth>YAML: The Source of Truth</a></li><li><a href=#ios-generate_ios_stringssh>iOS: generate_ios_strings.sh</a></li><li><a href=#android-generate_android_stringssh>Android: generate_android_strings.sh</a></li><li><a href=#key-conversion-comparison-across-three-platforms>Key Conversion Comparison Across Three Platforms</a></li></ul></li></ul></li><li><a href=#open-source-contributions>Open-Source Contributions</a></li><li><a href=#release-summary>Release Summary</a></li><li><a href=#programming-with-ai-vibe-coding>Programming with AI (Vibe Coding?)</a></li><li><a href=#future-plans>Future Plans</a></li><li><a href=#references-and-citations>References and Citations</a><ul><li><ul><li><a href=#standards-documents>Standards Documents</a></li><li><a href=#libraries-and-frameworks>Libraries and Frameworks</a></li><li><a href=#reference-materials>Reference Materials</a></li></ul></li></ul></li><li><a href=#special-thanks>Special Thanks</a></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg -ms-5 ps-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 -ms-5 ps-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 border-s-1 -ms-5 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#project-introduction>Project Introduction</a></li><li><a href=#the-beginning-making-exif-frames-easier>The Beginning: Making EXIF Frames Easier</a></li><li><a href=#change-of-direction-you-cant-take-a-laptop-at-concert-hall>Change of Direction: &ldquo;You Can&rsquo;t Take a Laptop at Concert Hall&rdquo;</a><ul><li><a href=#cultural-differences-at-events--what-i-noticed-at-animenyc-and-east-asia>Cultural Differences at Events &ndash; What I Noticed at AnimeNYC and East Asia</a></li><li><a href=#the-upcoming-hololive-expo>The Upcoming Hololive Expo</a></li><li><a href=#requests-from-others>Requests from Others</a></li></ul></li><li><a href=#architecture-from-desktop-to-mobile>Architecture: From Desktop to Mobile</a></li><li><a href=#why-i-gave-up-on-the-web-version>Why I Gave Up on the Web Version</a><ul><li><a href=#heif-wasm-on-top-of-wasm-with-js-in-between>HEIF: WASM on Top of WASM, with JS in Between</a></li><li><a href=#drag--drop-a-desktop-developers-expectations-vs-reality>Drag & Drop: A Desktop Developer&rsquo;s Expectations vs. Reality</a></li><li><a href=#honestly-i-only-know-c-and-rust>Honestly, I Only Know C and Rust</a></li></ul></li><li><a href=#development-journey-through-the-timeline>Development Journey Through the Timeline</a><ul><li><a href=#v010v011-2025-10-1921--first-pre-release>v0.1.0~v0.1.1 (2025-10-19~21) &ndash; First Pre-release</a></li><li><a href=#v012v016-2025-10-2711-24--theme-expansion-and-watermarks>v0.1.2~v0.1.6 (2025-10-27~11-24) &ndash; Theme Expansion and Watermarks</a></li><li><a href=#v017-2025-11-2612-19--cjk-rendering-improvements-and-open-source-contributions>v0.1.7 (2025-11-26~12-19) &ndash; CJK Rendering Improvements and Open-Source Contributions</a></li><li><a href=#v018-2025-12-2527--ui-renewal-and-performance-improvements>v0.1.8 (2025-12-25~27) &ndash; UI Renewal and Performance Improvements</a></li><li><a href=#v019-2026-01-1802-04--face-detection-lut-and-first-ios-release>v0.1.9 (2026-01-18~02-04) &ndash; Face Detection, LUT, and First iOS Release</a></li></ul></li><li><a href=#technical-challenges-and-solutions>Technical Challenges and Solutions</a><ul><li><a href=#1-cross-platform-ffi-complexity>1. Cross-Platform FFI Complexity</a></li><li><a href=#2-the-endless-variables-of-exif-parsing>2. The Endless Variables of EXIF Parsing</a></li><li><a href=#3-makernote-parsing-extracting-per-manufacturer-shooting-settings>3. MakerNote Parsing: Extracting Per-Manufacturer Shooting Settings</a><ul><li><a href=#exif-ifd-entry-structure-and-makernote-offset-issues>EXIF IFD Entry Structure and MakerNote Offset Issues</a></li></ul></li><li><a href=#4-camera-manufacturer-logo-system-csv-to-buildrs-to-binary-embedding>4. Camera Manufacturer Logo System: CSV to build.rs to Binary Embedding</a><ul><li><a href=#compile-time-svg-download--embedding-from-csv>Compile Time: SVG Download & Embedding from CSV</a></li><li><a href=#runtime-exif-to-logo-matching-to-svg-rasterization>Runtime: EXIF to Logo Matching to SVG Rasterization</a></li></ul></li><li><a href=#5-cjk-font-rendering-and-variable-font-optimization>5. CJK Font Rendering and Variable Font Optimization</a><ul><li><a href=#variable-font-weight-remapping>Variable Font Weight Remapping</a></li><li><a href=#merging-multiple-font-files-into-one--absolute-file-size-reduction>Merging Multiple Font Files into One &ndash; Absolute File Size Reduction</a></li><li><a href=#variable-font-weight-selection-in-egui>Variable Font Weight Selection in egui</a></li><li><a href=#built-in-fonts-and-system-fonts>Built-in Fonts and System Fonts</a></li><li><a href=#debugging-font-kit-macos-memory-explosion>Debugging font-kit macOS Memory Explosion</a></li></ul></li><li><a href=#6-lut-color-grading-wagahai-luts-optimization-philosophy>6. LUT Color Grading: wagahai-lut&rsquo;s Optimization Philosophy</a><ul><li><a href=#what-is-a-cube-lut>What is a CUBE LUT?</a></li><li><a href=#wagahai-luts-optimization-strategy>wagahai-lut&rsquo;s Optimization Strategy</a></li><li><a href=#benchmark-results>Benchmark Results</a></li></ul></li><li><a href=#7-desktop-face-detection-speed-mode-and-sliding-window-algorithm>7. Desktop Face Detection: Speed Mode and Sliding Window Algorithm</a><ul><li><a href=#fastest>Fastest</a></li><li><a href=#fast>Fast</a></li><li><a href=#normal>Normal</a></li><li><a href=#slow>Slow</a></li><li><a href=#slowest>Slowest</a></li></ul></li><li><a href=#8-ios-native-integration>8. iOS Native Integration</a></li><li><a href=#9-mpf-and-embedded-preview-image-extraction>9. MPF and Embedded Preview Image Extraction</a><ul><li><a href=#images-hidden-inside-a-jpeg>Images Hidden Inside a JPEG</a></li><li><a href=#why-mpf-previews-matter-memory-and-performance>Why MPF Previews Matter: Memory and Performance</a></li></ul></li><li><a href=#10-heifheic-decoder-per-platform-strategy>10. HEIF/HEIC Decoder: Per-Platform Strategy</a></li><li><a href=#11-theme-parameter-system-rust-to-json-to-platform-specific-ui>11. Theme Parameter System: Rust to JSON to Platform-Specific UI</a></li><li><a href=#12-multilingual-translation-system-auto-generating-translations-for-3-platforms-from-a-single-yaml>12. Multilingual Translation System: Auto-Generating Translations for 3 Platforms from a Single YAML</a><ul><li><a href=#yaml-the-source-of-truth>YAML: The Source of Truth</a></li><li><a href=#ios-generate_ios_stringssh>iOS: generate_ios_strings.sh</a></li><li><a href=#android-generate_android_stringssh>Android: generate_android_strings.sh</a></li><li><a href=#key-conversion-comparison-across-three-platforms>Key Conversion Comparison Across Three Platforms</a></li></ul></li></ul></li><li><a href=#open-source-contributions>Open-Source Contributions</a></li><li><a href=#release-summary>Release Summary</a></li><li><a href=#programming-with-ai-vibe-coding>Programming with AI (Vibe Coding?)</a></li><li><a href=#future-plans>Future Plans</a></li><li><a href=#references-and-citations>References and Citations</a><ul><li><ul><li><a href=#standards-documents>Standards Documents</a></li><li><a href=#libraries-and-frameworks>Libraries and Frameworks</a></li><li><a href=#reference-materials>Reference Materials</a></li></ul></li></ul></li><li><a href=#special-thanks>Special Thanks</a></li></ul></nav></div></details></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><blockquote><p>EXIF-based photo frame + automatic face detection app, from desktop to mobile with a Rust core</p></blockquote><p>This is probably the first time I&rsquo;ve openly written an otaku-ish post on this blog.
Honestly, I started writing this quite a while ago, but I couldn&rsquo;t figure out whether to target the audience as developers or VTuber otaku.
In the end, I decided to just go with the flow and list everything I developed and contributed.</p><p>This blog has mainly covered Rust Embedded topics, and I previously worked on a Rust Embedded mass-production project called <a href=https://github.com/pmnxis/billmock-app-rs target=_blank rel=noreferrer>billmock-app-rs</a>.</p><p>This post introduces the development journey of <a href=https://github.com/pmnxis/chama-optics target=_blank rel=noreferrer>Chama Optics</a>.</p><p>The official release of <strong>0.2.0</strong> for iOS / Android / macOS / Linux / Windows is planned for the last week of February 2026, and this article covers the development process before App Store and Google Play approval.</p><blockquote><p>üåê <a href=/ko/posts/chama-optics-dev-story/>ÌïúÍµ≠Ïñ¥ ÏïÑÌã∞ÌÅ¥</a> | <a href=/ja/posts/chama-optics-dev-story/>Êó•Êú¨Ë™û„Ç¢„Éº„ÉÜ„Ç£„ÇØ„É´</a></p></blockquote><hr><h2 class="relative group">Project Introduction<div id=project-introduction class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#project-introduction aria-label=Anchor>#</a></span></h2><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=auto alt="Chama Optics" width=1280 height=720 src=/en/posts/chama-optics-dev-story/haachama-optics_hu_c9db7982d9164695.webp srcset="/en/posts/chama-optics-dev-story/haachama-optics_hu_c9db7982d9164695.webp 800w, /en/posts/chama-optics-dev-story/haachama-optics.webp 1280w" sizes="(min-width: 768px) 50vw, 65vw" data-zoom-src=/en/posts/chama-optics-dev-story/haachama-optics.webp></figure></p><p><strong>Chama Optics</strong> is a photo post-processing application that analyzes EXIF data from photos taken with DSLR/mirrorless cameras, applies various themed frames, and adds effects such as watermarks, mosaics, and stickers. The name &ldquo;Chama&rdquo; is derived from the nickname of travel VTuber Akai Haato (Ëµ§‰∫ï„ÅØ„ÅÇ„Å®).</p><p>I&rsquo;ve gone through countless mobile devices, but my interest has always been on the <strong>making</strong> side of electronics, and I was far from smartphone app development. As a fan of Hololive JP 1st Generation member Akai Haato (HAACHAMA), my otaku life led me to start my first project in a software development domain outside of embedded systems.</p><p>I first conceptualized this program in March 2025.
At the time, I wanted it to run as a web app, and I was testing libraries, the WASM environment, and porting libheif.
In August 2025, after attending Amane Kanata&rsquo;s solo live LOCK-ON in Tokyo, Japan, and the AnimeNYC World Tour + EN Concert (All for one) in New York, USA, I keenly felt the need to quickly organize photos, compress them to WEBP, and post them.
At the same time, Akai Haato had recently taken a liking to photography &ndash; showing the camera she uses in membership-only posts and encouraging photo posting on <a href=https://x.com/hashtag/%E6%8E%A8%E3%81%97%E6%B4%BB%E3%81%AF%E3%81%82%E3%81%A8%E3%82%93%E6%97%A5%E8%A8%98 target=_blank rel=noreferrer>#Êé®„ÅóÊ¥ª„ÅØ„ÅÇ„Å®„ÇìÊó•Ë®ò</a> (Oshikatsu Haaton Diary). I wanted to develop an app under the Haato (HAACHAMA) name for her.</p><table><thead><tr><th>Recent 3D Live</th><th>Akai Haato X(twitter)</th></tr></thead><tbody><tr><td><blockquote class=twitter-tweet><p lang=ja dir=ltr>/Ôºè<br>üì¢ Êú¨Êó•ÔºíÔºëÔºöÔºêÔºê„Åã„Çâ‚ÄºÔ∏è<br>\Ôºº<br><br>Ëµ§‰∫ï„ÅØ„ÅÇ„Å®ÁîüË™ï3D LIVEÈñãÂÇ¨!!üéä<br><br>üéÅ„ÉÜ„Éº„Éû„ÅØ„Éõ„É©„Éº‚ÅâÔ∏è<br>üéÅ„Ç≤„Çπ„ÉàÂ§öÊï∞&ÂëäÁü•„ÅÇ„Çä‚óé<br>üéÅÊºîÂá∫„ÅØ„Åì„Å†„Çè„ÇäÊ∫ÄÂ§©ü•≥<br><br>„ÉÄ„É≥„Çπ„ÇÑÊ≠å„ÇÇÁ≤æ‰∏ÄÊùØ„Åå„Çì„Å∞„Å£„Åü„ÅÆ„Åß<br>„Åø„Çì„Å™ÊòØÈùûÔºÅË¶ã„Å´Êù•„Å¶„Å≠„Å£‚ùïüëÄ‚ú®<a href="https://twitter.com/hashtag/%E8%B5%A4%E4%BA%95%E3%81%AF%E3%81%82%E3%81%A8%E7%88%86%E8%AA%95%E7%A5%AD2025?src=hash&amp;ref_src=twsrc%5Etfw">#Ëµ§‰∫ï„ÅØ„ÅÇ„Å®ÁàÜË™ïÁ•≠2025</a><br><br>„ÄêÈñãÂÇ¨Â†¥ÊâÄ„Äë<a href=https://t.co/3IUA2stYWi>https://t.co/3IUA2stYWi</a>‚Ä¶ <a href=https://t.co/A1OqUBCbsM>pic.twitter.com/A1OqUBCbsM</a></p>&mdash; Ëµ§‰∫ï„ÅØ„ÅÇ„Å®‚ù§Ô∏è‚Äçüî•ÊóÖ„Åô„Çã„Ç¢„Ç§„Éâ„É´ (@akaihaato) <a href="https://twitter.com/akaihaato/status/1954294114519851374?ref_src=twsrc%5Etfw">August 9, 2025</a></blockquote><script async src=https://platform.twitter.com/widgets.js></script></td><td><blockquote class=twitter-tweet><p lang=ja dir=ltr>Âõõ‰∏áÊ∏©Ê≥â„Çπ„ÉÜ„Ç≠„Å™Â†¥ÊâÄ„Åß„Åó„Åü„ÄÇ<br>„Åê„Çì„Åæ„ÉºÂ∏ùÂõΩ„ÄÅ„ÅÇ„Çä„Åå„Å®„Çì‚ù§Ô∏è‚Äçüî• <a href=https://t.co/Ov0CwFRF7V>pic.twitter.com/Ov0CwFRF7V</a></p>&mdash; Ëµ§‰∫ï„ÅØ„ÅÇ„Å®‚ù§Ô∏è‚Äçüî•ÊóÖ„Åô„Çã„Ç¢„Ç§„Éâ„É´ (@akaihaato) <a href="https://twitter.com/akaihaato/status/1916078150804799563?ref_src=twsrc%5Etfw">April 26, 2025</a></blockquote><script async src=https://platform.twitter.com/widgets.js></script></td></tr></tbody></table><p>When developing the program, I adhered to these principles:</p><ul><li>There must be no architectural discrimination across desktop platforms.</li><li>It must be minimally tied to MS or Apple&rsquo;s development ecosystems.</li><li>It must not use many resources and must be fast.</li></ul><p>These goals might sound grandiose, but really I&rsquo;m just a Rust enthusiast and that&rsquo;s why these are the goals.</p><hr><h2 class="relative group">The Beginning: Making EXIF Frames Easier<div id=the-beginning-making-exif-frames-easier class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#the-beginning-making-exif-frames-easier aria-label=Anchor>#</a></span></h2><p>I didn&rsquo;t plan a grand cross-platform app from the start.</p><p>Among camera enthusiasts, there&rsquo;s a culture of sharing photos with frames that display camera model, lens, shutter speed, and other information based on EXIF data. I enjoyed this practice too, and had been referencing a web-based tool called <a href=https://github.com/jeonghyeon-net/exif-frame target=_blank rel=noreferrer>exif-frame</a>. However, I was frustrated by its lack of HEIF format support and limitations with high-resolution image output, so the idea to build it myself is what sparked Chama Optics.</p><p>Initially, I only considered <strong>desktop use</strong>. I had vague thoughts about mobile, but since I always carried my MacBook around even when traveling, mobile wasn&rsquo;t on my radar at all. Pulling the SD card from the camera, organizing photos on the MacBook, applying frames, and uploading &ndash; that workflow was second nature.</p><hr><h2 class="relative group">Change of Direction: &ldquo;You Can&rsquo;t Take a Laptop at Concert Hall&rdquo;<div id=change-of-direction-you-cant-take-a-laptop-at-concert-hall class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#change-of-direction-you-cant-take-a-laptop-at-concert-hall aria-label=Anchor>#</a></span></h2><p>Two things prompted the change in direction.</p><h3 class="relative group">Cultural Differences at Events &ndash; What I Noticed at AnimeNYC and East Asia<div id=cultural-differences-at-events--what-i-noticed-at-animenyc-and-east-asia class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#cultural-differences-at-events--what-i-noticed-at-animenyc-and-east-asia aria-label=Anchor>#</a></span></h3><p>In August 2025, I visited the US for <strong>AnimeNYC</strong> and the <strong>Hololive World Tour / EN Concert</strong>. I noticed an interesting difference there. In the US, people tended <strong>not to mosaic other people&rsquo;s faces</strong> when posting event photos. But at events in Korea and Japan, <strong>mosaicing other people&rsquo;s faces is considered proper etiquette and an unspoken rule</strong>.</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=auto alt="AnimeNYC event photo example" width=4072 height=2852 src=/en/posts/chama-optics-dev-story/P1090028-OPTICS_hu_8d712446ebc299fb.webp srcset="/en/posts/chama-optics-dev-story/P1090028-OPTICS_hu_8d712446ebc299fb.webp 800w, /en/posts/chama-optics-dev-story/P1090028-OPTICS_hu_b596c2480f9c7781.webp 1280w" sizes="(min-width: 768px) 50vw, 65vw" data-zoom-src=/en/posts/chama-optics-dev-story/P1090028-OPTICS.webp></figure></p><p>&ldquo;Mosaicing other people&rsquo;s faces&rdquo; is too tedious to do manually every time. Especially when you have dozens or hundreds of photos. The thought that <strong>automatic face detection + mosaic/sticker functionality</strong> was needed started to weigh heavily from this point.</p><h3 class="relative group">The Upcoming Hololive Expo<div id=the-upcoming-hololive-expo class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#the-upcoming-hololive-expo aria-label=Anchor>#</a></span></h3><p>Another motivator was the <strong>Hololive Expo/Festival in March 2026</strong>. What if you could take photos at the venue, apply frames on the spot, process mosaics, and post to social media right there? But you can&rsquo;t open a MacBook at an event. <strong>It had to be processable directly on a smartphone.</strong></p><h3 class="relative group">Requests from Others<div id=requests-from-others class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#requests-from-others aria-label=Anchor>#</a></span></h3><p>On top of this, people around me started <strong>requesting an iOS version</strong>. So I started developing for iOS, and then <strong>requests for an Android version</strong> came in too.</p><p>This is how a desktop-only program expanded to support iOS and eventually Android. For mobile, the design direction shifted to consider the <strong>general user experience</strong> more than mirrorless camera users. The starting point of EXIF frames remained, but a new use case was added: &ldquo;quickly processing and sharing photos on-site at events.&rdquo;</p><hr><h2 class="relative group">Architecture: From Desktop to Mobile<div id=architecture-from-desktop-to-mobile class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#architecture-from-desktop-to-mobile aria-label=Anchor>#</a></span></h2><p>Originally, I planned to build only a desktop app with Rust + egui. Writing all the core logic in Rust turned out to be a great decision. When expanding to iOS/Android, I was able to <strong>reuse the core code for image processing, EXIF parsing, theme rendering, and encoding/decoding as-is</strong>.</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="ChamaOptics Architecture" src=/en/posts/chama-optics-dev-story/architecture_layers.svg></figure></p><p>On desktop, the Rust core is used via <strong>direct linking</strong>. On iOS, it&rsquo;s <strong>called from Swift via C FFI</strong>. On Android, it&rsquo;s <strong>called from Kotlin via JNA (Java Native Access)</strong>. The Rust core is managed as a git submodule, and core features like EXIF interpretation, image overlays (text, EXIF, margins, scaling, encoding/decoding) are shared across all platforms.</p><p>However, face detection uses a different strategy per platform:</p><ul><li><strong>Desktop (macOS/Windows/Linux)</strong>: ONNX Runtime + InsightFace (SCRFD det_10g) model. Depending on Speed Mode, a sliding window with a fixed 640x640 input size is applied in multiple stages (2560/1280/640) to detect even small faces, with NMS to remove duplicates.</li><li><strong>iOS</strong>: Uses Apple Vision Framework natively. Fast and accurate without ONNX models, and favorable for privacy.</li><li><strong>Android</strong>: Uses Google ML Kit (<code>com.google.mlkit:face-detection</code>) &ndash; Google&rsquo;s on-device face detection library, mapping Rust core&rsquo;s speed_mode to FAST/ACCURATE performance modes.</li></ul><hr><h2 class="relative group">Why I Gave Up on the Web Version<div id=why-i-gave-up-on-the-web-version class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#why-i-gave-up-on-the-web-version aria-label=Anchor>#</a></span></h2><p>I&rsquo;m not well-versed in web apps or how the web and browsers work. Despite that, Chama Optics was initially <strong>designed with Web (WASM) in mind.</strong> Since egui supports WASM, I had a vague expectation that &ldquo;desktop and web could work simultaneously.&rdquo; But I gave up after trying to implement these two features:</p><ul><li><strong>HEIF decoding</strong></li><li><strong>Drag & Drop in egui Web</strong></li></ul><h3 class="relative group">HEIF: WASM on Top of WASM, with JS in Between<div id=heif-wasm-on-top-of-wasm-with-js-in-between class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#heif-wasm-on-top-of-wasm-with-js-in-between aria-label=Anchor>#</a></span></h3><p>Before the difficulty of running libheif in the browser, the fundamental architecture didn&rsquo;t make sense to me. libheif is already compiled to WASM, and the egui app is also WASM. The fact that communication between these two had to go through <strong>JavaScript-based FFI multiple times</strong> didn&rsquo;t sit right with me. Most cross-language FFI is done through C, so I couldn&rsquo;t understand why the JS ecosystem required this approach.</p><h3 class="relative group">Drag & Drop: A Desktop Developer&rsquo;s Expectations vs. Reality<div id=drag--drop-a-desktop-developers-expectations-vs-reality class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#drag--drop-a-desktop-developers-expectations-vs-reality aria-label=Anchor>#</a></span></h3><p>Beyond Drag & Drop, I expected WASM to receive events from the browser in ways more typical of desktop/embedded development &ndash; like receiving the DOM in binary form rather than through JS &ndash; but that wasn&rsquo;t the case.</p><h3 class="relative group">Honestly, I Only Know C and Rust<div id=honestly-i-only-know-c-and-rust class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#honestly-i-only-know-c-and-rust aria-label=Anchor>#</a></span></h3><p>I <strong>only know C and Rust.</strong> In other words, I&rsquo;m either completely ignorant about web development, or I&rsquo;ve done it in very bizarre ways in the past.</p><p>Once I had to display a large amount of data on the web, and since I didn&rsquo;t know how, I created the data as CSV, then used a <strong>hex editor to do a bulk find-and-replace</strong> of <code>,</code> and <code>\n</code> with HTML tags like <code>&lt;div></code> to create a static website and deployed it. With 25% of the 21st century already behind us, even I thought &ldquo;what am I doing?&rdquo;</p><p>Of course, since WASM is web technology, following the web ecosystem and its conventions is the norm. But since I&rsquo;m not a web developer, I couldn&rsquo;t get on board. I was <strong>very far removed from the JS/Web ecosystem</strong>, and building native mobile apps felt far more natural than overcoming these fundamental differences in development philosophy. In v0.1.9-beta, I officially removed WASM support and directed that energy toward iOS/Android native development.</p><hr><h2 class="relative group">Development Journey Through the Timeline<div id=development-journey-through-the-timeline class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#development-journey-through-the-timeline aria-label=Anchor>#</a></span></h2><h3 class="relative group">v0.1.0~v0.1.1 (2025-10-19~21) &ndash; First Pre-release<div id=v010v011-2025-10-1921--first-pre-release class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#v010v011-2025-10-1921--first-pre-release aria-label=Anchor>#</a></span></h3><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="v0.1.0 screenshot" src=https://github.com/user-attachments/assets/2471db65-8b0b-44e4-9d2b-31701184878e></figure></p><p>First binary release for macOS/Windows. Film theme frame, Japanese translation, batch save, filename prefix/suffix settings. macOS code-signed DMG distribution and Korean/English/Japanese installation guide wiki.</p><h3 class="relative group">v0.1.2~v0.1.6 (2025-10-27~11-24) &ndash; Theme Expansion and Watermarks<div id=v012v016-2025-10-2711-24--theme-expansion-and-watermarks class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#v012v016-2025-10-2711-24--theme-expansion-and-watermarks aria-label=Anchor>#</a></span></h3><table><thead><tr><th style=text-align:center>Film Date Theme</th><th style=text-align:center>Strap Theme</th><th style=text-align:center>Monitor Theme</th><th style=text-align:center>Lightroom Theme</th></tr></thead><tbody><tr><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="Film Date" src=https://github.com/user-attachments/assets/a6bf0e51-d3b1-4779-9d65-080b225958f4></figure></td><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt=Strap src=https://github.com/user-attachments/assets/039ab49f-85b1-414b-95e3-2da166cea27f></figure></td><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt=Monitor src=https://github.com/user-attachments/assets/e92b81a0-4465-4dad-9097-7e8b4814fc15></figure></td><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt=Lightroom src=https://github.com/user-attachments/assets/ce1022cd-aea3-4260-9d5f-5e15997388de></figure></td></tr></tbody></table><p>Added Film Date/Film Glow/Just Frame/Strap/Monitor/Lightroom themes. Watermark (9 positions, opacity, blend mode), font selection (built-in + OS fonts), automatic camera manufacturer logo, HEIF orientation fix, initial variable font support, Longside scale option.</p><h3 class="relative group">v0.1.7 (2025-11-26~12-19) &ndash; CJK Rendering Improvements and Open-Source Contributions<div id=v017-2025-11-2612-19--cjk-rendering-improvements-and-open-source-contributions class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#v017-2025-11-2612-19--cjk-rendering-improvements-and-open-source-contributions aria-label=Anchor>#</a></span></h3><table><thead><tr><th style=text-align:center>One Line Theme</th><th style=text-align:center>Shot On Two Line Theme</th></tr></thead><tbody><tr><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="One Line" src=https://github.com/user-attachments/assets/337337f3-7c17-467a-b965-06481cba98c8></figure></td><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="Shot On 2" src=https://github.com/user-attachments/assets/a9ba4540-6540-418c-8e21-4f9961d7bff7></figure></td></tr></tbody></table><table><thead><tr><th style=text-align:center>Nikon PhotoStyle</th><th style=text-align:center>Lumix Photo Style + LUT</th></tr></thead><tbody><tr><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt=Nikon src=https://github.com/user-attachments/assets/28016fd2-2d4d-4043-88e1-c29f7577a32a></figure></td><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt=Lumix src=https://github.com/user-attachments/assets/62219e6a-c6cb-49ac-9803-cda29321b998></figure></td></tr></tbody></table><p>One Line/Two Line/Shot On themes. Major CJK glyph rendering improvements with SourceHanSans fallback built-in. Submitted a PR to <a href=https://github.com/kamadak/exif-rs target=_blank rel=noreferrer>exif-rs</a> to extract Lumix LUT and Nikon PhotoStyle names from EXIF, pre-applied before merge.</p><h3 class="relative group">v0.1.8 (2025-12-25~27) &ndash; UI Renewal and Performance Improvements<div id=v018-2025-12-2527--ui-renewal-and-performance-improvements class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#v018-2025-12-2527--ui-renewal-and-performance-improvements aria-label=Anchor>#</a></span></h3><table><thead><tr><th style=text-align:center>Image List Tab</th><th style=text-align:center>Theme Settings Tab</th></tr></thead><tbody><tr><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt=Tab1 src=https://github.com/user-attachments/assets/798d9c93-833a-4e9f-876d-ee3fe7182dab></figure></td><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt=Tab2 src=https://github.com/user-attachments/assets/4dd969fa-6f75-4f73-8c8a-f89ac66e1b1b></figure></td></tr></tbody></table><p>Tab-based interface (4 tabs), EXIF variable auto-completion, automatic image grouping, 2MP MPF preview-based theme previews, Rayon multi-core parallel processing, system font loading memory issue fix. Also submitted a PR to <a href=https://github.com/emilk/egui target=_blank rel=noreferrer>egui</a>.</p><h3 class="relative group">v0.1.9 (2026-01-18~02-04) &ndash; Face Detection, LUT, and First iOS Release<div id=v019-2026-01-1802-04--face-detection-lut-and-first-ios-release class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#v019-2026-01-1802-04--face-detection-lut-and-first-ios-release aria-label=Anchor>#</a></span></h3><table><thead><tr><th style=text-align:center>Face Detection (Desktop)</th><th style=text-align:center>Mosaic Applied</th></tr></thead><tbody><tr><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="Face Detection" src=https://github.com/user-attachments/assets/a038cdaa-f755-4d8f-97c9-71f57004e739></figure></td><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt=Mosaic src=https://github.com/user-attachments/assets/6ed05280-1980-448a-9243-aff0836d2470></figure></td></tr></tbody></table><table><thead><tr><th style=text-align:center>Color Grading UI</th><th style=text-align:center>LUT Applied Result</th></tr></thead><tbody><tr><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="LUT UI" src=https://github.com/user-attachments/assets/554f96b2-217a-4603-93f5-1df41309f77e></figure></td><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="LUT Result" src=https://github.com/user-attachments/assets/4d49174c-2624-4b3c-a8a1-fc2b56d357c1></figure></td></tr></tbody></table><table><thead><tr><th style=text-align:center>iOS Gallery</th><th style=text-align:center>iOS Editing</th></tr></thead><tbody><tr><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=auto alt=Gallery width=2412 height=1311 src=/en/posts/chama-optics-dev-story/previews-d2OPTICS_hu_1ac30e400eb3a375.webp srcset="/en/posts/chama-optics-dev-story/previews-d2OPTICS_hu_1ac30e400eb3a375.webp 800w, /en/posts/chama-optics-dev-story/previews-d2OPTICS_hu_92f7456d73efcbec.webp 1280w" sizes="(min-width: 768px) 50vw, 65vw" data-zoom-src=/en/posts/chama-optics-dev-story/previews-d2OPTICS.webp></figure></td><td style=text-align:center><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=auto alt=Editor width=2412 height=1311 src=/en/posts/chama-optics-dev-story/color-themes-d2OPTICS_hu_d6a28de598a9adb.webp srcset="/en/posts/chama-optics-dev-story/color-themes-d2OPTICS_hu_d6a28de598a9adb.webp 800w, /en/posts/chama-optics-dev-story/color-themes-d2OPTICS_hu_e12507295bd67776.webp 1280w" sizes="(min-width: 768px) 50vw, 65vw" data-zoom-src=/en/posts/chama-optics-dev-story/color-themes-d2OPTICS.webp></figure></td></tr></tbody></table><p>The last desktop-only release and the first iOS app release. ONNX (InsightFace) face detection + mosaic/stroke/sticker overlays. 1D/3D LUT color grading (<a href=https://github.com/pmnxis/wagahai-lut target=_blank rel=noreferrer>wagahai-lut</a>). iOS uses SwiftUI + Vision Framework native face detection, with a Rust FFI bridge (<code>ffi_ios.rs</code> + <code>RustBridge.swift</code>). Indonesian translation added.</p><hr><h2 class="relative group">Technical Challenges and Solutions<div id=technical-challenges-and-solutions class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#technical-challenges-and-solutions aria-label=Anchor>#</a></span></h2><p>Let me first summarize the performance strategies applied throughout the project:</p><ul><li><strong>Rayon parallel processing</strong> &ndash; Multi-core utilization for batch image export. However, for pixel-level processing like color correction, parallelization with <code>par_chunks_exact_mut()</code> is applied only when the image exceeds 100,000 pixels; smaller images use sequential processing to avoid context-switching overhead.</li><li><strong><code>fast_image_resize</code>-based resizing</strong> &ndash; Instead of the <code>image</code> crate&rsquo;s default resize, SIMD-optimized <code>fast_image_resize</code> significantly improves thumbnail generation and preview resizing speed.</li><li><strong>Lazy loading and caching</strong> &ndash; LUT files are parsed and cached in <code>lut_cache: HashMap&lt;Uuid, CubeLut></code> on first use, and EXIF thumbnails are lazy-loaded into <code>thumbnail_cache</code>. When cloning for background threads (<code>clone_for_thread()</code>), the cache is excluded to prevent unnecessary memory duplication.</li><li><strong>Perceptual hash-based image grouping</strong> &ndash; On image load, an 8x8 grayscale average hash (64-bit) is pre-computed, enabling subsequent similar image grouping via Hamming distance O(1) comparison. Grouping is done using only metadata without reloading original images.</li><li><strong>Build profile optimization</strong> &ndash; Release builds use <code>opt-level = 3</code>, <code>lto = "fat"</code>, <code>codegen-units = 1</code>. Even in Dev builds, performance-sensitive dependencies like <code>fast_image_resize</code>, <code>mozjpeg</code>, and <code>ab_glyph</code> are individually set to <code>opt-level = 3</code> to maintain image processing performance during debugging.</li></ul><h3 class="relative group">1. Cross-Platform FFI Complexity<div id=1-cross-platform-ffi-complexity class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#1-cross-platform-ffi-complexity aria-label=Anchor>#</a></span></h3><p>Different FFI strategies were adopted to use the Rust core across three platforms (desktop/iOS/Android):</p><table><thead><tr><th style=text-align:left>Platform</th><th style=text-align:left>FFI Method</th><th style=text-align:left>Characteristics</th></tr></thead><tbody><tr><td style=text-align:left>Desktop (egui)</td><td style=text-align:left>Direct Linking</td><td style=text-align:left>Rust to Rust, no FFI needed</td></tr><tr><td style=text-align:left>iOS (SwiftUI)</td><td style=text-align:left>C FFI (<code>@_silgen_name</code>)</td><td style=text-align:left>Direct C function calls from Swift</td></tr><tr><td style=text-align:left>Android (Compose)</td><td style=text-align:left>JNA (Java Native Access)</td><td style=text-align:left>.so invocation from Kotlin via JNA</td></tr></tbody></table><p>The main challenge was maintaining this bridge layer while ensuring stable memory management (string allocation/deallocation, opaque pointer handle patterns).</p><h3 class="relative group">2. The Endless Variables of EXIF Parsing<div id=2-the-endless-variables-of-exif-parsing class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#2-the-endless-variables-of-exif-parsing aria-label=Anchor>#</a></span></h3><p>EXIF recording methods differ across cameras:</p><ul><li><strong>Shutter speed / F-value floating-point issues</strong> &ndash; Cases where 1/125 sec is recorded as a messy value like <code>0.008000000</code>, requiring automatic correction</li><li><strong>HEIF/HEIC orientation errors</strong> &ndash; Orientation being incorrect in some images</li><li><strong>Cameras without lens information</strong> &ndash; Handling compact cameras like Nikon Coolpix</li><li><strong>Information hidden in MakerNote</strong> &ndash; Parsing vendor-specific non-public EXIF fields like Lumix LUT names, Nikon PhotoStyle, Sony Creative Look</li></ul><p>For this, I submitted PRs directly to the <a href=https://github.com/kamadak/exif-rs target=_blank rel=noreferrer>exif-rs</a> library to add the needed functionality.</p><h3 class="relative group">3. MakerNote Parsing: Extracting Per-Manufacturer Shooting Settings<div id=3-makernote-parsing-extracting-per-manufacturer-shooting-settings class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#3-makernote-parsing-extracting-per-manufacturer-shooting-settings aria-label=Anchor>#</a></span></h3><p>Recent mirrorless cameras have excellent built-in color grading features. Lumix&rsquo;s Photo Style, Nikon&rsquo;s Picture Control, Sony&rsquo;s Creative Look, and so on. Among photographers, &ldquo;which color setting was used&rdquo; is as important as the camera model or lens, and I thought it would be great to include this information in the frame.</p><p>The <a href=https://www.cipa.jp/std/documents/download_e.html?DC-008-Translation-2023-E target=_blank rel=noreferrer>EXIF standard</a>&rsquo;s <strong>MakerNote</strong> (Tag 0x927C) is a non-standard area that camera manufacturers can use freely. The format differs between manufacturers &ndash; and even between models from the same manufacturer &ndash; and documentation is sparse. But it hides information important to photographers, like <strong>&ldquo;which color setting was used for the shot.&rdquo;</strong></p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="MakerNote parsing flow" src=/en/posts/chama-optics-dev-story/makernote_parsing.svg></figure></p><p>In Chama Optics, the manufacturer is first identified via <code>exif.maker_note_vendor()</code>, then dispatched to manufacturer-specific parsers.</p><p><strong>Nikon</strong> &ndash; Extracts Picture Control names from the <code>PictureControlData</code> / <code>PictureControlData2</code> tags. User-defined profile names like <code>"VitalityFilm_Pmango"</code> or preset names like <code>"Flat"</code>, <code>"Vivid"</code> are found here.</p><p><strong>Panasonic (Lumix)</strong> &ndash; Provides the richest data. Extracts the base Photo Style name (<code>"NostalgicKintex"</code>) from <code>PhotoStyleName</code>, and the applied LUT filename (<code>"KintexYellow33.CUBE"</code>) along with Gain values from <code>LutPrimaryFile</code>/<code>LutSecondaryFile</code>. This information directly connects to Chama Optics&rsquo; LUT color grading feature.</p><p><strong>Sony</strong> &ndash; Extracts Creative Style/Creative Look information (<code>"Vivid"</code>, <code>"Standard"</code>, <code>"Portrait"</code>, etc.) from the <code>Sony_0x9416</code> tag.</p><p>This MakerNote parsing feature didn&rsquo;t exist in exif-rs, so I implemented it myself and submitted it as <a href=https://github.com/kamadak/exif-rs/pull/57 target=_blank rel=noreferrer>PR #57</a>.</p><h4 class="relative group">EXIF IFD Entry Structure and MakerNote Offset Issues<div id=exif-ifd-entry-structure-and-makernote-offset-issues class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#exif-ifd-entry-structure-and-makernote-offset-issues aria-label=Anchor>#</a></span></h4><p>To parse MakerNote, you first need to understand EXIF&rsquo;s IFD (Image File Directory) structure. EXIF data is based on the TIFF format, and each IFD entry is exactly <strong>12 bytes</strong>:</p><ul><li><strong>Tag</strong> (2 bytes) &ndash; Field identifier (e.g., <code>0x927C</code> = MakerNote)</li><li><strong>Type</strong> (2 bytes) &ndash; Data type</li><li><strong>Count</strong> (4 bytes) &ndash; Number of values</li><li><strong>Value/Offset</strong> (4 bytes) &ndash; The value itself if data is 4 bytes or less; otherwise, an <strong>offset pointing to the data&rsquo;s location</strong></li></ul><p>In standard EXIF, this offset is the <strong>distance from the TIFF header start</strong>. Simple and straightforward. But within MakerNote&rsquo;s internal IFD, this rule breaks down.</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="EXIF IFD entry structure and MakerNote offset methods" src=/en/posts/chama-optics-dev-story/exif_makernote_structure.svg></figure></p><p><strong>Here&rsquo;s the problem</strong>: MakerNote also contains entries with the same structure as IFD entries, but the reference point for offsets &ndash; &ldquo;distance from where?&rdquo; &ndash; <strong>differs by manufacturer.</strong></p><ul><li><strong>TIFF-Relative method</strong> (Panasonic, Canon, Sony, Leica, Sigma) &ndash; Offsets inside MakerNote are relative to the original TIFF header start. The MakerNote itself has no TIFF header, and you need to subtract <code>tiff_offset</code> (distance from TIFF start to MakerNote) from the offset to find the actual data location.</li><li><strong>MakerNote-Relative method</strong> (Nikon, Olympus, Fujifilm, Samsung, Apple, Pentax) &ndash; Offsets inside MakerNote are relative to the MakerNote start. Self-contained structure; Nikon even has its own TIFF header inside the MakerNote.</li></ul><p>Additionally, byte order (endianness) also differs by manufacturer. Nikon uses its own TIFF header, Olympus/Apple use <code>"II"</code>/<code>"MM"</code> bytes in the proprietary header, and Samsung auto-detects from IFD tag number patterns.</p><p>In the end, I implemented header format, offset correction formulas, and byte order detection logic for 10 manufacturers (Panasonic, Nikon, Sony, Canon, Olympus, Fujifilm, Samsung, Apple, Sigma, Pentax), resulting in a PR of 23 files and approximately 5,900 lines.</p><h3 class="relative group">4. Camera Manufacturer Logo System: CSV to build.rs to Binary Embedding<div id=4-camera-manufacturer-logo-system-csv-to-buildrs-to-binary-embedding class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#4-camera-manufacturer-logo-system-csv-to-buildrs-to-binary-embedding aria-label=Anchor>#</a></span></h3><p>To automatically insert <strong>camera manufacturer logos</strong> into photo frames for themes like Strap and Film, two things are needed: (1) identifying the manufacturer from EXIF, and (2) rendering that manufacturer&rsquo;s SVG logo.</p><h4 class="relative group">Compile Time: SVG Download & Embedding from CSV<div id=compile-time-svg-download--embedding-from-csv class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#compile-time-svg-download--embedding-from-csv aria-label=Anchor>#</a></span></h4><p>I previously covered approaches for <a href=/ko/posts/my_first_commerical_rust_embedded_product_3/>maximizing work at compile time with <code>const fn</code>/<code>const impl</code></a> and <a href=/ko/posts/my_first_commerical_rust_embedded_product_4/><code>build.rs</code> build script techniques</a> in a Rust Embedded mass-production project. Chama Optics&rsquo; logo system builds on that experience, extensively using <code>build.rs</code> + <code>include_bytes!()</code>.</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="Compile-time logo pipeline" src=/en/posts/chama-optics-dev-story/logo_build_pipeline.svg></figure></p><p><code>assets/logo_mnf.csv</code> defines logo information for 35 manufacturers. When <code>cargo build</code> runs, <code>build.rs</code> reads this CSV and performs the following:</p><ol><li><strong>SVG Download</strong> &ndash; Fetches SVGs from the <code>url</code> column of each row. For Wikimedia Commons URLs, it downloads via HTTP; for local paths (<code>assets/logo_mnf/contax.svg</code>), it reads directly. On network failure, it retries up to 3 times with 5-second intervals.</li><li><strong>MD5 Hash Verification</strong> &ndash; Compares the MD5 hash of the downloaded file against the <code>expected_md5</code> value in the CSV. <strong>If the file already exists and the hash matches, the re-download is skipped.</strong> If the hash doesn&rsquo;t match, it <code>panic!</code>s to halt the build &ndash; because if the SVG changed on Wikimedia&rsquo;s end, it needs to be intentionally reviewed.</li><li><strong>Rust Code Generation</strong> &ndash; Generates <code>assets/auto_generated/logo_assets.rs</code>, embedding each SVG into the binary via <code>include_bytes!()</code>. No file loading is needed at runtime.</li></ol><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=c1>// Example of auto-generated code
</span></span></span><span class=line><span class=cl><span class=k>pub</span><span class=w> </span><span class=k>const</span><span class=w> </span><span class=no>LOGO_ASSETS</span>: <span class=kp>&amp;</span><span class=p>[</span><span class=n>ArtAsset</span><span class=p>]</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=o>&amp;</span><span class=p>[</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>ArtAsset</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>key</span>: <span class=s>&#34;canon.svg&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>data</span>: <span class=nc>include_bytes</span><span class=o>!</span><span class=p>(</span><span class=s>&#34;.../assets/download/canon.svg&#34;</span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>color_type</span>: <span class=nc>ColorType</span>::<span class=n>Color</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>mnf</span>: <span class=s>&#34;canon&#34;</span><span class=p>,</span><span class=w> </span><span class=n>model</span>: <span class=s>&#34;&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>mnf_model_rel</span>: <span class=nc>MnfRelation</span>::<span class=n>Any</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>},</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// ... 35 manufacturers
</span></span></span><span class=line><span class=cl><span class=p>];</span></span></span></code></pre></div></div><h4 class="relative group">Runtime: EXIF to Logo Matching to SVG Rasterization<div id=runtime-exif-to-logo-matching-to-svg-rasterization class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#runtime-exif-to-logo-matching-to-svg-rasterization aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="Runtime logo matching" src=/en/posts/chama-optics-dev-story/logo_runtime_matching.svg></figure></p><p>When a photo is loaded, <code>Tag::Make</code> (manufacturer) and <code>Tag::Model</code> (model name) are extracted from EXIF, and the <code>LOGO_ASSETS</code> array is iterated for matching.</p><p>There are two matching rules:</p><ul><li><strong><code>MnfRelation::Any</code></strong> &ndash; Either the manufacturer name <strong>or</strong> model name needs to match (most cases)</li><li><strong><code>MnfRelation::Both</code></strong> &ndash; Both the manufacturer name <strong>and</strong> model name must match (special cases)</li></ul><p>A real-world case where <code>Both</code> is needed: <strong>Sigma</strong> changed its logo in 2025. The only camera using the new logo is the <code>SIGMA BF</code> model, so <code>sigma2025.svg</code> (new logo) is registered in the CSV as <code>mnf="sigma", model="sigma bf", mnf_model_rel=Both</code>, while other Sigma cameras use <code>sigma.svg</code> (old logo) with <code>mnf="sigma", mnf_model_rel=Any</code>.</p><p>The matched SVG is parsed with <code>usvg</code>, rasterized with <code>resvg</code>+<code>tiny-skia</code>, and composited at the appropriate position and size within the frame. Rendering behavior varies based on <code>color_type</code> (Black/Color) and <code>fill_ops</code> (Default/Monochrome), allowing logo rendering that matches the background color.</p><h3 class="relative group">5. CJK Font Rendering and Variable Font Optimization<div id=5-cjk-font-rendering-and-variable-font-optimization class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#5-cjk-font-rendering-and-variable-font-optimization aria-label=Anchor>#</a></span></h3><p>Numerous issues arose when rendering Japanese, Korean, and Chinese text on images:</p><ul><li>Some CJK ideographs failing to render</li><li>Glyph widths being incorrect with variable fonts</li></ul><p>The solution was to <strong>embed SourceHanSans as a built-in fallback font</strong>, automatically substituting glyphs unsupported by the selected font. Specifically, the text is iterated character by character, and when the primary font returns <code>GlyphId(0)</code> (no glyph), rendering switches to the SourceHanSans fallback font.</p><h4 class="relative group">Variable Font Weight Remapping<div id=variable-font-weight-remapping class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#variable-font-weight-remapping aria-label=Anchor>#</a></span></h4><p>The primary font used in Chama Optics, <strong>BarlowGX.ttf</strong>, is a variable font, but its internal weight axis values used a non-standard range of <strong>22 to 188</strong>. This didn&rsquo;t match the <strong>100 to 900</strong> range used by CSS standards, FreeType, etc., so specifying Regular weight with <code>ab_glyph</code>&rsquo;s <code>set_variation(b"wght", 400.0)</code> didn&rsquo;t produce the intended result. Additionally, the default width was set to wdth=300 (Condensed), causing glyph widths to be wrong too.</p><p>I thought simply modifying <code>fvar</code> (Font Variations metadata) would suffice, but the <code>hmtx</code> table holding actual glyph widths was still based on Condensed metrics. <strong>Changing only the metadata doesn&rsquo;t change the rendering result.</strong> Ultimately, I extracted 9 weight instances from BarlowGX.ttf at wdth=500 (Regular width), used them as master sources, and completely rebuilt the variable font with <code>fontTools.varLib.build()</code>. The results are <code>Barlow-Variable-Remapped.ttf</code> and <code>Barlow-Variable-Remapped-Narrow.ttf</code>.</p><h4 class="relative group">Merging Multiple Font Files into One &ndash; Absolute File Size Reduction<div id=merging-multiple-font-files-into-one--absolute-file-size-reduction class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#merging-multiple-font-files-into-one--absolute-file-size-reduction aria-label=Anchor>#</a></span></h4><p>Another advantage of variable fonts is the ability to <strong>merge multiple weight files into one</strong>. Where previously 9 or more static font files were needed (Barlow-Thin.ttf, Barlow-Light.ttf, Barlow-Regular.ttf, Barlow-Bold.ttf, Barlow-Black.ttf, etc.), a single variable font can replace them all.</p><p>The same applies to CJK fonts. SourceHanSans (the ideal choice for Japanese, Korean, and Chinese characters) originally ships as separate files per weight, but using the variable font version (<code>SourceHanSansVF</code>) covers all weights from 200 to 800 in a single file. However, this font had the same issue as BarlowGX, so I remapped the weight axis to the standard range to produce <code>SourceHanSansVF-remapped.otf</code>.</p><p>Going further, I used <code>fontTools</code> to <strong>merge fonts with different character sets into one</strong>. Latin fonts + Japanese fonts + Korean fonts can be combined into a single file, and by combining WOFF2 decompression, TTC (Font Collection) processing, instance extraction at specific weights, and UTF-8-based character subsetting, the final file size was minimized.</p><p>The final font files embedded in Chama Optics are:</p><table><thead><tr><th style=text-align:left>Font</th><th style=text-align:right>Static Font Size</th><th style=text-align:right>Variable Font Size</th><th style=text-align:left>Savings</th></tr></thead><tbody><tr><td style=text-align:left><code>Barlow-Variable-Remapped.ttf</code> (100~900)</td><td style=text-align:right>~1.35 MB (9 weights)</td><td style=text-align:right><strong>385 KB</strong></td><td style=text-align:left><strong>~3.5x</strong></td></tr><tr><td style=text-align:left><code>Barlow-Variable-Remapped-Narrow.ttf</code> (100~900)</td><td style=text-align:right>~1.45 MB (9 weights)</td><td style=text-align:right><strong>207 KB</strong></td><td style=text-align:left><strong>~7x</strong></td></tr><tr><td style=text-align:left><code>SourceHanSansVF-remapped.otf</code> (200~800)</td><td style=text-align:right>~105 MB (7 weights)</td><td style=text-align:right><strong>30 MB</strong></td><td style=text-align:left><strong>~3.5x</strong></td></tr><tr><td style=text-align:left><code>DejaVuSansMono.ttf</code> (static)</td><td style=text-align:right>&ndash;</td><td style=text-align:right>327 KB</td><td style=text-align:left>&ndash;</td></tr><tr><td style=text-align:left><code>digital-7.ttf</code> (static)</td><td style=text-align:right>&ndash;</td><td style=text-align:right>34 KB</td><td style=text-align:left>&ndash;</td></tr><tr><td style=text-align:left><strong>Total</strong></td><td style=text-align:right><strong>~108 MB</strong></td><td style=text-align:right><strong>~31 MB</strong></td><td style=text-align:left><strong>~3.5x</strong></td></tr></tbody></table><p>The Barlow case is especially dramatic. The original Barlow project contains 9 weights x 3 widths x 2 (upright+italic) = 54 static TTF files totaling <strong>8.5 MB</strong>, while the two variable fonts needed for Chama Optics (normal + narrow) total just <strong>592 KB</strong>. In a mobile app bundle size-sensitive environment, this difference is decisive.</p><h4 class="relative group">Variable Font Weight Selection in egui<div id=variable-font-weight-selection-in-egui class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#variable-font-weight-selection-in-egui aria-label=Anchor>#</a></span></h4><p>In the desktop version (egui), the variable font weight can be <strong>freely adjusted by the user</strong>. The key is the <code>set_variation</code> API from the <code>ab_glyph</code> crate:</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=k>pub</span><span class=w> </span><span class=k>struct</span> <span class=nc>VariableFontPack</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>pub</span><span class=w> </span><span class=n>label</span>: <span class=kp>&amp;</span><span class=nb>&#39;static</span> <span class=kt>str</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>pub</span><span class=w> </span><span class=n>font</span>: <span class=nc>ab_glyph</span>::<span class=n>FontRef</span><span class=o>&lt;</span><span class=nb>&#39;static</span><span class=o>&gt;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>pub</span><span class=w> </span><span class=n>default</span>: <span class=kt>u16</span><span class=p>,</span><span class=w>       </span><span class=c1>// Default weight (e.g., 300)
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>pub</span><span class=w> </span><span class=n>start</span>: <span class=kt>u16</span><span class=p>,</span><span class=w>         </span><span class=c1>// Minimum weight (e.g., 100)
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>pub</span><span class=w> </span><span class=n>end_include</span>: <span class=kt>u16</span><span class=p>,</span><span class=w>   </span><span class=c1>// Maximum weight (e.g., 900)
</span></span></span><span class=line><span class=cl><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=k>impl</span><span class=w> </span><span class=n>VariableFontPack</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>pub</span><span class=w> </span><span class=k>fn</span> <span class=nf>get_font_by_weight</span><span class=p>(</span><span class=o>&amp;</span><span class=bp>self</span><span class=p>,</span><span class=w> </span><span class=n>weight</span>: <span class=kt>u16</span><span class=p>)</span><span class=w> </span>-&gt; <span class=nc>ab_glyph</span>::<span class=n>FontArc</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=kd>let</span><span class=w> </span><span class=n>clamped</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>weight</span><span class=p>.</span><span class=n>clamp</span><span class=p>(</span><span class=bp>self</span><span class=p>.</span><span class=n>start</span><span class=p>,</span><span class=w> </span><span class=bp>self</span><span class=p>.</span><span class=n>end_include</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=kd>let</span><span class=w> </span><span class=k>mut</span><span class=w> </span><span class=n>font</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=bp>self</span><span class=p>.</span><span class=n>font</span><span class=p>.</span><span class=n>clone</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>font</span><span class=p>.</span><span class=n>set_variation</span><span class=p>(</span><span class=sa>b</span><span class=s>&#34;wght&#34;</span><span class=p>,</span><span class=w> </span><span class=n>clamped</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=kt>f32</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>font</span><span class=p>.</span><span class=n>into</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></div></div><p>When the user adjusts the weight slider in theme settings, <code>set_variation(b"wght", weight)</code> is called with that value to change the font weight at runtime. Continuous values from 100 (Thin) to 900 (Black) can be specified, and intermediate values like 350 or 450 are interpolated for smooth weight transitions.</p><p>This logic works identically across desktop, iOS, and Android. On iOS, <code>FontSelectionView</code> displays a weight slider only for variable fonts and passes the selected weight value to the Rust core via FFI. Android follows the same structure, passing the <code>fontWeight</code> parameter to Rust FFI from Kotlin.</p><p>CJK fallback also respects the weight. When the primary font is Barlow weight 700 (Bold) and a CJK character appears, SourceHanSans is rendered at a weight close to 700 so that <strong>Latin and CJK character weights appear consistent</strong>.</p><h4 class="relative group">Built-in Fonts and System Fonts<div id=built-in-fonts-and-system-fonts class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#built-in-fonts-and-system-fonts aria-label=Anchor>#</a></span></h4><p>Fonts used in Chama Optics fall into two categories: <strong>built-in fonts</strong> and <strong>system (OS) fonts</strong>.</p><p>Built-in fonts are bundled with the app by default: Barlow (Latin), SourceHanSans (CJK fallback), D2Coding (monospace), Digital-7 (segment display style), etc. System fonts allow users to select from fonts installed on their OS for use in themes. Since users need to be able to freely choose the font for text displayed on EXIF frames, built-in fonts alone aren&rsquo;t sufficient.</p><p><strong>On desktop, fonts are embedded in the binary via <code>include_bytes!</code></strong>:</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=k>pub</span><span class=p>(</span><span class=k>crate</span><span class=p>)</span><span class=w> </span><span class=k>const</span><span class=w> </span><span class=no>FONT_BARLOW</span>: <span class=nc>BuiltInFonts</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>BuiltInFonts</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>name</span>: <span class=s>&#34;Barlow&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>data</span>: <span class=nc>include_bytes</span><span class=o>!</span><span class=p>(</span><span class=s>&#34;../../assets/fonts/Barlow-Variable-Remapped.ttf&#34;</span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=p>};</span></span></span></code></pre></div></div><p>Desktop distributes as a single executable for convenience, so font files are included in the binary at compile time. It runs immediately with just the executable, no separate font directory needed.</p><p>On the other hand, <strong>iOS/Android load fonts dynamically via file paths</strong>. Mobile apps are sensitive to binary size, and separating resource files within the app bundle is also platform convention. Swift/Kotlin passes the font directory path to the Rust core via FFI, and Rust reads the files at the appropriate time using <code>std::fs::read()</code>.</p><p>System fonts are supported on desktop only. <code>font-kit</code> crate&rsquo;s <code>SystemSource</code> enumerates OS-installed fonts, and the user&rsquo;s selected font is loaded. This work is performed on a background thread to avoid blocking the UI, shared thread-safely via <code>Arc&lt;RwLock&lt;Vec&lt;SystemFont>>></code>.</p><h4 class="relative group">Debugging font-kit macOS Memory Explosion<div id=debugging-font-kit-macos-memory-explosion class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#debugging-font-kit-macos-memory-explosion aria-label=Anchor>#</a></span></h4><p>After implementing system font enumeration, a serious problem appeared on macOS. <strong>Memory usage shot up to 1.0GB, peaking at 1.5GB</strong> immediately after app launch. (<a href=https://github.com/pmnxis/chama-optics/issues/5 target=_blank rel=noreferrer>#5</a>)</p><p>Tracing with <code>MallocStackLogging</code> and <code>malloc_history</code> revealed the cause was in <code>font-kit</code>&rsquo;s macOS backend (<code>core_text</code>). <code>font_kit::SystemSource::all_fonts()</code> was <strong>reading the entire file data of each font into memory</strong> while enumerating system fonts:</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>435 calls for 2045941700 bytes:  &lt;- ~2GB
</span></span><span class=line><span class=cl>  font_kit::sources::core_text::create_handles_from_core_text_collection
</span></span><span class=line><span class=cl>    font_kit::utils::slurp_file    &lt;- reads entire font file into memory
</span></span><span class=line><span class=cl>      alloc::raw_vec::RawVecInner::try_allocate_in</span></span></code></pre></div></div><p>macOS has hundreds of system fonts installed, and CJK fonts (like Apple SD Gothic Neo, Hiragino, etc.) can be tens of MB each. <code>slurp_file</code> was loading all of them into memory, allocating about 2GB for 435 fonts. (On Windows, the same code used about 90MB.)</p><p>The fix was to fork <code>font-kit</code> and modify <code>all_fonts()</code> to <strong>collect only metadata (name, path) without reading font data</strong>. After the fix, memory usage dropped dramatically to <strong>144.9MB</strong> (peak 389.4MB).</p><h3 class="relative group">6. LUT Color Grading: wagahai-lut&rsquo;s Optimization Philosophy<div id=6-lut-color-grading-wagahai-luts-optimization-philosophy class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#6-lut-color-grading-wagahai-luts-optimization-philosophy aria-label=Anchor>#</a></span></h3><p>The library name comes from a tweet by <a href=https://x.com/wagahaida_L target=_blank rel=noreferrer>wagahaida_L (Laplus Darkness)</a>.</p><table><thead><tr><th>LaplusDarknesss</th><th>wagahaida_L</th></tr></thead><tbody><tr><td><blockquote class=twitter-tweet><p lang=qme dir=ltr><a href=https://t.co/dKCBGYJobj>pic.twitter.com/dKCBGYJobj</a></p>&mdash; „É©„Éó„É©„Çπ„Éª„ÉÄ„Éº„ÇØ„Éç„Çπüõ∏üíú (@LaplusDarknesss) <a href="https://twitter.com/LaplusDarknesss/status/1940063453647147386?ref_src=twsrc%5Etfw">July 1, 2025</a></blockquote><script async src=https://platform.twitter.com/widgets.js></script></td><td><blockquote class=twitter-tweet><p lang=zxx dir=ltr><a href=https://t.co/WjplefTDWX>https://t.co/WjplefTDWX</a> <a href=https://t.co/8L19fSqYBg>pic.twitter.com/8L19fSqYBg</a></p>&mdash; „É©„ÉóÊßò (@wagahaida_L) <a href="https://twitter.com/wagahaida_L/status/1992881206682423708?ref_src=twsrc%5Etfw">November 24, 2025</a></blockquote><script async src=https://platform.twitter.com/widgets.js></script></td></tr></tbody></table><blockquote><p>As an aside, the cheki-style (Polaroid-style) automatic image generation feature being prepared for v0.2.0 was also inspired by Laplus Darkness. I think she&rsquo;s cunningly clever.</p></blockquote><p>The LUT color grading feature added in v0.1.9 uses the self-developed <a href=https://github.com/pmnxis/wagahai-lut target=_blank rel=noreferrer>wagahai-lut</a> (<a href=https://crates.io/crates/wagahai-lut target=_blank rel=noreferrer>crates.io</a>) library.</p><h4 class="relative group">What is a CUBE LUT?<div id=what-is-a-cube-lut class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#what-is-a-cube-lut aria-label=Anchor>#</a></span></h4><p>A CUBE LUT (Look-Up Table) is a <a href=https://web.archive.org/web/20220220033515/https://wwwimages2.adobe.com/content/dam/acom/en/products/speedgrade/cc/pdfs/cube-lut-specification-1.0.pdf target=_blank rel=noreferrer><code>.cube</code> file format defined by Adobe</a> that contains color transformation data. There are two types: 1D LUT and 3D LUT.</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="CUBE LUT concept" src=/en/posts/chama-optics-dev-story/lut_cube_concept.svg></figure></p><p>A <strong>1D LUT</strong> transforms each R, G, and B channel independently. It&rsquo;s a simple structure that looks up input values in a table and converts them to output values. Suitable for brightness/contrast adjustment, but cross-channel interactions (e.g., converting red to blue) are impossible. Table sizes are typically 1,024 (10-bit) to 65,536 (16-bit) entries, with values between adjacent entries calculated via linear interpolation.</p><p>A <strong>3D LUT</strong> maps the entire RGB 3D color space. Input (R, G, B) can be transformed to a completely different (R&rsquo;, G&rsquo;, B&rsquo;), making it useful for creative color grading in film/photography (film look, color grading). Lattice points within the cube define known mappings, and values between lattice points are calculated via <strong>trilinear interpolation</strong> from the 8 surrounding vertices. Common sizes are 17^3 (4,913 points), 33^3 (35,937 points), and 65^3 (274,625 points).</p><h4 class="relative group">wagahai-lut&rsquo;s Optimization Strategy<div id=wagahai-luts-optimization-strategy class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#wagahai-luts-optimization-strategy aria-label=Anchor>#</a></span></h4><p>Existing Rust LUT libraries focused on generality. wagahai-lut was optimized from memory layout to SIMD level to meet Chama Optics&rsquo; requirement: &ldquo;batch processing dozens of 24MP photos must be fast.&rdquo; However, since both x86_64 and ARM64 need to be supported, instead of writing assembly directly, I used the <a href=https://crates.io/crates/wide target=_blank rel=noreferrer><code>wide</code></a> crate for architecture-agnostic vector optimizations.</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="wagahai-lut optimization strategy" src=/en/posts/chama-optics-dev-story/lut_optimization.svg></figure></p><p><strong>1) Structure of Arrays (SoA) Memory Layout</strong></p><p>Typical 3D LUT implementations use an AoS (Array of Structures) layout: <code>[Rgb, Rgb, Rgb, ...]</code>. But trilinear interpolation needs to read 8 vertex values one channel at a time, so in AoS, unnecessary channel data gets loaded into the cache line alongside the needed data.</p><p>wagahai-lut stores 3D LUTs as three separate arrays: <code>r: Vec&lt;f32></code>, <code>g: Vec&lt;f32></code>, <code>b: Vec&lt;f32></code>. Thanks to this SoA layout, the 8 values needed for one channel&rsquo;s interpolation are close together in memory, resulting in higher CPU cache hit rates.</p><p><strong>2) SIMD Parallel Processing (<code>wide::f32x4</code>)</strong></p><p>For 1D LUT processing, <code>wide</code> crate&rsquo;s <code>f32x4</code> SIMD vectors perform linear interpolation of all three R, G, B channels in a <strong>single vector operation</strong>. Three of the four lanes are assigned to R, G, B, with multiplication and addition handled in a single instruction.</p><p><strong>3) Fixed-Size Specialization</strong></p><p>1D LUTs use <code>Box&lt;[Rgb; SIZE]></code> fixed-size arrays for common sizes: <code>Bit10(1024)</code>, <code>Bit12(4096)</code>, <code>Bit14(16384)</code>, <code>Bit16(65536)</code>. Since the size is determined at compile time, bounds checking can be bypassed with direct <code>get_unchecked()</code> access. 3D LUTs also provide separate types for common sizes like 17^3, 33^3, and 65^3.</p><p><strong>4) In-Place Processing and Loop Optimization</strong></p><p>The <code>apply_rgb_mut()</code> / <code>apply_rgba_mut()</code> functions modify image buffers in-place with zero additional memory allocation. In hot loops, the domain range inverse (<code>inv_domain_range</code>) is pre-computed outside the loop, raw pointer arithmetic eliminates <code>get_pixel()</code>/<code>put_pixel()</code> call overhead, and byte slices are traversed linearly to maximize CPU cache prefetching.</p><h4 class="relative group">Benchmark Results<div id=benchmark-results class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#benchmark-results aria-label=Anchor>#</a></span></h4><p>Processing times on M4 Max (Stable Rust), including JPEG decode/encode:</p><table><thead><tr><th style=text-align:left>Resolution</th><th style=text-align:right>1D LUT</th><th style=text-align:right>3D LUT</th></tr></thead><tbody><tr><td style=text-align:left>1920x1080 (FHD)</td><td style=text-align:right>14.39 ms</td><td style=text-align:right>19.40 ms</td></tr><tr><td style=text-align:left>6000x4000 (24MP)</td><td style=text-align:right>159.91 ms</td><td style=text-align:right>223.15 ms</td></tr><tr><td style=text-align:left>8144x5424 (44MP)</td><td style=text-align:right>294.34 ms</td><td style=text-align:right>417.09 ms</td></tr></tbody></table><p>At about 0.22 seconds for 3D LUT processing of a 24MP photo, combined with Rayon parallelization, practical speed is achieved when batch-processing dozens of photos in Chama Optics.</p><h3 class="relative group">7. Desktop Face Detection: Speed Mode and Sliding Window Algorithm<div id=7-desktop-face-detection-speed-mode-and-sliding-window-algorithm class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#7-desktop-face-detection-speed-mode-and-sliding-window-algorithm aria-label=Anchor>#</a></span></h3><p>The desktop version uses ONNX Runtime + InsightFace (det_10g) model. This model&rsquo;s input size is a <strong>fixed 640x640 pixels</strong>. But actual photos are mostly 24MP (6000x4000) or larger, and if the entire image is scaled down to 640x640, faces in group photos where people are photographed small will be missed.</p><p>To solve this, a <strong>multi-stage sliding window algorithm based on Speed Mode</strong> was implemented.</p><table><thead><tr><th style=text-align:left>Mode</th><th style=text-align:center>max_depth</th><th style=text-align:left>Depth Loop Window Size</th><th style=text-align:left>Overall Behavior</th></tr></thead><tbody><tr><td style=text-align:left>Fastest</td><td style=text-align:center>0</td><td style=text-align:left>(none)</td><td style=text-align:left>Full image -> 640x640 resize -> single inference</td></tr><tr><td style=text-align:left>Fast</td><td style=text-align:center>1</td><td style=text-align:left>(none, depth loop not executed)</td><td style=text-align:left>+ Short-side (<code>min(W,H)</code>) sliding window</td></tr><tr><td style=text-align:left>Normal</td><td style=text-align:center>1</td><td style=text-align:left>640x640</td><td style=text-align:left>+ 640x640 fine-grained window</td></tr><tr><td style=text-align:left>Slow</td><td style=text-align:center>2</td><td style=text-align:left>1280x1280 -> 640x640</td><td style=text-align:left>+ 1280->640 multi-stage window</td></tr><tr><td style=text-align:left>Slowest</td><td style=text-align:center>3</td><td style=text-align:left>2560x2560 -> 1280x1280 -> 640x640</td><td style=text-align:left>+ 2560->1280->640 full multi-stage window</td></tr></tbody></table><blockquote><p><strong>Depth Loop window size formula</strong>: <code>window = 640 x 2^(max_depth - depth - 1)</code></p><p>Example: Slowest (max_depth=3) -> depth 0: 2560, depth 1: 1280, depth 2: 640</p></blockquote><p>The algorithm flow is as follows:</p><ol><li><strong>Stage 1 (common)</strong>: Resize the full image to 640x640 for a single inference. Large faces are caught at this stage.</li><li><strong>Stage 2 (Fast and above)</strong>: Move a sliding window of size equal to the image&rsquo;s short side (<code>min(width, height)</code>) with 10% overlap, resizing each window to 640x640 for inference. Prevents misses in unusual aspect ratios (panoramas, etc.).</li><li><strong>Stage 3 (Normal and above)</strong>: Iterate through windows of size <code>640 x 2^(max_depth - depth - 1)</code> per depth. Slowest uses 2560->1280->640, Slow uses 1280->640, Normal uses a single 640 depth.</li><li><strong>Final</strong>: Remove duplicate detections with NMS (Non-Maximum Suppression, IoU threshold 0.4).</li></ol><p>Diagrams visualizing each Speed Mode&rsquo;s behavior (based on a 6000x4000 source image):</p><h4 class="relative group">Fastest<div id=fastest class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#fastest aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="Speed Mode: Fastest" src=/en/posts/chama-optics-dev-story/speed_mode_fastest.svg></figure></p><h4 class="relative group">Fast<div id=fast class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#fast aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="Speed Mode: Fast" src=/en/posts/chama-optics-dev-story/speed_mode_fast.svg></figure></p><h4 class="relative group">Normal<div id=normal class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#normal aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="Speed Mode: Normal" src=/en/posts/chama-optics-dev-story/speed_mode_normal.svg></figure></p><h4 class="relative group">Slow<div id=slow class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#slow aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="Speed Mode: Slow" src=/en/posts/chama-optics-dev-story/speed_mode_slow.svg></figure></p><h4 class="relative group">Slowest<div id=slowest class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#slowest aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="Speed Mode: Slowest" src=/en/posts/chama-optics-dev-story/speed_mode_slowest.svg></figure></p><p>Below is an example of an actual event photo processed in Slowest mode. Even small faces in the back corners of large group photos are detected without exception and mosaic-processed.</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=auto alt="Slowest mode applied example" width=4072 height=1644 src=/en/posts/chama-optics-dev-story/P1167220-OPTICS_hu_15c3e6f46edc9351.webp srcset="/en/posts/chama-optics-dev-story/P1167220-OPTICS_hu_15c3e6f46edc9351.webp 800w, /en/posts/chama-optics-dev-story/P1167220-OPTICS_hu_155c228295382ce9.webp 1280w" sizes="(min-width: 768px) 50vw, 65vw" data-zoom-src=/en/posts/chama-optics-dev-story/P1167220-OPTICS.webp></figure></p><blockquote><p>2025 AGF Amane Kanata fan group photo session</p></blockquote><p>Usage scenarios for each mode:</p><table><thead><tr><th style=text-align:left>Mode</th><th style=text-align:left>Average Processing Time</th><th style=text-align:left>Suitable Situation</th></tr></thead><tbody><tr><td style=text-align:left>Fastest</td><td style=text-align:left>~0.5 sec</td><td style=text-align:left>1-2 person portraits</td></tr><tr><td style=text-align:left>Fast</td><td style=text-align:left>~0.6 sec</td><td style=text-align:left>1-2 person photos with unusual aspect ratios like panoramas</td></tr><tr><td style=text-align:left>Normal</td><td style=text-align:left>~7 sec</td><td style=text-align:left>Group photos of about 10 people</td></tr><tr><td style=text-align:left>Slow</td><td style=text-align:left>~13 sec</td><td style=text-align:left>Group photos of 40-50 people</td></tr><tr><td style=text-align:left>Slowest</td><td style=text-align:left>~28 sec</td><td style=text-align:left>Large group photos of 50+ people</td></tr></tbody></table><p>Fastest scales the entire image to a single 640x640 and finishes in ~0.5 seconds, while Slowest takes ~28 seconds as it scans with overlapping windows at three stages (2560/1280/640). But capturing even small faces in the back corners of event group photos requires this level of scanning.</p><p>Execution providers are also optimized per platform:</p><ul><li><strong>macOS</strong>: CoreML Execution Provider auto-selected &ndash; leveraging Apple&rsquo;s Neural Engine/GPU acceleration</li><li><strong>Windows/Linux</strong>: CPU or OnnxAuto (auto-detection)</li></ul><p>On macOS, even if the user selects CPU, it&rsquo;s internally switched to CoreML to <strong>leverage Apple Silicon&rsquo;s Neural Engine</strong>. This provides several times the performance improvement over CPU.</p><p>On iOS, the sliding window algorithm structure (Fastest/Fast/pyramid depth) is identical to the desktop, but <strong>Apple Vision Framework (<code>VNDetectFaceRectanglesRequest</code>)</strong> is used as the inference engine instead of InsightFace ONNX. Since Vision handles scaling internally, the 640√ó640 resize step is unnecessary, and accurate face detection is possible without an ONNX model.</p><p>On Android, Google ML Kit (<code>com.google.mlkit:face-detection</code>) is used with a multi-pass cumulative structure:</p><ul><li><strong>Pass 1 (all speeds)</strong>: Decode whole image at max ~1024px, <code>PERFORMANCE_MODE_FAST</code>, <code>minFaceSize=0.2</code></li><li><strong>Pass 2 (Fast and above)</strong>: Sliding square window of <code>min(w,h)</code> size with 10% overlap on the 1024px bitmap</li><li><strong>Pass 3+ (Normal and above)</strong>: Pyramid multi-level decode &ndash; <code>base = floor(min(minSide/2, maxSide/3) √ó 1.1)</code>, Normal searches L0, Slow L0‚ÄìL1, Slowest L0‚ÄìL2, all with <code>PERFORMANCE_MODE_ACCURATE</code>, <code>minFaceSize=0.1</code></li><li>All pass results merged via NMS (IoU 0.4) to remove duplicates</li></ul><h3 class="relative group">8. iOS Native Integration<div id=8-ios-native-integration class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#8-ios-native-integration aria-label=Anchor>#</a></span></h3><p>The iOS app doesn&rsquo;t merely wrap the Rust core &ndash; it maximizes the platform&rsquo;s strengths:</p><ul><li><strong>Vision Framework</strong> &ndash; Native iOS face detection for fast and accurate recognition without ONNX models</li><li><strong>PhotosUI</strong> &ndash; Direct image selection from the iOS photo library</li><li><strong>Metal rendering</strong> &ndash; GPU-accelerated image processing</li><li><strong>iPad support</strong> &ndash; Layout optimized for the larger screen</li></ul><h3 class="relative group">9. MPF and Embedded Preview Image Extraction<div id=9-mpf-and-embedded-preview-image-extraction class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#9-mpf-and-embedded-preview-image-extraction aria-label=Anchor>#</a></span></h3><p>Extracting sub-images hidden inside JPEG files plays a decisive role in Chama Optics&rsquo; performance. This feature was implemented as <a href=https://github.com/kamadak/exif-rs/pull/58 target=_blank rel=noreferrer>exif-rs PR #58</a> (<a href=https://github.com/kamadak/exif-rs/pull/58 target=_blank rel=noreferrer>+1,364 lines</a>, based on PR #57).</p><h4 class="relative group">Images Hidden Inside a JPEG<div id=images-hidden-inside-a-jpeg class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#images-hidden-inside-a-jpeg aria-label=Anchor>#</a></span></h4><p>A single JPEG file can actually contain multiple images.</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="JPEG file structure and MPF sub-images" src=/en/posts/chama-optics-dev-story/jpeg_mpf_structure.svg></figure></p><p>Images embedded inside a JPEG can be extracted from three sources:</p><ol><li><strong>EXIF IFD(1) Thumbnail</strong> &ndash; Standard EXIF thumbnail (usually 160x120)</li><li><strong>APP2 Segment (MPF)</strong> &ndash; Multi-Picture Format defined in the <a href=https://www.cipa.jp/std/documents/download_e.html?DC-007-Translation-2021-E target=_blank rel=noreferrer>CIPA DC-007</a> standard. Stored as separate complete JPEG streams after the main EOI.</li><li><strong>MakerNote Internal Preview</strong> &ndash; Vendor-specific non-standard preview images</li></ol><h4 class="relative group">Why MPF Previews Matter: Memory and Performance<div id=why-mpf-previews-matter-memory-and-performance class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#why-mpf-previews-matter-memory-and-performance aria-label=Anchor>#</a></span></h4><p>When showing thumbnails in a photo list, the simplest approach is to <strong>load the original image and then resize it</strong>. But this is horribly inefficient.</p><table><thead><tr><th style=text-align:left>Method</th><th style=text-align:left>Memory Usage</th><th style=text-align:left>Processing Time</th></tr></thead><tbody><tr><td style=text-align:left>Load original (24MP) -> resize</td><td style=text-align:left>~72MB (24M x 3bytes)</td><td style=text-align:left>Slow</td></tr><tr><td style=text-align:left>Use IFD(1) thumbnail</td><td style=text-align:left>~76KB (160x120)</td><td style=text-align:left>Fast, but too small and blurry</td></tr><tr><td style=text-align:left><strong>Use MPF preview (~2MP)</strong></td><td style=text-align:left><strong>~8MB</strong></td><td style=text-align:left><strong>Fast, and visually sufficient</strong></td></tr></tbody></table><p>IFD(1) thumbnails are too small &ndash; fine for list views but blurry for previews. Loading originals means a 24MP image occupies ~72MB in memory with long decoding times. <strong>MPF&rsquo;s 1-2MP preview images</strong> are the sweet spot &ndash; visually sharp enough while keeping memory and CPU overhead at less than 1/10 of the original.</p><p>Especially for a program like Chama Optics that needs to <strong>show dozens of photos simultaneously in a list with theme previews</strong>, this difference is decisive. Loading 50 24MP photos as originals would take ~3.6GB; loading MPF previews takes ~400MB &ndash; roughly a 9x difference.</p><p>To avoid impacting existing exif-rs users, this was provided behind the <code>mpf</code> feature flag.</p><h3 class="relative group">10. HEIF/HEIC Decoder: Per-Platform Strategy<div id=10-heifheic-decoder-per-platform-strategy class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#10-heifheic-decoder-per-platform-strategy aria-label=Anchor>#</a></span></h3><p>Beyond JPEG, more devices are saving photos in HEIF (High Efficiency Image Format). iOS in particular uses HEIF by default when shooting, and the OS itself decides whether to convert to JPEG or keep HEIF when transferring photos externally &ndash; it&rsquo;s not easy for apps to control this. Some mirrorless cameras (Sony, Canon, etc.) have also started supporting HEIF shooting. While some users stick to JPEG for compatibility, failing to handle HEIF files is fatal for a photo app. The problem is that HEIF decoding support varies widely across platforms.</p><p>Chama Optics adopted the strategy of <strong>using OS native decoders wherever possible, and only using libheif on platforms without native support</strong>.</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="HEIF decoder strategy" src=/en/posts/chama-optics-dev-story/heif_decoder_strategy.svg></figure></p><p><strong>iOS/macOS</strong> &ndash; Apple&rsquo;s ImageIO framework natively supports HEIF. Decoding is possible using only the OS API without external libraries. On iOS, the decoded pixel buffer is passed from the Swift app layer to Rust via C FFI; on macOS, Rust calls macOS API bindings directly.</p><p><strong>Android</strong> &ndash; API 26 (Android 8.0) and above natively support HEIF via BitmapFactory and MediaCodec. The Kotlin app decodes and passes the result to Rust via JNA.</p><p><strong>Windows/Linux</strong> &ndash; No native HEIF decoder, or it&rsquo;s limited. In this case, <a href=https://crates.io/crates/libheif-rs target=_blank rel=noreferrer>libheif_rs</a> (Rust bindings for libheif) is used. Since libheif_rs handles C FFI internally, Rust code only calls safe APIs. libheif internally uses libde265 (HEVC decoder) and libaom (AV1/AVIF).</p><p>The key to this strategy is <code>#[cfg(target_os)]</code> conditional compilation. Platforms with native decoders get optimal performance with no external dependencies, and libheif_rs is linked only on platforms that need it. As a result, libheif-related code isn&rsquo;t even compiled in macOS builds.</p><h3 class="relative group">11. Theme Parameter System: Rust to JSON to Platform-Specific UI<div id=11-theme-parameter-system-rust-to-json-to-platform-specific-ui class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#11-theme-parameter-system-rust-to-json-to-platform-specific-ui aria-label=Anchor>#</a></span></h3><p>Chama Optics themes have over 40 configuration parameters &ndash; font weight, watermark position/opacity, frame style, logo visibility, colors, margins, and more. The core requirement was that these parameters must produce <strong>identical results</strong> on desktop and mobile.</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="Theme parameter system" src=/en/posts/chama-optics-dev-story/theme_param_json.svg></figure></p><p>On desktop (egui), Rust structs are <strong>directly referenced</strong> to draw UI widgets. Code like <code>Slider::new(&amp;mut config.font_weight, 100..=900)</code> means the struct field is the UI state &ndash; no JSON serialization, no intermediate conversion.</p><p>The problem is mobile. iOS (SwiftUI) and Android (Jetpack Compose) can&rsquo;t directly access Rust structs. If we manually built UI for each of the 40+ parameters on the Swift/Kotlin side and wrote FFI code to pass values back and forth for each one? Every time a parameter is added, Rust, Swift, and Kotlin would all need simultaneous modifications.</p><p>I solved this with <code>proc_macro</code>. When <code>#[derive(ThemeParam)]</code> is added to a Rust struct definition, the following is auto-generated at compile time:</p><ul><li><strong>JSON schema</strong>: JSON containing each field&rsquo;s UI type (slider, toggle, enum selector, color picker, etc.), range, and default values</li><li><strong>FFI functions</strong>: C ABI functions callable from mobile, such as <code>get_param_json()</code>, <code>set_param()</code></li><li><strong>Deserialization logic</strong>: Code that applies JSON-received values to the Rust struct</li></ul><p>The mobile app parses this JSON to <strong>dynamically generate native UI elements</strong>. <code>"type": "slider"</code> becomes SwiftUI&rsquo;s <code>Slider</code>, Jetpack Compose&rsquo;s <code>Slider()</code>. <code>"type": "toggle"</code> becomes <code>Toggle</code> / <code>Switch</code>. When the user changes a value, it&rsquo;s passed to the Rust core via FFI, and the Rust core returns results through the same rendering pipeline.</p><p>As a result, a single Rust struct simultaneously serves as <strong>UI specification, data model, and serialization format</strong>. When adding a new parameter, just add a field to Rust and annotate it with UI hints &ndash; the proc_macro updates the JSON schema, and the mobile app automatically displays the corresponding UI on the next build. No Swift/Kotlin code modifications needed.</p><p>The <code>build.rs</code> overuse and <code>const fn</code> obsession from embedded development found its application here. Honestly, I&rsquo;m not sure if using proc_macro for this is clean &ndash; even I think it&rsquo;s &ldquo;grotesque.&rdquo; But <strong>it&rsquo;s definitely better than manually synchronizing 40+ parameters across 3 platforms.</strong> For those wanting to learn more about Rust&rsquo;s procedural macros, <a href=https://priver.dev/blog/rust/procedural-macros/ target=_blank rel=noreferrer>this article</a> is a good reference.</p><h3 class="relative group">12. Multilingual Translation System: Auto-Generating Translations for 3 Platforms from a Single YAML<div id=12-multilingual-translation-system-auto-generating-translations-for-3-platforms-from-a-single-yaml class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#12-multilingual-translation-system-auto-generating-translations-for-3-platforms-from-a-single-yaml aria-label=Anchor>#</a></span></h3><p>Supporting 4 languages (English, Korean, Japanese, Indonesian) while <strong>keeping translation strings synchronized across 3 platforms.</strong> If you had to manually edit iOS&rsquo;s <code>.strings</code>, Android&rsquo;s <code>strings.xml</code>, and the desktop&rsquo;s Rust code every time you add or modify a translation key? You&rsquo;d inevitably miss something or fall out of sync.</p><p>The solution is simple. <strong>Use YAML files in rust-core as the single source of truth, and automatically convert them to each platform&rsquo;s format at build time.</strong></p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=low alt="i18n build pipeline" src=/en/posts/chama-optics-dev-story/i18n_build_pipeline.svg></figure></p><h4 class="relative group">YAML: The Source of Truth<div id=yaml-the-source-of-truth class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#yaml-the-source-of-truth aria-label=Anchor>#</a></span></h4><p>There are 23 YAML files in the <code>rust-core/locales/</code> directory. They&rsquo;re split by feature &ndash; <code>common.yml</code>, <code>gallery.yml</code>, <code>theme.yml</code>, <code>face_detection.yml</code>, etc. &ndash; totaling approximately 3,900 lines.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># rust-core/locales/gallery.yml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>gallery</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>empty_state_title</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>en</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;No Images Yet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ko</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Ïù¥ÎØ∏ÏßÄ ÏóÜÏùå&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ja</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;ÁîªÂÉè„Åå„ÅÇ„Çä„Åæ„Åõ„Çì&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>id</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Belum Ada Gambar&#34;</span></span></span></code></pre></div></div><p>This structure matches the format required by the <code>rust_i18n</code> crate exactly. On desktop, <code>rust_i18n::i18n!("locales")</code> embeds the YAML at compile time, and <code>t!("gallery.empty_state_title")</code> is called at runtime. No separate conversion needed. Since <code>cargo:rerun-if-changed=locales</code> is declared in <code>build.rs</code>, modifying YAML triggers automatic recompilation.</p><p>The problem is iOS and Android.</p><h4 class="relative group">iOS: generate_ios_strings.sh<div id=ios-generate_ios_stringssh class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#ios-generate_ios_stringssh aria-label=Anchor>#</a></span></h4><p>iOS uses <code>NSLocalizedString</code> and <code>.strings</code> files. <code>generate_ios_strings.sh</code> parses YAML using Python3 + PyYAML and generates per-locale <code>Localizable.strings</code>.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Automatically called from build_ios.sh</span>
</span></span><span class=line><span class=cl>./generate_ios_strings.sh</span></span></code></pre></div></div><p>It flattens the YAML hierarchy into dot notation for the <code>.strings</code> format.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>/* Auto-generated from rust-core/locales - DO NOT EDIT */
</span></span><span class=line><span class=cl>&#34;gallery.empty_state_title&#34; = &#34;Ïù¥ÎØ∏ÏßÄ ÏóÜÏùå&#34;;
</span></span><span class=line><span class=cl>&#34;common.actions.save&#34; = &#34;Ï†ÄÏû•&#34;;</span></span></code></pre></div></div><p>There were also iOS-specific requirements. Sometimes the same key needs different phrasing on iOS &ndash; for example, where desktop says &ldquo;Load file,&rdquo; iOS should say &ldquo;Select photo&rdquo; for a more natural feel. To handle this, I implemented <strong><code>_ios</code> suffix overrides</strong>. If <code>import.label_ios</code> is defined in YAML, the iOS build uses that value instead of <code>import.label</code>. Desktop and Android are unaffected.</p><p>This script is automatically called from <code>build_ios.sh</code> before Rust cross-compilation, so editing YAML and running an Xcode build automatically reflects the translations.</p><h4 class="relative group">Android: generate_android_strings.sh<div id=android-generate_android_stringssh class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#android-generate_android_stringssh aria-label=Anchor>#</a></span></h4><p>Android uses <code>strings.xml</code> and the <code>R.string.*</code> resource system. There are two key differences.</p><p><strong>First, the key format is different.</strong> Android resource names cannot use dots (<code>.</code>). YAML&rsquo;s <code>gallery.empty_state_title</code> must be converted to <code>gallery_empty_state_title</code> for Android.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>yml_key_to_android_key</span><span class=p>(</span><span class=n>yml_key</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>yml_key</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>&#39;.&#39;</span><span class=p>,</span> <span class=s1>&#39;_&#39;</span><span class=p>)</span></span></span></code></pre></div></div><p><strong>Second, the locale directory conventions differ.</strong> Android represents Indonesian as <code>in</code> instead of <code>id</code> &ndash; <code>values-in/strings.xml</code>. The script handles this mapping.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ANDROID_LOCALE_MAP<span class=o>[</span><span class=s2>&#34;en&#34;</span><span class=o>]=</span><span class=s2>&#34;values&#34;</span>
</span></span><span class=line><span class=cl>ANDROID_LOCALE_MAP<span class=o>[</span><span class=s2>&#34;ko&#34;</span><span class=o>]=</span><span class=s2>&#34;values-ko&#34;</span>
</span></span><span class=line><span class=cl>ANDROID_LOCALE_MAP<span class=o>[</span><span class=s2>&#34;ja&#34;</span><span class=o>]=</span><span class=s2>&#34;values-ja&#34;</span>
</span></span><span class=line><span class=cl>ANDROID_LOCALE_MAP<span class=o>[</span><span class=s2>&#34;id&#34;</span><span class=o>]=</span><span class=s2>&#34;values-in&#34;</span>    <span class=c1># Android uses &#34;in&#34; for Indonesian</span></span></span></code></pre></div></div><p>Another difference from the iOS script is that it uses <strong>diff-based synchronization</strong>. While iOS overwrites files entirely each time, the Android script leaves already-existing keys untouched and <strong>only adds missing keys</strong>. This preserves entries managed manually on the Android side (like app names). Running with <code>--check</code> mode reports missing translations without modifying files.</p><p>When actually using these keys in Android, <code>ThemeI18n.kt</code> maps YAML dot-notation keys to <code>R.string.*</code> resource IDs.</p><div class=highlight-wrapper><div class=highlight><pre tabindex=0 class=chroma><code class=language-kotlin data-lang=kotlin><span class=line><span class=cl><span class=k>object</span> <span class=nc>ThemeI18n</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>fun</span> <span class=nf>translate</span><span class=p>(</span><span class=n>context</span><span class=p>:</span> <span class=n>Context</span><span class=p>,</span> <span class=n>key</span><span class=p>:</span> <span class=n>String</span><span class=p>):</span> <span class=n>String</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>val</span> <span class=py>resourceId</span> <span class=p>=</span> <span class=n>keyToResourceId</span><span class=p>(</span><span class=n>key</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=k>if</span> <span class=p>(</span><span class=n>resourceId</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>)</span> <span class=n>context</span><span class=p>.</span><span class=n>getString</span><span class=p>(</span><span class=n>resourceId</span><span class=p>)</span> <span class=k>else</span> <span class=n>key</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></div></div><h4 class="relative group">Key Conversion Comparison Across Three Platforms<div id=key-conversion-comparison-across-three-platforms class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#key-conversion-comparison-across-three-platforms aria-label=Anchor>#</a></span></h4><table><thead><tr><th style=text-align:left>Element</th><th style=text-align:left>Desktop (Rust)</th><th style=text-align:left>iOS (Swift)</th><th style=text-align:left>Android (Kotlin)</th></tr></thead><tbody><tr><td style=text-align:left><strong>Source</strong></td><td style=text-align:left><code>t!("gallery.empty_state_title")</code></td><td style=text-align:left><code>NSLocalizedString("gallery.empty_state_title")</code></td><td style=text-align:left><code>R.string.gallery_empty_state_title</code></td></tr><tr><td style=text-align:left><strong>Key separator</strong></td><td style=text-align:left><code>.</code> (dot)</td><td style=text-align:left><code>.</code> (dot)</td><td style=text-align:left><code>_</code> (underscore)</td></tr><tr><td style=text-align:left><strong>Generation method</strong></td><td style=text-align:left>Compile-time embedding</td><td style=text-align:left>Build script auto-generation</td><td style=text-align:left>Build script diff sync</td></tr><tr><td style=text-align:left><strong>Platform override</strong></td><td style=text-align:left>‚Äî</td><td style=text-align:left><code>_ios</code> suffix</td><td style=text-align:left>‚Äî</td></tr><tr><td style=text-align:left><strong>Indonesian code</strong></td><td style=text-align:left><code>id</code></td><td style=text-align:left><code>id</code></td><td style=text-align:left><code>in</code></td></tr></tbody></table><p>Thanks to this structure, <strong>editing a single YAML file</strong> reflects changes across all three platforms. Manually synchronizing 23 YAML files, 4 languages, and 3 platforms is practically impossible &ndash; automation was the only approach I could think of.</p><hr><h2 class="relative group">Open-Source Contributions<div id=open-source-contributions class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#open-source-contributions aria-label=Anchor>#</a></span></h2><p>Throughout the development of Chama Optics, I actively contributed to the open-source projects it depends on.</p><table><thead><tr><th style=text-align:left>Project</th><th style=text-align:left>Contribution</th></tr></thead><tbody><tr><td style=text-align:left><a href=https://github.com/kamadak/exif-rs target=_blank rel=noreferrer>exif-rs</a></td><td style=text-align:left>MakerNote parsing &ndash; 10 manufacturer support (<a href=https://github.com/kamadak/exif-rs/pull/57 target=_blank rel=noreferrer>PR #57</a>, +5,946 lines)</td></tr><tr><td style=text-align:left><a href=https://github.com/kamadak/exif-rs target=_blank rel=noreferrer>exif-rs</a></td><td style=text-align:left>MPF and embedded preview image extraction (<a href=https://github.com/kamadak/exif-rs/pull/58 target=_blank rel=noreferrer>PR #58</a>, +1,364 lines)</td></tr><tr><td style=text-align:left><a href=https://github.com/kamadak/exif-rs target=_blank rel=noreferrer>exif-rs</a></td><td style=text-align:left>TIFF field access improvements (<a href=https://github.com/kamadak/exif-rs/pull/51 target=_blank rel=noreferrer>PR #51</a>, approved)</td></tr><tr><td style=text-align:left><a href=https://github.com/servo/font-kit target=_blank rel=noreferrer>font-kit</a></td><td style=text-align:left>Fix macOS system font enumeration memory explosion (<a href=https://github.com/servo/font-kit/pull/271 target=_blank rel=noreferrer>PR #271</a>)</td></tr><tr><td style=text-align:left><a href=https://github.com/emilk/egui target=_blank rel=noreferrer>egui</a></td><td style=text-align:left>Improve main weight setting on variable font load (<a href=https://github.com/emilk/egui/pull/7790 target=_blank rel=noreferrer>PR #7790</a>, approved)</td></tr><tr><td style=text-align:left><a href=https://github.com/pmnxis/wagahai-lut target=_blank rel=noreferrer>wagahai-lut</a></td><td style=text-align:left>1D/3D LUT color grading library (<a href=https://crates.io/crates/wagahai-lut target=_blank rel=noreferrer>crates.io</a>)</td></tr></tbody></table><hr><h2 class="relative group">Release Summary<div id=release-summary class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#release-summary aria-label=Anchor>#</a></span></h2><table><thead><tr><th style=text-align:left>Version</th><th style=text-align:left>Date</th><th style=text-align:left>Major Changes</th></tr></thead><tbody><tr><td style=text-align:left>v0.1.0</td><td style=text-align:left>2025-10-19</td><td style=text-align:left>First pre-release, macOS/Windows, Film theme</td></tr><tr><td style=text-align:left>v0.1.1</td><td style=text-align:left>2025-10-19</td><td style=text-align:left>Japanese translation, batch save, prefix/suffix</td></tr><tr><td style=text-align:left>v0.1.2</td><td style=text-align:left>2025-10-27</td><td style=text-align:left>Glow effect, Film Date/Glow themes</td></tr><tr><td style=text-align:left>v0.1.3</td><td style=text-align:left>2025-11-03</td><td style=text-align:left>Watermark (9 positions), font selection</td></tr><tr><td style=text-align:left>v0.1.4~5</td><td style=text-align:left>2025-11-05~12</td><td style=text-align:left>Just Frame, Strap themes, camera logos</td></tr><tr><td style=text-align:left>v0.1.6</td><td style=text-align:left>2025-11-24</td><td style=text-align:left>Monitor, Lightroom themes, Longside scale</td></tr><tr><td style=text-align:left>v0.1.7</td><td style=text-align:left>2025-12-19</td><td style=text-align:left>One/Two Line, Shot On themes, CJK fix, PhotoStyle</td></tr><tr><td style=text-align:left>v0.1.8</td><td style=text-align:left>2025-12-27</td><td style=text-align:left>Tab UI, grouping, theme preview, multi-core</td></tr><tr><td style=text-align:left>v0.1.9</td><td style=text-align:left>2026-02-04</td><td style=text-align:left>Face detection, LUT color grading, <strong>iOS TestFlight first release</strong></td></tr></tbody></table><hr><h2 class="relative group">Programming with AI (Vibe Coding?)<div id=programming-with-ai-vibe-coding class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#programming-with-ai-vibe-coding aria-label=Anchor>#</a></span></h2><p>I was initially skeptical about AI coding.</p><p>That&rsquo;s why the majority of the desktop version still relies on my hand-written code + <code>cargo fmt/clippy/check</code>. AI (Claude) still doesn&rsquo;t properly understand my intention to overuse <code>const</code> on desktop &ndash; a habit from Rust Embedded.</p><p>But while developing for mobile, I thought <strong>doing all of this alone would be insane</strong>. The priority was to deliver the same results as the existing desktop version on mobile, and I expected there would be a lot of calling native APIs and Rust FFI directly.</p><p>Around that time, while going to a friend&rsquo;s wedding invitation gathering, a friend riding in the car with me said, &ldquo;<strong>Liquid UI in Flutter isn&rsquo;t working properly on iOS 26 right now.</strong>&rdquo; That cemented my decision to only develop natively, and simultaneously I decided to let AI handle the mobile code.</p><p>The result was a division of labor: <strong>I wrote the Rust core myself</strong>, while <strong>the mobile UI (SwiftUI/Jetpack Compose) and FFI bridges were written together with AI</strong>. On the Rust side, I have specific patterns and styles that AI can&rsquo;t match well, but for writing platform-native code in languages I don&rsquo;t know well, like Swift/Kotlin, AI was a huge help.</p><p>After this experience, I started thinking about the position of cross-platform frameworks like Flutter. Of course, the problem that Flutter and React Native solve &ndash; covering multiple platforms with a single codebase &ndash; is still valid. But as AI becomes capable enough to write native code for each platform, the motivation of &ldquo;choosing cross-platform because you don&rsquo;t know native&rdquo; may gradually weaken. The fact that someone like me, who knew nothing about mobile development, could write SwiftUI and Jetpack Compose natively with AI assistance alone might be one case showing that possibility.</p><hr><h2 class="relative group">Future Plans<div id=future-plans class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#future-plans aria-label=Anchor>#</a></span></h2><p>Starting from v0.1.9, desktop-only releases are over, and from v0.2.0 onward, releases will include iOS and Android mobile apps. Rather than adding more features, I plan to focus on occasional stabilization and theme additions.</p><p>The immediate goal is <strong>real-world deployment at the Hololive Expo/Festival in March 2026</strong>. Taking photos with a mirrorless camera at the venue, applying frames directly on iPhone, automatically mosaicing faces, and posting to social media &ndash; providing a workflow where camera users and general smartphone users alike can comfortably use the app in their own environment.</p><p>As a side project, Chama Optics aims to be &ldquo;a tool that helps photographers better showcase their photos,&rdquo; providing an ever more convenient workflow. And based on the procedural macro and optimization experience built up during this development, I also plan to put more effort back into Rust Embedded.</p><hr><h2 class="relative group">References and Citations<div id=references-and-citations class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#references-and-citations aria-label=Anchor>#</a></span></h2><h4 class="relative group">Standards Documents<div id=standards-documents class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#standards-documents aria-label=Anchor>#</a></span></h4><ul><li>CIPA DC-008 &ndash; <a href=https://www.cipa.jp/std/documents/download_e.html?DC-008-Translation-2023-E target=_blank rel=noreferrer>Exchangeable image file format (Exif) Version 3.0</a></li><li>CIPA DC-007 &ndash; <a href=https://www.cipa.jp/std/documents/download_e.html?DC-007-Translation-2021-E target=_blank rel=noreferrer>Multi-Picture Format (MPF)</a></li><li>Adobe ‚Äî <a href=https://web.archive.org/web/20220220033515/https://wwwimages2.adobe.com/content/dam/acom/en/products/speedgrade/cc/pdfs/cube-lut-specification-1.0.pdf target=_blank rel=noreferrer>Adobe Cube LUT Spec 1.0</a></li></ul><h4 class="relative group">Libraries and Frameworks<div id=libraries-and-frameworks class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#libraries-and-frameworks aria-label=Anchor>#</a></span></h4><ul><li><a href=https://github.com/kamadak/exif-rs target=_blank rel=noreferrer>exif-rs</a> &ndash; Rust EXIF parsing library</li><li><a href=https://github.com/emilk/egui target=_blank rel=noreferrer>egui</a> &ndash; Rust immediate mode GUI framework</li><li><a href=https://github.com/servo/font-kit target=_blank rel=noreferrer>font-kit</a> &ndash; Cross-platform font loading library</li><li><a href=https://github.com/pmnxis/wagahai-lut target=_blank rel=noreferrer>wagahai-lut</a> (<a href=https://crates.io/crates/wagahai-lut target=_blank rel=noreferrer>crates.io</a>) &ndash; 1D/3D LUT color grading library</li><li><a href=https://crates.io/crates/libheif-rs target=_blank rel=noreferrer>libheif-rs</a> &ndash; libheif Rust bindings</li><li><a href=https://crates.io/crates/wide target=_blank rel=noreferrer>wide</a> &ndash; Cross-platform SIMD vector crate</li><li><a href=https://onnxruntime.ai/ target=_blank rel=noreferrer>ONNX Runtime</a> &ndash; Cross-platform ML inference engine</li><li><a href=https://github.com/deepinsight/insightface/tree/master/detection/scrfd target=_blank rel=noreferrer>InsightFace SCRFD</a> &ndash; Face detection model (det_10g)</li><li><a href=https://github.com/jeonghyeon-net/exif-frame target=_blank rel=noreferrer>exif-frame</a> &ndash; EXIF frame web tool (initial reference for Chama Optics)</li></ul><h4 class="relative group">Reference Materials<div id=reference-materials class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#reference-materials aria-label=Anchor>#</a></span></h4><ul><li><a href=https://priver.dev/blog/rust/procedural-macros/ target=_blank rel=noreferrer>Rust Procedural Macros</a> &ndash; Procedural macro reference</li><li><a href=https://exiftool.org/TagNames/ target=_blank rel=noreferrer>ExifTool TagNames</a> &ndash; Manufacturer-specific MakerNote tag reference</li><li><a href=https://exiv2.org/makernote.html target=_blank rel=noreferrer>Exiv2 MakerNote Documentation</a> &ndash; MakerNote structure and manufacturer-specific format reference</li></ul><hr><h2 class="relative group">Special Thanks<div id=special-thanks class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#special-thanks aria-label=Anchor>#</a></span></h2><ul><li><a href=https://github.com/SkuldNorniern target=_blank rel=noreferrer>SkuldNorniern</a> &ndash; Debugging and face detection assistance</li><li><a href=https://github.com/miniex target=_blank rel=noreferrer>miniex</a> &ndash; Font system debugging and face detection assistance</li><li><a href=https://github.com/jcm7612 target=_blank rel=noreferrer>jcm7612</a> &ndash; Debugging and feedback</li><li><a href=https://x.com/shiemika324 target=_blank rel=noreferrer>shiemika324</a> &ndash; Illustration and icon illustration</li></ul></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://pmnxis.github.io/en/posts/chama-optics-dev-story/&amp;title=Chama%20Optics%20Development%20Story" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://pmnxis.github.io/en/posts/chama-optics-dev-story/&amp;text=Chama%20Optics%20Development%20Story" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></span>
</a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://reddit.com/submit/?url=https://pmnxis.github.io/en/posts/chama-optics-dev-story/&amp;resubmit=true&amp;title=Chama%20Optics%20Development%20Story" title="Submit to Reddit" aria-label="Submit to Reddit"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M201.5 305.5c-13.8.0-24.9-11.1-24.9-24.6.0-13.8 11.1-24.9 24.9-24.9 13.6.0 24.6 11.1 24.6 24.9.0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4.0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7.0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9.0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5.0 52.6 59.2 95.2 132 95.2 73.1.0 132.3-42.6 132.3-95.2.0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6.0-2.2-2.2-6.1-2.2-8.3.0-2.5 2.5-2.5 6.4.0 8.6 22.8 22.8 87.3 22.8 110.2.0 2.5-2.2 2.5-6.1.0-8.6-2.2-2.2-6.1-2.2-8.3.0zm7.7-75c-13.6.0-24.6 11.1-24.6 24.9.0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.1 24.9-24.6.0-13.8-11-24.9-24.9-24.9z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.facebook.com/sharer/sharer.php?u=https://pmnxis.github.io/en/posts/chama-optics-dev-story/&amp;quote=Chama%20Optics%20Development%20Story" title="Share on Facebook" aria-label="Share on Facebook"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14.0 55.52 4.84 55.52 4.84v61h-31.28c-30.8.0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://pmnxis.github.io/en/posts/chama-optics-dev-story/&amp;subject=Chama%20Optics%20Development%20Story" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span class="flex flex-col"><a class="flex text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" href=/en/posts/my_first_commerical_rust_embedded_product_4/><span class=leading-6><span class="inline-block rtl:rotate-180">&larr;</span>&ensp;Developing a Mass-Produced Rust Embedded Product - 4 Leveraging Build Scripts
</span></a><span class="ms-6 mt-1 text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2023-11-13T21:00:00+09:00>13 November 2023</time>
</span></span><span class="flex flex-col items-end"><a class="flex text-right text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" href=/en/posts/chama-optics-public-release/><span class=leading-6>Chama Optics Release&ensp;<span class="inline-block rtl:rotate-180">&rarr;</span>
</span></a><span class="me-6 mt-1 text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2026-02-17T00:00:00+09:00>17 February 2026</time></span></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=scroll-to-top class="fixed bottom-6 end-6 z-50 transform translate-y-4 opacity-0 duration-200"><a href=#the-top class="pointer-events-auto flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex list-none flex-col sm:flex-row"><li class="flex mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/en/tags/ title=Tags>Tags</a></li><li class="flex mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/en/categories/ title=Categories>Categories</a></li><li class="flex mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=https://github.com/pmnxis title>GitHub</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2026</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh] z-500" data-url=https://pmnxis.github.io/en/><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>